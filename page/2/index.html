<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
<meta name="referrer" content="no-referrer">
  <link rel="apple-touch-icon" sizes="180x180" href="/zyhjy/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/zyhjy/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/zyhjy/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/zyhjy/images/logo.svg" color="#222">

<link rel="stylesheet" href="/zyhjy/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Comic Sans MS:300,300italic,400,400italic,700,700italic|Noto Serif SC:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/zyhjy/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zyh-eric.gitee.io","root":"/zyhjy/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="爱小雅，爱生活，爱物理!">
<meta property="og:type" content="website">
<meta property="og:title" content="ZYHJY">
<meta property="og:url" content="https://zyh-eric.gitee.io/zyhjy/page/2/">
<meta property="og:site_name" content="ZYHJY">
<meta property="og:description" content="爱小雅，爱生活，爱物理!">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Yuhang Zhang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://zyh-eric.gitee.io/zyhjy/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>ZYHJY</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/zyhjy/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ZYHJY</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/zyhjy/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/zyhjy/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/zyhjy/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/zyhjy/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/zyhjy/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/05/19/Qemu%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/05/19/Qemu%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">Qemu介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-19 21:03:50" itemprop="dateCreated datePublished" datetime="2023-05-19T21:03:50+08:00">2023-05-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:50" itemprop="dateModified" datetime="2023-07-30T18:15:50+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Qemu/" itemprop="url" rel="index"><span itemprop="name">Qemu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/05/19/Arrch64%20CPU%E6%8C%87%E4%BB%A4%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/05/19/Arrch64%20CPU%E6%8C%87%E4%BB%A4%E9%9B%86/" class="post-title-link" itemprop="url">Arrch64 CPU Structure</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-19 21:03:50" itemprop="dateCreated datePublished" datetime="2023-05-19T21:03:50+08:00">2023-05-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:50" itemprop="dateModified" datetime="2023-07-30T18:15:50+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Qemu/" itemprop="url" rel="index"><span itemprop="name">Qemu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0-Qemu-Arrch64中的常用寄存器"><a href="#0-Qemu-Arrch64中的常用寄存器" class="headerlink" title="0. Qemu Arrch64中的常用寄存器"></a>0. Qemu Arrch64中的常用寄存器</h1><table>
<thead>
<tr>
<th>Name</th>
<th>Size</th>
<th>Description</th>
<th>Alias</th>
</tr>
</thead>
<tbody><tr>
<td>WZR</td>
<td>32 bits</td>
<td>Zero register</td>
<td></td>
</tr>
<tr>
<td>XZR</td>
<td>64 bits</td>
<td>Zero register</td>
<td></td>
</tr>
<tr>
<td>FP</td>
<td>64 bits</td>
<td>Current stack pointer</td>
<td>X29</td>
</tr>
<tr>
<td>LR</td>
<td>64 bits</td>
<td>Current stack pointer</td>
<td>X30</td>
</tr>
<tr>
<td>SP</td>
<td>64 bits</td>
<td>Current stack pointer</td>
<td>X31</td>
</tr>
<tr>
<td>PC</td>
<td>64 bits</td>
<td>Program counter</td>
<td></td>
</tr>
</tbody></table>
<h1 id="1-An-Introduction-to-the-ARMv8-Instruction-Sets-ARMv8指令集简介"><a href="#1-An-Introduction-to-the-ARMv8-Instruction-Sets-ARMv8指令集简介" class="headerlink" title="1. An Introduction to the ARMv8 Instruction Sets &#x2F; ARMv8指令集简介"></a>1. An Introduction to the ARMv8 Instruction Sets &#x2F; ARMv8指令集简介</h1><p>ARMv8架构引入的最重要的变化之一是增加了64位指令集。这个指令集与现有的32位指令集架构相辅相成。这个增加使得可以访问64位宽整数寄存器和数据操作，并且能够使用64位大小的内存指针。这些新指令被称为A64指令，运行在AArch64执行状态下。ARMv8还包括原始的ARM指令集，现在称为A32指令集，以及Thumb (T32)指令集。A32和T32都在AArch32状态下执行，与ARMv7保持向后兼容。</p>
<p>尽管ARMv8-A与32位ARM体系结构保持向后兼容，但A64指令集与旧的指令集架构是独立的并且编码方式不同。A64添加了一些额外的功能，同时去除了可能限制高性能实现速度或能量效率的其他特性。ARMv8架构还对32位指令集(A32和T32)进行了一些增强。然而，使用这些功能的代码与旧的ARMv7实现不兼容。然而，A64指令集中的指令操作码仍然是32位长，而不是64位。</p>
<p>寻求更详细的A64汇编语言描述的程序员还可以参考ARM编译器armasm参考指南v6.01。</p>
<h2 id="The-ARMv8-instruction-sets"><a href="#The-ARMv8-instruction-sets" class="headerlink" title="The ARMv8 instruction sets"></a>The ARMv8 instruction sets</h2><p>新的A64指令集与现有的A32指令集相似。指令长度为32位，具有类似的语法。</p>
<p>在AArch64状态下，引入了一种新的指令集供内核使用。遵循命名约定，并反映64位操作，该指令集称为：<strong>A64</strong><br>A64提供了与AArch32或ARMv7中的A32和T32指令集类似的功能。新的A64指令集的设计带来了几个改进：</p>
<h4 id="一致的编码方案"><a href="#一致的编码方案" class="headerlink" title="一致的编码方案"></a>一致的编码方案</h4><p>A32中一些指令的晚期添加导致编码方案的一些不一致性。例如，LDR和STR对半字节的支持在编码上与主流的字节和字传输指令稍有不同。结果是寻址模式稍有不同。</p>
<h4 id="广泛的常量范围"><a href="#广泛的常量范围" class="headerlink" title="广泛的常量范围"></a>广泛的常量范围</h4><p>A64指令提供了广泛的常量选项，每个选项都适用于特定指令类型的要求。</p>
<ul>
<li>算术指令通常接受12位立即数常量。</li>
<li>逻辑指令通常接受32位或64位常量，其编码具有一定的限制。</li>
<li>MOV指令接受16位立即数，可以移动到任何16位边界。</li>
<li>地址生成指令适用于与4KB页面大小对齐的地址。</li>
</ul>
<p>对于用于位操作指令的常量，存在稍微复杂的规则。然而，位字段操作指令可以在源操作数或目标操作数中处理任何连续的位序列。</p>
<p>A64提供了灵活的常量，但是编码这些常量，甚至确定特定常量是否可以在特定上下文中合法编码，可能并不简单。</p>
<h4 id="数据类型更容易处理"><a href="#数据类型更容易处理" class="headerlink" title="数据类型更容易处理"></a>数据类型更容易处理</h4><p>A64天然支持64位有符号和无符号数据类型，提供更简洁和高效的操作64位整数的方法。这对于提供64位整数的所有语言，如C或Java，都是有利的。</p>
<h4 id="长偏移量"><a href="#长偏移量" class="headerlink" title="长偏移量"></a>长偏移量</h4><p>A64指令通常提供更长的偏移量，用于<em>PC相对分支和偏移寻址</em>。</p>
<p>增加的分支范围使得管理交叉段跳转更容易。动态生成的代码通常放置在堆上，因此实际上可以位于任何位置。运行时系统通过增加分支范围更容易管理这个过程，并且需要的修复次数更少。</p>
<p>字面池（嵌入在代码流中的字面数据块）的需求一直是ARM指令集的特性。这在A64中仍然存在。然而，更大的PC相对加载偏移量在字面池的管理方面提供了很大帮助，使得每个编译单元可以使用一个字面池。这消除了在长代码序列中为多个池制造位置的需要。</p>
<h4 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h4><p>在AArch64中，指针是64位的，这允许更大的虚拟内存寻址，并提供更大的地址映射自由度。然而，使用64位指针确实会带来一些成本。相同的代码片段在使用64位指针时通常使用更多内存，而不是32位指针。每个指针都存储在内存中，需要8字节而不是4字节。这听起来可能微不足道，但可能累积到显著的性能损失。此外，由于转向64位的内存空间增加使用，可能导致<em>缓存命中的访问次数下降</em>。缓存命中的下降可能会降低性能。</p>
<p>某些语言可以使用压缩指针来解决性能问题，例如Java。</p>
<h4 id="条件构造代替IT块"><a href="#条件构造代替IT块" class="headerlink" title="条件构造代替IT块"></a>条件构造代替IT块</h4><p>IT块是T32的一个有用特性，可以实现避免对未执行指令周围进行短程前向分支的高效序列。然而，它们有时对硬件的高效处理具有一定困难。A64移除了这些块，并用条件指令（如CSEL或条件选择和CINC或条件递增）替换它们。这些条件构造更直观和更容易处理，无需特殊情况。</p>
<h4 id="移位和旋转行为更直观"><a href="#移位和旋转行为更直观" class="headerlink" title="移位和旋转行为更直观"></a>移位和旋转行为更直观</h4><p>A32或T32的移位和旋转行为并不总是与高级语言预期的行为相匹配。</p>
<p>ARMv7提供了一个可用于数据处理指令的位移器。然而，指定移位类型和移位量需要一定数量的操作码位，这些位可以在其他地方使用。</p>
<p>因此，A64指令删除了很少使用的选项，并添加了新的显式指令来执行更复杂的移位操作。</p>
<h4 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h4><p>在静态和动态生成常见算术函数的代码时，A32和T32通常需要不同的指令或指令序列。这是为了处理不同的数据类型。A64中这些操作更加一致，因此更容易生成在不同大小数据类型上进行简单操作的常见序列。</p>
<p>例如，在T32中，相同的指令可以具有不同的编码，具体取决于使用的寄存器（低寄存器还是高寄存器）。</p>
<p>A64指令集编码更加规则和合理。因此，与T32相比，A64汇编器通常需要更少的代码行数。</p>
<h4 id="固定长度指令"><a href="#固定长度指令" class="headerlink" title="固定长度指令"></a>固定长度指令</h4><p>所有A64指令的长度都相同，而T32是一种可变长度指令集。这使得管理和跟踪生成的代码序列更容易，特别是对动态代码生成器有影响。</p>
<h4 id="三个操作数更好地映射"><a href="#三个操作数更好地映射" class="headerlink" title="三个操作数更好地映射"></a>三个操作数更好地映射</h4><p>A32通常保留了用于数据处理操作的真正的三个操作数结构。而T32则包含大量的双操作数指令格式，这在生成代码时稍微不够灵活。A64坚持使用一致的三个操作数语法，进一步增加了指令集的规则性和统一性，有利于编译器。</p>
<h3 id="C-C-inline-assembly"><a href="#C-C-inline-assembly" class="headerlink" title="C&#x2F;C++ inline assembly"></a>C&#x2F;C++ inline assembly</h3><p>在C和C++中，你可以使用<code>asm</code>关键字来包含内联汇编代码。它允许你直接在C或C++函数中嵌入汇编代码。以下是一个示例：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> j)</span> &#123;</span><br><span class="line">  <span class="type">int</span> res = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">asm</span> (</span><br><span class="line">    <span class="string">&quot;ADD %w[result], %w[input_i], %w[input_j]&quot;</span></span><br><span class="line">    : [result] <span class="string">&quot;=r&quot;</span> (res)</span><br><span class="line">    : [input_i] <span class="string">&quot;r&quot;</span> (i), [input_j] <span class="string">&quot;r&quot;</span> (j)</span><br><span class="line">  );</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="type">int</span> a = <span class="number">1</span>;</span><br><span class="line">  <span class="type">int</span> b = <span class="number">2</span>;</span><br><span class="line">  <span class="type">int</span> c = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">  c = add(a, b);</span><br><span class="line">  </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Result of %d + %d = %d\n&quot;</span>, a, b, c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>asm</code>内联汇编语句的一般形式如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">asm</span>(code [: output_operand_list [: input_operand_list [: clobber_list]]]);</span><br></pre></td></tr></table></figure>

<p>以下是各个组成部分的说明：</p>
<ul>
<li><code>code</code>表示汇编代码本身。在示例中，它是<code>&quot;ADD %[result], %[input_i], %[input_j]&quot;</code>。</li>
<li><code>output_operand_list</code>是一个可选的以逗号分隔的输出操作数列表。每个操作数由方括号中的符号名称、约束字符串和括号中的C表达式组成。</li>
<li><code>input_operand_list</code>是一个可选的以逗号分隔的输入操作数列表。输入操作数使用与输出操作数相同的语法。</li>
<li><code>clobber_list</code>是一个可选的被破坏的寄存器或其他值的列表。</li>
</ul>
<p>当在C&#x2F;C++和汇编代码之间调用函数时，你必须遵循AAPCS64规则。</p>
<p>更多信息，请参考：<a target="_blank" rel="noopener" href="https://gcc.gnu.org/onlinedocs/gcc/Using-Assembly-Language-with-C.html#Using-Assembly-Language-with-C">https://gcc.gnu.org/onlinedocs/gcc/Using-Assembly-Language-with-C.html#Using-Assembly-Language-with-C</a>。</p>
<h1 id="2-The-A64-instruction-set"><a href="#2-The-A64-instruction-set" class="headerlink" title="2. The A64 instruction set"></a>2. The A64 instruction set</h1><p>尽管大多数应用级程序员在日常工作中不需要频繁编写汇编代码，但在某些情况下，了解汇编语言仍然具有重要价值。汇编代码在需要高度优化的情况下特别有用，例如编写编译器或使用C等高级语言无法直接访问的低级特性时。</p>
<p>在开发引导代码、设备驱动程序或操作系统时，可能需要使用汇编代码。这些领域通常需要对硬件有精细控制，并要求代码执行效率高。在这些情况下，使用汇编语言编写特定代码部分可以提高性能，并提供对硬件资源的低级访问能力。</p>
<p>此外，在调试C程序时，理解汇编代码变得至关重要。分析汇编指令与相应的C语句之间的映射有助于识别问题并优化代码。能够阅读汇编代码可以增强程序员理解和排查复杂软件行为的能力。</p>
<p>虽然汇编语言对大多数程序员来说不是主要工具，但在性能、低级控制和调试效率至关重要的专门领域中，汇编语言的重要性凸显出来。</p>
<h2 id="Instruction-mnemonics-指令助记符"><a href="#Instruction-mnemonics-指令助记符" class="headerlink" title="Instruction mnemonics &#x2F; 指令助记符"></a>Instruction mnemonics &#x2F; 指令助记符</h2><p>A64汇编语言中使用了指令助记符的重载，根据操作数寄存器名称的不同形式来区分不同的指令。例如，下面的ADD指令具有不同的编码，但您只需要记住一个助记符，汇编器会根据操作数自动选择正确的编码。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ADD W0, W1, W2             // 添加32位寄存器</span><br><span class="line"></span><br><span class="line">ADD X0, X1, X2             // 添加64位寄存器</span><br><span class="line"></span><br><span class="line">ADD X0, X1, W2, SXTW       // 将符号扩展的32位寄存器添加到64位扩展寄存器</span><br><span class="line"></span><br><span class="line">ADD X0, X1, #42            // 添加立即数到64位寄存器</span><br><span class="line"></span><br><span class="line">ADD V0.8H, V1.8H, V2.8H    // NEON中的16位逐个通道添加，共8个通道</span><br></pre></td></tr></table></figure>

<h2 id="Data-processing-instructions-数据处理指令"><a href="#Data-processing-instructions-数据处理指令" class="headerlink" title="Data processing instructions &#x2F; 数据处理指令"></a>Data processing instructions &#x2F; 数据处理指令</h2><p>数据处理指令是处理器的基本算术和逻辑操作，操作的对象是通用寄存器中的值，或者一个寄存器和一个立即值。乘法和除法指令可以看作是这些指令的特殊情况。</p>
<p>数据处理指令大多使用一个目标寄存器和两个源操作数。一般格式可以认为是指令，后面是操作数，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Instruction Rd, Rn, Operand2</span><br></pre></td></tr></table></figure>

<p>第二个操作数可以是一个寄存器、一个修改后的寄存器或一个立即值。使用 R 表示它可以是 X 寄存器或 W 寄存器。</p>
<p>数据处理操作包括：</p>
<ul>
<li>算术和逻辑操作。</li>
<li>移动和移位操作。</li>
<li>符号扩展和零扩展指令。</li>
<li>位和位域操作。</li>
<li>有条件的比较和数据处理操作。</li>
</ul>
<h2 id="Memory-access-instructions-访存指令"><a href="#Memory-access-instructions-访存指令" class="headerlink" title="Memory access instructions &#x2F; 访存指令"></a>Memory access instructions &#x2F; 访存指令</h2><p>和之前的所有ARM处理器一样，ARMv8架构也是一种加载&#x2F;存储（Load&#x2F;Store）架构。这意味着没有数据处理指令直接在内存中操作数据。数据首先必须加载到寄存器中，进行修改，然后再存储到内存中。程序必须指定一个地址、要传输的数据大小以及一个源或目标寄存器。还有其他的加载和存储指令提供了进一步的选项，比如非临时的加载&#x2F;存储、加载&#x2F;存储互斥和获取&#x2F;释放。</p>
<p>内存指令可以以非对齐的方式访问普通内存（参见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Memory-Ordering?lang=en">内存排序</a>）。但这在独占访问、加载获取或存储释放变体中是不支持的。如果不希望进行非对齐访问，可以配置为出错。</p>
<h3 id="Specifying-the-address-for-a-Load-or-Store-instruction"><a href="#Specifying-the-address-for-a-Load-or-Store-instruction" class="headerlink" title="Specifying the address for a Load or Store instruction"></a>Specifying the address for a Load or Store instruction</h3><p>在A64中，用于加载（Load）或存储（Store）指令的地址指定方式与A32和T32类似。虽然存在一些额外的限制和新特性，但对于熟悉A32或T32的人来说，A64提供的地址指定方式应该不会让人感到意外。</p>
<p>在A64中，地址操作数的基础寄存器必须始终是一个X寄存器。然而，有几条指令支持零扩展（zero-extension）或符号扩展（sign-extension），以便可以将32位偏移量作为W寄存器提供。</p>
<h4 id="a-写回修饰符（Writeback-Modifier）（-）"><a href="#a-写回修饰符（Writeback-Modifier）（-）" class="headerlink" title="a. 写回修饰符（Writeback Modifier）（!）"></a>a. 写回修饰符（Writeback Modifier）（!）</h4><p>在ARM汇编语言中，<code>STP</code>（Store Pair）指令的尾部的感叹号（!）是一个存储修饰符，称为写回修饰符（Writeback Modifier）。</p>
<p><code>STP</code>指令用于将一对寄存器的数据存储到内存中。写回修饰符（!）用于指示指令是否应该将存储操作后的更新地址写回到基地址寄存器。如果使用了感叹号（!），则表示在存储数据后，将基地址寄存器进行更新，以便指向下一个存储操作的地址。</p>
<p>以下是一个示例，展示了带有写回修饰符（!）的<code>STP</code>指令的使用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">STP X0, X1, [SP, #16]!</span><br></pre></td></tr></table></figure>

<p>上述指令将X0和X1寄存器的数据存储到内存地址为(SP + 16)的位置。同时，由于感叹号（!）的存在，指令执行后，SP寄存器的值会被更新，指向下一个存储操作的地址。</p>
<p>需要注意的是，如果不使用写回修饰符（!），则基地址寄存器的值不会被修改，即不会进行写回操作。这样，下一次的存储操作将使用原始的基地址进行。</p>
<p>写回修饰符（!）的使用可以方便地在一条指令中实现连续的存储操作，同时更新基地址寄存器，而无需额外的指令来更新寄存器的值。</p>
<h4 id="b-Offset-modes"><a href="#b-Offset-modes" class="headerlink" title="b. Offset modes"></a>b. Offset modes</h4><ol>
<li>有一个64位的基址寄存器（base register）</li>
<li>将一个立即数 &#x2F; 寄存器值 &#x2F; 修改后的寄存器值加到64位的基址寄存器上，这个加上的数就是offset</li>
<li>eg:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LDR X0, [X1, X2, LSL #3] // LSL和#3之间没有逗号</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>load from [X1 + (X2 &lt;&lt; 3)]</li>
<li>lsl : logic shift left</li>
</ul>
<h4 id="c-Index-modes"><a href="#c-Index-modes" class="headerlink" title="c. Index modes"></a>c. Index modes</h4><p>索引模式（Index modes）与偏移模式（Offset modes）类似，但它们还会更新基础寄存器。其语法与A32和T32相同，但操作的集合更为限制。通常，只能为索引模式提供立即偏移量（immediate offsets）。</p>
<p>索引模式有两个变体：前索引模式（pre-index modes）在访问内存之前应用偏移量，而后索引模式（post-index modes）在访问内存之后应用偏移量。</p>
<table>
<thead>
<tr>
<th>Example instruction</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>LDR X0, [X1, #8]!</td>
<td>Pre-index: Update X1 first (to X1 + #8), then load from the new address</td>
</tr>
<tr>
<td>LDR X0, [X1], #8</td>
<td>Post-index: Load from the unmodified address in X1 first, then update X1 (to X1 + #8)</td>
</tr>
<tr>
<td>STP X0, X1, [SP, #-16]!</td>
<td>Push X0 and X1 to the stack. sp is modified</td>
</tr>
<tr>
<td>LDP X0, X1, [SP], #16</td>
<td>Pop X0 and X1 off the stack. sp is modified</td>
</tr>
</tbody></table>
<p>These options map cleanly onto some common C operations:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A C example showing accesses that a compiler is likely to generate.</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">example_strcpy</span><span class="params">(<span class="type">char</span> * dst, <span class="type">const</span> <span class="type">char</span> * src)</span> </span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> c;</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">    c = *(src++);             <span class="comment">// LDRB W2, [X1], #1</span></span><br><span class="line">    *(dst++) = c;             <span class="comment">// STRB W2, [X0], #1</span></span><br><span class="line">    &#125; <span class="keyword">while</span> (c != <span class="string">&#x27;\0&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="PC-relative-modes-load-literal"><a href="#PC-relative-modes-load-literal" class="headerlink" title="PC-relative modes (load-literal)"></a>PC-relative modes (load-literal)</h4><p>A64引入了另一种专门用于访问<strong>字面池（literal pools）</strong>的寻址模式，称为PC相对模式（PC-relative modes）。字面池是嵌入在指令流中的数据块。这些池不会被执行，但可以通过PC相对内存地址从周围的代码中访问它们的数据。字面池通常用于编码无法适应简单的立即数移动指令的常量值。</p>
<p>在A32和T32中，PC可以像通用寄存器一样读取，因此只需将PC指定为基础寄存器即可访问字面池。</p>
<p>在A64中，PC通常是不可访问的，但是有一种特殊的寻址模式（仅适用于加载指令）可以访问PC相对地址。这种专用的寻址模式的范围比A32和T32中的PC相对加载要大得多，因此字面池可以被更稀疏地定位。</p>
<table>
<thead>
<tr>
<th>Example instruction</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>LDR W0, &lt;label&gt;</td>
<td>Load 4 bytes from &lt;label&gt; into W0</td>
</tr>
<tr>
<td>LDR X0, &lt;label&gt;</td>
<td>Load 8 bytes from &lt;label&gt; into X0</td>
</tr>
<tr>
<td>LDRSW X0, &lt;label&gt;</td>
<td>Load 4 bytes from &lt;label&gt; and sign-extend into X0</td>
</tr>
<tr>
<td>LDR S0, &lt;label&gt;</td>
<td>Load 4 bytes from &lt;label&gt; into S0</td>
</tr>
<tr>
<td>LDR D0, &lt;label&gt;</td>
<td>Load 8 bytes from &lt;label&gt; into D0</td>
</tr>
<tr>
<td>LDR Q0, &lt;label&gt;</td>
<td>Load 16 bytes from &lt;label&gt; into Q0</td>
</tr>
<tr>
<td>Note:</td>
<td></td>
</tr>
<tr>
<td>&lt;label&gt; must be 4-byte-aligned for all variants.</td>
<td></td>
</tr>
</tbody></table>
<h3 id="Unprivileged-access"><a href="#Unprivileged-access" class="headerlink" title="Unprivileged access"></a>Unprivileged access</h3><p>A64 LDTR和STTR指令执行非特权的加载（Load）或存储（Store）操作（请参阅ARMv8-A架构参考手册中的LDTR和STTR）：</p>
<ul>
<li>在EL0、EL2或EL3级别下，它们的行为类似于普通的加载或存储指令。</li>
<li>当在EL1级别下执行时，它们的行为类似于在EL0特权级别下执行。</li>
</ul>
<p>这些指令与A32 LDRT和STRT指令是等效的。</p>
<h3 id="Non-temporal-load-and-store-pair-非暂态（non-temporal）加载和存储"><a href="#Non-temporal-load-and-store-pair-非暂态（non-temporal）加载和存储" class="headerlink" title="Non-temporal load and store pair &#x2F; 非暂态（non-temporal）加载和存储"></a>Non-temporal load and store pair &#x2F; 非暂态（non-temporal）加载和存储</h3><p>在ARMv8架构中引入了非暂态（non-temporal）加载和存储的概念。这些概念体现在LDNP和STNP指令中，它们用于读取或写入一对寄存器值。同时，它们向内存系统发出提示，表明对该数据进行缓存是无益的。这个提示并不禁止内存系统的活动，比如地址的缓存、预加载或者聚集。然而，它表明进行缓存不太可能提高性能。一个典型的用例可能是流式数据处理，但需要注意的是，有效地使用这些指令需要针对具体微架构的特定方法。</p>
<p>非暂态加载和存储放宽了内存排序要求。在上述例子中，LDNP指令可能在前面的LDR指令之前执行，这可能导致从不确定的X0地址读取数据。<br>For example:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LDR X0, [X3]</span><br><span class="line">LDNP X2, X1, [X0]      // Xo may not be loaded when the instruction executes!</span><br></pre></td></tr></table></figure>
<p>为了纠正上述问题，需要使用显式的加载屏障：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LDR X0, [X3]</span><br><span class="line">DMB nshld</span><br><span class="line">LDNP X2, X1, [X0]</span><br></pre></td></tr></table></figure>
<p>通过引入加载屏障，可以确保在LDNP指令执行之前先加载X0的值，从而避免了不确定的读取。这样，非暂态加载和存储指令才能够在程序中被正确使用。</p>
<h3 id="Memory-access-atomicity"><a href="#Memory-access-atomicity" class="headerlink" title="Memory access atomicity"></a>Memory access atomicity</h3><p>对齐的内存访问使用单个通用寄存器可以保证原子性。使用对齐的内存地址进行的一对通用寄存器的加载对（load pair）和存储对（store pair）指令可以保证作为两个独立的原子访问。非对齐访问不是原子的，因为通常需要进行两次独立的访问。此外，浮点数和SIMD（单指令多数据）内存访问不能保证原子性。</p>
<h3 id="Memory-barrier-and-fence-instructions"><a href="#Memory-barrier-and-fence-instructions" class="headerlink" title="Memory barrier and fence instructions"></a>Memory barrier and fence instructions</h3><p>ARMv7和ARMv8都支持不同类型的内存屏障操作。这些操作在<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Memory-Ordering?lang=en">Memory Ordering</a>中有更详细的描述：</p>
<p>数据内存屏障（Data Memory Barrier，DMB）：在继续执行后续访问之前，强制使程序顺序中较早的所有内存访问对全局可见。</p>
<p>数据同步屏障（Data Synchronization Barrier，DSB）：在程序继续执行之前，完成所有待处理的加载和存储、缓存维护指令以及TLB维护指令。DSB的行为类似于DMB，但具有附加属性。</p>
<p>指令同步屏障（Instruction Synchronization Barrier，ISB）：该指令刷新CPU流水线和预取缓冲区，导致ISB之后的指令从缓存或内存中获取（或重新获取）。</p>
<p>ARMv8引入了单向栅栏（one-sided fences），这与Release Consistency模型相关。这些栅栏被称为Load-Acquire（LDAR）和Store-Release（STLR），它们是基于地址的同步原语（见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Memory-Ordering?lang=en">One-way barriers</a>）。这两个操作可以配对形成一个完整的栅栏。这些指令仅支持基址寄存器寻址，不支持偏移量或其他类型的索引寻址。</p>
<h3 id="Synchronization-primitives"><a href="#Synchronization-primitives" class="headerlink" title="Synchronization primitives"></a>Synchronization primitives</h3><p>ARMv7-A和ARMv8-A架构都支持独占内存访问。在A64中，这是通过Load&#x2F;Store exclusive（LDXR&#x2F;STXR）指令对实现的。</p>
<p>LDXR指令从内存地址加载一个值，并尝试在该地址上默默地获取独占锁。然后，Store-Exclusive指令只有在成功获取并持有锁时才会将新值写入该位置。LDXR&#x2F;STXR配对用于构建标准的同步原语，例如自旋锁。还提供了一对配对的LDXRP和STXRP指令，以允许原子更新跨越两个寄存器的位置。可用的选项包括字节、半字、字和双字。与Load Acquire&#x2F;Store Release配对一样，只支持基址寄存器寻址，没有任何偏移量。</p>
<p>CLREX指令用于清除监视器，但与ARMv7不同，异常的进入或返回也会清除监视器。监视器也可能被意外地清除，例如由于缓存逐出或与应用程序无直接关联的其他原因。在配对的LDXR和STXR指令之间，软件必须避免任何显式的内存访问、系统控制寄存器更新或缓存维护指令。</p>
<p>此外，还有一对独占的Load Acquire&#x2F;Store Release指令，称为LDAXR和STLXR。详见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Multi-core-processors/Multi-processing-systems/Synchronization?lang=en">同步</a>部分。</p>
<h2 id="Flow-control"><a href="#Flow-control" class="headerlink" title="Flow control"></a>Flow control</h2><p>A64指令集提供了多种不同类型的分支指令（参见表<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/The-A64-instruction-set/Flow-control?lang=en">6.12</a>）。对于简单的相对分支，即从当前地址偏移的分支，使用B指令。<em>无条件的简单相对分支可以向前或向后分支到距离当前程序计数器位置最多128MB的位置</em>。<em>有条件的简单相对分支，在B后附加条件码，其范围较小，为±1MB</em>。</p>
<p>对于需要将返回地址存储在链接寄存器（X30）中的子程序调用，使用BL指令。它没有条件版本。<em>BL的行为类似于B指令，同时额外存储返回地址，即BL指令后一条指令的地址，到寄存器X30中</em>。</p>
<h2 id="System-control-and-other-instructions-系统控制和其他指令"><a href="#System-control-and-other-instructions-系统控制和其他指令" class="headerlink" title="System control and other instructions &#x2F; 系统控制和其他指令"></a>System control and other instructions &#x2F; 系统控制和其他指令</h2><p>A64指令集包含与以下内容相关的指令：</p>
<ul>
<li>异常处理。</li>
<li>系统寄存器访问。</li>
<li>调试。</li>
<li>提示指令，在许多系统中具有电源管理应用。</li>
</ul>
<h3 id="Exception-handling-instructions"><a href="#Exception-handling-instructions" class="headerlink" title="Exception handling instructions"></a>Exception handling instructions</h3><p>有三条异常处理指令，其目的是引发异常。这些指令用于调用在操作系统中运行在更高异常级别的代码（EL1），虚拟机监控程序（EL2）或安全监控程序（EL3）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SVC #imm16   // 监管者调用，允许应用程序调用内核（EL1）。</span><br><span class="line"></span><br><span class="line">HVC #imm16   // 虚拟机监控程序调用，允许操作系统代码调用虚拟机监控程序（EL2）。</span><br><span class="line"></span><br><span class="line">SMC #imm16   // 安全监控程序调用，允许操作系统或虚拟机监控程序调用安全监控程序（EL3）。</span><br></pre></td></tr></table></figure>
<p>立即值将在异常综合寄存器中提供给处理程序。这与ARMv7不同，ARMv7需要通过读取调用指令的操作码来确定立即值。详细信息请参阅<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/AArch64-Exception-Handling?lang=en">AArch64异常处理</a>。</p>
<p>要从异常返回，请使用ERET指令。此指令通过将SPSR_ELn复制到PSTATE并跳转到ELR_ELn中保存的返回地址来恢复处理器状态。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/05/19/Arrch64%20CPU%20Structure/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/05/19/Arrch64%20CPU%20Structure/" class="post-title-link" itemprop="url">Arrch64 CPU Structure</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-19 21:03:50" itemprop="dateCreated datePublished" datetime="2023-05-19T21:03:50+08:00">2023-05-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:50" itemprop="dateModified" datetime="2023-07-30T18:15:50+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Qemu/" itemprop="url" rel="index"><span itemprop="name">Qemu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0-介绍"><a href="#0-介绍" class="headerlink" title="0. 介绍"></a>0. 介绍</h1><ul>
<li>ARMv8-A Architecture and Processors描述了以前的 32 位 ARM 架构，介绍了 ARMv8，并描述了 ARMv8 处理器的一些属性。</li>
<li>接下来，ARMv8 基础知识以异常级别和执行状态的形式描述了体系结构的构建块。</li>
<li>ARMv8 寄存器随后介绍了 ARMv8 体系结构中可用的寄存器。</li>
</ul>
<p>ARMv8 架构中引入的最重要的变化之一是添加了 64 位指令集，它补充了现有的 32 位架构。</p>
<ul>
<li><p>ARMv8 指令集简介介绍了 ARMv7 (A32)指令集架构(ISA) 与 A64 指令集之间的差异。A64 指令集更详细地介绍了 Instruction Set 及其使用。除了用于通用操作的新指令集外，ARMv8 还更改了 NEON 和浮点指令集。</p>
</li>
<li><p>AArch64 浮点数和 NEON描述了 ARMv8 到 ARM 高级 SIMD (NEON) 和浮点指令的变化。有关 NEON 及其在 ARMv7 中的功能的更详细指南，请参阅ARM NEON 程序员指南。</p>
</li>
<li><p>本书的移植到 A64涵盖了将代码从其他体系结构或以前的 ARM 体系结构移植到 ARMv8 时可能遇到的问题。</p>
</li>
<li><p>ARM 64 位架构的 ABI描述了ARM 架构规范的应用程序二进制接口(ABI)。ABI 是针对 ARM 目标的所有编程行为的规范，它管理 64 位代码采用的形式。</p>
</li>
<li><p>AArch64 Exception Handling描述了 ARMv8 在 AArch64 状态下的异常处理行为。</p>
</li>
</ul>
<p>在此之后，重点转移到处理器的内部架构。</p>
<ul>
<li><p>缓存描述了缓存的设计以及缓存的使用如何提高性能。</p>
</li>
<li><p>支持 ARMv8 和转向 64 位架构的一个重要推动因素可能是允许访问比仅使用 32 位更大的地址空间。内存管理单元描述了 MMU 如何将虚拟内存地址转换为物理地址。</p>
</li>
<li><p>内存排序描述了 ARMv8 架构中内存的弱排序模型。通常，这意味着内存访问的顺序不需要与加载和存储操作的程序顺序相同。只有一些程序员必须知道内存排序问题。如果您的代码直接与硬件或在其他内核上执行的代码交互，直接加载或写入要执行的指令，或修改页表，那么您可能必须考虑顺序和障碍。如果您要实现自己的同步功能或无锁算法，这也适用。</p>
</li>
<li><p>多核处理器描述了 ARMv8-A 架构如何支持多核系统。使用 ARMv8 处理器的系统几乎总是以这种方式实现的。</p>
</li>
<li><p>电源管理描述了 ARM 内核如何使用其硬件来降低功耗。big.LITTLE Technology涵盖了应用于多核和多集群系统的电源管理的另一个方面。本章介绍 ARM 的 big.LITTLE 技术如何将高能效LITTLE内核与高性能大内核结合在一起，以提供具有高性能和能效的系统。</p>
</li>
<li><p>安全性描述了 ARMv8 处理器如何创建一个安全或受信任的系统，以保护密码或信用卡详细信息等资产免遭未经授权的复制或损坏。</p>
</li>
<li><p>本书的主要部分以调试结束，描述了 Cortex-A53 和 Cortex-A57 处理器中可用的标准调试和跟踪功能。</p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Introduction">https://developer.arm.com/documentation/den0024/a/Introduction</a></p>
<h1 id="1-ARMv8-A-架构"><a href="#1-ARMv8-A-架构" class="headerlink" title="1. ARMv8-A 架构"></a>1. ARMv8-A 架构</h1><h2 id="以前的Arm架构："><a href="#以前的Arm架构：" class="headerlink" title="以前的Arm架构："></a>以前的Arm架构：</h2><p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/ARMv8-A-Architecture-and-Processors">https://developer.arm.com/documentation/den0024/a/ARMv8-A-Architecture-and-Processors</a></p>
<h2 id="ARMv8-A-架构"><a href="#ARMv8-A-架构" class="headerlink" title="ARMv8-A 架构"></a>ARMv8-A 架构</h2><ul>
<li><p>ARMv8-A 架构是针对应用程序配置的最新一代 ARM 架构。</p>
</li>
<li><p>ARMv8 用于描述整体架构，现在包括了 32 位执行和 64 位执行。</p>
</li>
<li><p>它引入了使用 64 位宽寄存器执行的能力，同时保持与现有 ARMv7 软件的向后兼容性。</p>
</li>
<li><p>ARMv8-A 架构引入了一些改变，可以设计出性能显著提高的处理器实现。</p>
<ul>
<li>大物理地址 &#x2F; Large physical address<ul>
<li>这使得处理器能够访问超过 4GB 的物理内存。</li>
</ul>
</li>
<li>64 位虚拟寻址 &#x2F; 64-bit virtual addressing<ul>
<li>这使得虚拟内存能够超过 4GB 的限制。对于使用内存映射文件 I&#x2F;O 或稀疏寻址的现代桌面和服务器软件来说，这非常重要。</li>
</ul>
</li>
<li>自动事件信号 &#x2F; Automatic event signaling<ul>
<li>这使得能够高效节能地使用高性能自旋锁。</li>
</ul>
</li>
<li>更大的寄存器文件 &#x2F; Larger register files<br>  -31 个 64 位通用寄存器提高性能并减少堆栈使用。</li>
<li>高效的 64 位立即数生成 &#x2F; Efficient 64-bit immediate generation<ul>
<li>对于文字池的需求较少。</li>
</ul>
</li>
<li>大范围的 PC 相对寻址 &#x2F; Large PC-relative addressing range<ul>
<li>为共享库和位置无关可执行文件内的数据寻址提供了一个 +&#x2F;-4GB 的寻址范围，以提高效率。</li>
</ul>
</li>
<li>额外的 16KB 和 64KB 翻译粒度 &#x2F; Additional 16KB and 64KB translation granules<ul>
<li>这降低了翻译后备缓冲 (TLB) 的缺失率和页表遍历的深度。</li>
</ul>
</li>
<li>新的异常模型 &#x2F; New exception model<br>  -这减少了操作系统和虚拟机监视器软件的复杂性。</li>
<li>高效的缓存管理 &#x2F; Efficient cache management<ul>
<li>用户空间缓存操作提高了动态代码生成的效率。使用数据缓存清零指令可以快速清除数据缓存。</li>
</ul>
</li>
<li>硬件加速的密码学 &#x2F; Hardware-accelerated cryptography<ul>
<li>提供了 3 到 10 倍更好的软件加密性能。这对于小颗粒度的解密和加密，以及不能高效地卸载到硬件加速器的情况（例如 HTTPS）非常有用。</li>
</ul>
</li>
<li>加载-获取、存储-释放指令 &#x2F; Load-Acquire, Store-Release instructions<ul>
<li>针对 C++11、C11、Java 内存模型设计。通过消除显式内存屏障指令，提高了线程安全代码的性能。</li>
</ul>
</li>
<li>NEON 双精度浮点高级 SIMD &#x2F; NEON double-precision floating-point advanced SIMD<ul>
<li>这使得可以将 SIMD 向量化应用于更广泛的算法集，例如科学计算、高性能计算 (HPC) 和超级计算机。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="2-Fundamentals-of-ARMv8-ARMv8-基础知识"><a href="#2-Fundamentals-of-ARMv8-ARMv8-基础知识" class="headerlink" title="2. Fundamentals of ARMv8 &#x2F; ARMv8 基础知识"></a>2. Fundamentals of ARMv8 &#x2F; ARMv8 基础知识</h1><ul>
<li><p>在ARMv8中，执行发生在四个异常级别之一。</p>
</li>
<li><p>在AArch64中，异常级别确定特权级别，类似于ARMv7中定义的特权级别。</p>
</li>
<li><p>异常级别决定特权级别，因此在ELn处执行对应于特权级别PLn。</p>
</li>
<li><p>类似地，具有较大值n的异常级别比另一个异常级别更高。</p>
</li>
<li><p>具有较小数字的异常级别被描述为处于较低的异常级别。</p>
</li>
<li><p>异常级别在ARMv8架构的所有操作状态下提供了软件执行特权的逻辑分离。它类似于并支持计算机科学中常见的分层保护域的概念。</p>
</li>
<li><p>以下是每个异常级别上典型软件运行的示例：</p>
<ol>
<li><p>EL0（Exception Level 0）：<br> -也称为用户级别，用于普通应用程序的执行。</p>
</li>
<li><p>EL1（Exception Level 1）：</p>
<ul>
<li>操作系统内核，也称为特权级别（privileged）。</li>
<li>也称为监管级别，用于特权级别较高的操作系统内核。</li>
<li>大多数操作系统内核代码在此级别上运行，具有更高的特权和对底层硬件的直接访问权限。操作系统内核通常被描述为具有特权的软件。</li>
</ul>
</li>
<li><p>EL2（Exception Level 2）：</p>
<ul>
<li>也称为虚拟化级别，用于虚拟化和处理器虚拟机监视器（Hypervisor）的执行。</li>
<li>在EL2级别上，可以运行虚拟机监视器软件，用于创建和管理虚拟机。</li>
</ul>
</li>
<li><p>EL3（Exception Level 3）：</p>
<ul>
<li>低级固件，包括安全监控器（Secure Monitor）。</li>
<li>也称为安全监控级别，用于安全性相关的功能和安全环境的执行。</li>
<li>在EL3级别上，可以运行安全监视器软件，用于实施安全策略和提供安全保护。</li>
</ul>
</li>
</ol>
</li>
</ul>
<p>通常情况下，软件的不同部分，比如应用程序、操作系统的内核或虚拟化管理程序，占据一个特定的异常级别。这个规则的一个例外是内核虚拟化管理程序（如KVM），它可以跨EL2和EL1级别运行。<br></p>
<p>ARMv8-A提供了两种安全状态，Secure（安全）和Non-secure（非安全）。Non-secure状态也被称为Normal World（正常世界）。这使得操作系统（OS）可以与一个可信任的OS并行运行在同一硬件上，并提供对某些软件攻击和硬件攻击的保护。ARM TrustZone技术使系统能够在Normal World和Secure World之间进行分区。与ARMv7-A架构一样，安全监控器（Secure monitor）充当了在Normal World和Secure World之间切换的入口。<br><br>Secure World没有EL2.<br><br><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Fundamentals-of-ARMv8">https://developer.arm.com/documentation/den0024/a/Fundamentals-of-ARMv8</a></p>
<h2 id="执行状态-Execution-states"><a href="#执行状态-Execution-states" class="headerlink" title="执行状态 &#x2F; Execution states"></a>执行状态 &#x2F; Execution states</h2><p>ARMv8架构定义了两个执行状态，AArch64和AArch32。每个状态用于分别描述使用64位通用寄存器或32位通用寄存器的执行。虽然ARMv8 AArch32保留了ARMv7中特权的定义，但在AArch64中，<strong>特权级别由异常级别确定</strong>。因此，ELn处的执行对应于特权级别PLn。<br><br>当处于AArch64状态时，处理器执行A64指令集。当处于AArch32状态时，处理器可以执行A32（在架构早期版本中称为ARM）或T32（Thumb）指令集。<br><br>在AArch32状态下，可信任的操作系统软件在Secure EL3中执行；而在AArch64状态下，主要在Secure EL1中执行。<br><br><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Fundamentals-of-ARMv8/Execution-states">https://developer.arm.com/documentation/den0024/a/Fundamentals-of-ARMv8/Execution-states</a></p>
<h2 id="改变异常级别-Changing-Exception-levels"><a href="#改变异常级别-Changing-Exception-levels" class="headerlink" title="改变异常级别 &#x2F; Changing Exception levels"></a>改变异常级别 &#x2F; Changing Exception levels</h2><p>···<br>改变异常级别（Changing Exception levels）是通过触发异常或使用异常相关的指令来实现的。ARMv8架构中，处理器可以从当前的执行级别切换到更高或更低的异常级别。</p>
<p>要切换到较高的异常级别，可以触发一个异常，例如使用异常相关的指令或发生特定的事件，导致处理器从当前级别切换到更高的级别。例如，从EL0级别切换到EL1级别，可以通过触发一个系统调用（如SVC指令）来引发一个异常，并将控制权转移到EL1级别的异常处理程序。</p>
<p>要切换到较低的异常级别，通常使用异常返回指令（例如ERET或RFE指令）。这些指令会从当前的异常级别返回到较低的级别，并将控制权交还给较低级别的异常处理程序。</p>
<p>在切换异常级别时，需要保存和恢复相应级别的上下文信息，包括寄存器状态、异常向量表和其他相关的控制状态。这样可以确保在切换后能够正确处理异常和保持系统的正确运行。</p>
<p>通过改变异常级别，系统可以在不同的特权级别之间进行切换，并控制不同软件组件的访问权限和特权级别。这提供了灵活的软件隔离和资源管理机制，以满足不同应用场景和安全要求的需要。</p>
<p>···<br>在ARMv7架构中，处理器模式（the processor mode，异常级别）可以在特权软件控制下或在发生异常时自动切换。当发生异常时，内核会保存当前的执行状态和返回地址，进入所需的模式，并可能禁用硬件中断。<br><br>这在下表中进行了总结。应用程序在最低特权级别PL0（先前称为非特权模式）下运行。操作系统在PL1下运行，而在具有虚拟化扩展的系统中，Hypervisor在PL2下运行。安全监控器（Secure monitor）作为在Secure和Non-secure（Normal）世界之间切换的入口，也在PL1下运行。<br></p>
<h3 id="Table-3-1-ARMv7-processor-modes"><a href="#Table-3-1-ARMv7-processor-modes" class="headerlink" title="Table 3.1. ARMv7 processor modes"></a>Table 3.1. ARMv7 processor modes</h3><table>
<thead>
<tr>
<th>Mode</th>
<th>Function</th>
<th>Security state</th>
<th>Privilege Level</th>
</tr>
</thead>
<tbody><tr>
<td>User (USR) &#x2F; 用户模式</td>
<td>大多数应用程序运行的非特权模式</td>
<td>Both</td>
<td>PL0</td>
</tr>
<tr>
<td>FIQ &#x2F; 快速中断模式</td>
<td>在FIQ中断异常发生时进入</td>
<td>Both</td>
<td>PL1</td>
</tr>
<tr>
<td>IRQ &#x2F; 中断模式</td>
<td>在IRQ中断异常发生时进入</td>
<td>Both</td>
<td>PL1</td>
</tr>
<tr>
<td>Supervisor(SVC) &#x2F; 监管模式</td>
<td>在复位时或执行监管调用指令（SVC）时进入</td>
<td>Both</td>
<td>PL1</td>
</tr>
<tr>
<td>Monitor (MON) &#x2F; 监控模式</td>
<td>在执行SMC指令（安全监控调用）或处理配置为安全处理的异常时进入。用于支持在安全和非安全状态之间切换。</td>
<td>Secure only</td>
<td>PL1</td>
</tr>
<tr>
<td>Abort (ABT) &#x2F; 异常模式</td>
<td>在内存访问异常发生时进入</td>
<td>Both</td>
<td>PL1</td>
</tr>
<tr>
<td>Undef (UND) &#x2F; 未定义模式</td>
<td>在执行未定义指令时进入</td>
<td>Both</td>
<td>PL1</td>
</tr>
<tr>
<td>System (SYS) &#x2F; 系统模式</td>
<td>特权模式，与用户模式共享寄存器视图</td>
<td>Both</td>
<td>PL1</td>
</tr>
<tr>
<td>Hyp (HYP)</td>
<td>通过Hypervisor Call和Hyp Trap异常进入。</td>
<td>Non-secure only</td>
<td>PL2</td>
</tr>
</tbody></table>
<p>在AArch64中，处理器模式被映射到异常级别，就像图3.6中所示。与ARMv7（AArch32）类似，当发生异常时，处理器会切换到支持处理异常的异常级别（模式）。<br></p>
<p>异常级别之间的切换遵循一下规则：<br></p>
<ul>
<li>从EL0切换到EL1等较高的异常级别表示增加了软件执行特权。</li>
<li>不能将异常发生在较低的异常级别。 &#x2F; An exception cannot be taken to a lower Exception level.</li>
<li>在EL0级别没有异常处理，异常必须在较高的异常级别进行处理。</li>
<li>异常引起程序流的改变。异常处理程序的执行从与引发异常相关的定义向量开始，在比EL0更高的异常级别上执行。异常包括：<ul>
<li>中断，如IRQ和FIQ。</li>
<li>内存系统异常。</li>
<li>未定义的指令。</li>
<li>系统调用。允许非特权软件向操作系统发出系统调用。</li>
<li>安全监控器或hypervisor陷阱。</li>
</ul>
</li>
<li>结束异常处理并返回到之前的异常级别是通过执行ERET指令完成的。</li>
<li>从异常返回时，可以保持在相同的异常级别或进入较低的异常级别。不能进入较高的异常级别。</li>
<li>随着异常级别的变化，安全状态也会改变，但从EL3返回到非安全状态时除外。请参阅<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Security/Switching-between-Secure-and-Non-secure-state?lang=en">在安全和非安全状态之间切换</a>。<br><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Fundamentals-of-ARMv8/Changing-Exception-levels">https://developer.arm.com/documentation/den0024/a/Fundamentals-of-ARMv8/Changing-Exception-levels</a></li>
</ul>
<h2 id="Changing-execution-state-更改执行状态"><a href="#Changing-execution-state-更改执行状态" class="headerlink" title="Changing execution state &#x2F; 更改执行状态"></a>Changing execution state &#x2F; 更改执行状态</h2><p>有时候，你需要改变系统的执行状态。例如，如果你正在运行一个64位操作系统，并且想要在EL0下运行一个32位应用程序，那么系统必须切换到AArch32执行状态。<br></p>
<p>当应用程序完成或执行返回到操作系统时，系统可以切换回AArch64。不能反过来进行切换。AArch32操作系统无法承载64位应用程序。<br></p>
<p>要在相同的异常级别之间切换执行状态，你必须切换到更高的异常级别，然后返回到原始的异常级别。例如，你可能在64位操作系统下运行32位和64位应用程序。在这种情况下，32位应用程序可以执行并生成一个Supervisor Call（SVC）指令，或者接收一个中断，导致切换到EL1和AArch64。（参见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/The-A64-instruction-set/System-control-and-other-instructions/Exception-handling-instructions?lang=en">异常处理指令</a>）然后操作系统可以进行任务切换并返回到AArch64下的EL0。实际上，这意味着你不能同时运行混合的32位和64位应用程序，因为它们之间没有直接的调用方式。<br></p>
<p>你只能通过改变异常级别来改变执行状态。触发异常可能从AArch32切换到AArch64，而从异常返回可能从AArch64切换到AArch32。<br></p>
<p>在EL3下的代码无法触发到更高的异常级别，因此除非通过复位，否则无法改变执行状态。<br></p>
<p>以下是在AArch64和AArch32执行状态之间切换时的一些要点摘要：<br></p>
<ul>
<li><p>AArch64和AArch32执行状态都具有一般相似的异常级别，但在安全和非安全操作之间存在一些差异。处理异常时处理器所处的执行状态可以限制其他执行状态可用的异常级别。</p>
</li>
<li><p>切换到AArch32需要从更高的异常级别转换到更低的异常级别。这是通过执行ERET指令退出异常处理程序的结果。请参阅异常处理指令。</p>
</li>
<li><p>切换到AArch64需要从较低的异常级别转换到较高的异常级别。触发异常可以是指令执行或外部信号的结果。</p>
</li>
<li><p>如果在触发异常或从异常返回时异常级别保持不变，执行状态将无法改变。</p>
</li>
<li><p>当ARMv8处理器在特定的异常级别处于AArch32执行状态时，它使用与ARMv7相同的异常模型来处理到达该异常级别的异常。在AArch64执行状态下，它使用<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/AArch64-Exception-Handling?lang=en%E4%B8%AD%E6%89%80%E6%8F%8F%E8%BF%B0%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B">AArch64异常处理</a>。</p>
</li>
</ul>
<p>因此，两种状态之间的交互是在安全监视器、虚拟机监控程序或操作系统的级别进行的。在AArch64状态下运行的虚拟机监控程序或操作系统可以支持较低特权级别下的AArch32操作。这意味着在AArch64下运行的操作系统可以承载AArch32和AArch64应用程序。同样，一个AArch64虚拟机监控程序可以承载AArch32和AArch64的客户操作系统。然而，一个32位操作系统不能承载64位应用程序，而一个32位虚拟机监控程序不能承载64位客户操作系统。</p>
<p>对于Cortex-A53和Cortex-A57处理器上实现的最高异常级别（EL3），在触发异常时，每个异常级别要使用的执行状态是固定的。只能通过复位处理器来改变异常级别。对于EL2和EL1，它是由<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/System-registers?lang=en%E6%8E%A7%E5%88%B6%E7%9A%84">系统寄存器</a>。<br><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Fundamentals-of-ARMv8/Changing-execution-state">https://developer.arm.com/documentation/den0024/a/Fundamentals-of-ARMv8/Changing-execution-state</a></p>
<h1 id="3-ARMv8-Registers"><a href="#3-ARMv8-Registers" class="headerlink" title="3. ARMv8 Registers"></a>3. ARMv8 Registers</h1><p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers">https://developer.arm.com/documentation/den0024/a/ARMv8-Registers</a><br>The AArch64 execution state provides 31 × 64-bit general-purpose registers accessible at all times and in all Exception levels.<br></p>
<p>Each register is 64 bits wide and they are generally referred to as registers X0-X30.<br><br>Each AArch64 64-bit general-purpose register (X0-X30) also has a 32-bit (W0-W30) form.<br></p>
<p>The 32-bit W register forms the lower half of the corresponding 64-bit X register. That is, W0 maps onto the lower word of X0, and W1 maps onto the lower word of X1.<br></p>
<p>Reads from W registers disregard the higher 32 bits of the corresponding X register and leave them unchanged. <em>Writes to W registers set the higher 32 bits of the X register to zero.</em> That is, writing 0xFFFFFFFF into W0 sets X0 to 0x00000000FFFFFFFF.<br></p>
<h2 id="AArch64-special-registers"><a href="#AArch64-special-registers" class="headerlink" title="AArch64 special registers"></a>AArch64 special registers</h2><p>除了31个核心寄存器外，还有一些特殊寄存器。<br><br>Note：</p>
<ul>
<li>没有叫做X31或W31的寄存器。许多指令的编码中，数字31表示零寄存器ZR（WZR或XZR）。还有一组受限指令，其中一个或多个参数的编码中数字31表示堆栈指针SP。</li>
</ul>
<p>当访问零寄存器时，所有的写操作都会被忽略，而所有的读操作都会返回0。请注意，<em>64位形式的堆栈指针寄存器（SP register）并不使用X前缀</em>。<br></p>
<p>Table 4.1. Special registers in AArch64<br></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Size</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>WZR</td>
<td>32 bits</td>
<td>Zero register</td>
</tr>
<tr>
<td>XZR</td>
<td>64 bits</td>
<td>Zero register</td>
</tr>
<tr>
<td>WSP</td>
<td>32 bits</td>
<td>Current stack pointer</td>
</tr>
<tr>
<td>SP</td>
<td>64 bits</td>
<td>Current stack pointer</td>
</tr>
<tr>
<td>PC</td>
<td>64 bits</td>
<td>Program counter</td>
</tr>
</tbody></table>
<p>在ARMv8架构中，在AArch64执行状态下，每个异常级别都有以下专用寄存器来保存异常返回状态：</p>
<ul>
<li>异常链接寄存器（ELR）。</li>
<li>保存的处理器状态寄存器（SPSR）。</li>
</ul>
<p><em>每个异常级别都有一个专用的堆栈指针寄存器（SP），但它不用于保存返回状态</em>。<br></p>
<p>Table 4.2. Special registers by Exception level<br></p>
<table>
<thead>
<tr>
<th></th>
<th>EL0</th>
<th>EL1</th>
<th>EL2</th>
<th>EL3</th>
</tr>
</thead>
<tbody><tr>
<td>Stack Pointer (SP)</td>
<td>SP_EL0</td>
<td>SP_EL1</td>
<td>SP_EL2</td>
<td>SP_EL3</td>
</tr>
<tr>
<td>Exception Link Register (ELR)</td>
<td></td>
<td>ELR_EL1</td>
<td>ELR_EL2</td>
<td>ELR_EL3</td>
</tr>
<tr>
<td>Saved Process Status Register (SPSR)</td>
<td></td>
<td>SPSR_EL1</td>
<td>SPSR_EL2</td>
<td>SPSR_EL3</td>
</tr>
</tbody></table>
<p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/AArch64-special-registers">https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/AArch64-special-registers</a></p>
<p>在ARMv8架构中，除了通用寄存器（X0-X30或W0-W30）之外，还有一些特殊寄存器用于特定的功能和控制。以下是其中一些常见的特殊寄存器：</p>
<ol>
<li><p>程序状态寄存器（Program Status Register，PSR）：用于存储和控制处理器的状态信息，例如条件码（Condition Flags）和执行状态（Execution State）。</p>
</li>
<li><p>控制寄存器（Control Register）：用于控制和配置处理器的行为，例如异常处理、内存访问权限和缓存控制。</p>
</li>
<li><p>中断&#x2F;异常向量表寄存器（Interrupt&#x2F;Exception Vector Table Register）：用于存储中断和异常处理程序的地址。</p>
</li>
<li><p>时钟寄存器（Timer Register）：用于计时和定时器功能。</p>
</li>
<li><p>系统控制寄存器（System Control Register）：用于配置和控制系统级别的设置，例如内存管理单元（MMU）和缓存。</p>
</li>
</ol>
<p>这只是一小部分常见的特殊寄存器，实际上还有其他特殊寄存器用于不同的处理器功能和系统配置。具体的特殊寄存器数量和功能可能因处理器型号、架构版本和实现而有所不同。</p>
<h3 id="零寄存器-Zero-register"><a href="#零寄存器-Zero-register" class="headerlink" title="零寄存器 &#x2F; Zero register"></a>零寄存器 &#x2F; Zero register</h3><p>零寄存器在用作源寄存器时读取为零，并且在用作目标寄存器时丢弃结果。你可以在大多数指令中使用零寄存器，但并不是所有指令都可以使用它。</p>
<h3 id="Stack-pointer-堆栈指针"><a href="#Stack-pointer-堆栈指针" class="headerlink" title="Stack pointer &#x2F; 堆栈指针"></a>Stack pointer &#x2F; 堆栈指针</h3><p>在ARMv8架构中，选择使用的堆栈指针在一定程度上与异常级别分离。默认情况下，触发异常会选择目标异常级别的堆栈指针，即SP_ELn。例如，触发到EL1的异常会选择SP_EL1作为堆栈指针。<strong>每个异常级别都有自己的堆栈指针</strong>，包括SP_EL0、SP_EL1、SP_EL2和SP_EL3。在AArch64下，除EL0以外的异常级别，处理器可以使用以下两种方式之一：</p>
<ol>
<li><p><em>与该异常级别关联的专用64位堆栈指针（SP_ELn）</em>。</p>
</li>
<li><p><em>与EL0关联的堆栈指针（SP_EL0）</em>。</p>
</li>
</ol>
<p><em>EL0只能访问SP_EL0</em>。<br></p>
<p>Table 4.3. AArch64 Stack pointer options</p>
<table>
<thead>
<tr>
<th>Exception level</th>
<th>Options</th>
</tr>
</thead>
<tbody><tr>
<td>EL0</td>
<td>EL0t</td>
</tr>
<tr>
<td>EL1</td>
<td>EL1t, EL1h</td>
</tr>
<tr>
<td>EL2</td>
<td>EL2t, EL2h</td>
</tr>
<tr>
<td>EL3</td>
<td>EL3t, EL3h</td>
</tr>
</tbody></table>
<p>The t后缀表示选择SP_EL0堆栈指针。h后缀表示选择SP_ELn堆栈指针。</p>
<p>大多数指令不能直接引用堆栈指针（SP）。然而，某些形式的算术指令，比如ADD指令，可以读取和写入当前堆栈指针，以调整函数中的堆栈指针。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ADD SP, SP, #0x10      // Adjust SP to be 0x10 bytes before its current value</span><br></pre></td></tr></table></figure>
<h3 id="程序计数器（Program-Counter，PC）"><a href="#程序计数器（Program-Counter，PC）" class="headerlink" title="程序计数器（Program Counter，PC）"></a>程序计数器（Program Counter，PC）</h3><p>程序计数器（Program Counter，PC）是ARMv7指令集的一个特性，它将R15作为通用寄存器来使用。PC的使用使得一些巧妙的编程技巧成为可能，但也给编译器和复杂流水线的设计带来了复杂性。在ARMv8中去除了对PC的直接访问，这使得返回预测更加容易，并简化了ABI规范。</p>
<p>PC永远不作为一个命名寄存器进行访问。它在某些指令中的使用是隐式的，例如PC相对加载和地址生成。PC不能作为数据处理指令或加载指令的目的地进行指定。</p>
<h3 id="异常链接寄存器（Exception-Link-Register，ELR）"><a href="#异常链接寄存器（Exception-Link-Register，ELR）" class="headerlink" title="异常链接寄存器（Exception Link Register，ELR）"></a>异常链接寄存器（Exception Link Register，ELR）</h3><p>异常链接寄存器<em>保存异常的返回地址</em>。</p>
<h3 id="链接寄存器（Link-Register，LR）"><a href="#链接寄存器（Link-Register，LR）" class="headerlink" title="链接寄存器（Link Register，LR）"></a>链接寄存器（Link Register，LR）</h3><p>在AArch64状态下，链接寄存器（Link Register，LR）用于存储子程序调用时的返回地址。如果返回地址存储在堆栈上，它也可以用作通用寄存器。LR对应寄存器30。</p>
<h3 id="保存程序状态寄存器（Saved-Program-Status-Register，SPSR"><a href="#保存程序状态寄存器（Saved-Program-Status-Register，SPSR" class="headerlink" title="保存程序状态寄存器（Saved Program Status Register，SPSR"></a>保存程序状态寄存器（Saved Program Status Register，SPSR</h3><p>当发生异常时，处理器状态会存储在相应的保存程序状态寄存器（Saved Program Status Register，SPSR）中，类似于ARMv7中的CPSR。<em>SPSR保存在发生异常之前的PSTATE值，并在执行异常返回时用于恢复PSTATE的值</em>。</p>
<p>The individual bits represent the following values for AArch64:</p>
<h4 id="N-31"><a href="#N-31" class="headerlink" title="N 31"></a>N 31</h4><p>Negative result (N flag).</p>
<h4 id="Z-30"><a href="#Z-30" class="headerlink" title="Z 30"></a>Z 30</h4><p>Zero result (Z) flag.</p>
<h4 id="C-29"><a href="#C-29" class="headerlink" title="C 29"></a>C 29</h4><p>Carry out (C flag).</p>
<h4 id="V-28"><a href="#V-28" class="headerlink" title="V 28"></a>V 28</h4><p>Overflow (V flag).</p>
<h4 id="SS-21"><a href="#SS-21" class="headerlink" title="SS 21"></a>SS 21</h4><p>软件步进（Software Step）标志。指示在发生异常时是否启用了软件步进。</p>
<h4 id="IL-20"><a href="#IL-20" class="headerlink" title="IL 20"></a>IL 20</h4><p>非法执行状态位（Illegal Execution State bit）。显示异常发生前的PSTATE.IL值。</p>
<h4 id="D-9"><a href="#D-9" class="headerlink" title="D 9"></a>D 9</h4><p>进程状态调试掩码（Process state Debug mask）。指示针对异常发生的异常级别的监视点、断点和软件步进调试事件的调试异常是否被屏蔽。</p>
<h4 id="A-8"><a href="#A-8" class="headerlink" title="A 8"></a>A 8</h4><p>SError (System Error) mask bit.</p>
<h4 id="I-7"><a href="#I-7" class="headerlink" title="I 7"></a>I 7</h4><p>IRQ mask bit.</p>
<h4 id="F-6"><a href="#F-6" class="headerlink" title="F 6"></a>F 6</h4><p>FIQ mask bit.</p>
<h4 id="M-4"><a href="#M-4" class="headerlink" title="M[4]"></a>M[4]</h4><p>Execution state that the exception was taken from. A value of 0 indicates AArch64.</p>
<h4 id="M-3-0"><a href="#M-3-0" class="headerlink" title="M[3:0]"></a>M[3:0]</h4><p>Mode or Exception level that an exception was taken from.</p>
<p>在ARMv8中，所写入的SPSR取决于异常级别。如果异常发生在EL1级别，则使用SPSR_EL1。如果异常发生在EL2级别，则使用SPSR_EL2。如果异常发生在EL3级别，则使用SPSR_EL3。在发生异常时，内核会填充相应的SPSR寄存器。</p>
<p>注意：<br>与异常级别相关联的ELR_ELn和SPSR_ELn寄存器对在较低的异常级别执行时保留其状态(retain their state)。</p>
<h2 id="Processor-state"><a href="#Processor-state" class="headerlink" title="Processor state"></a>Processor state</h2><p>在AArch64架构中，没有直接等效于ARMv7的当前程序状态寄存器（CPSR）。在AArch64中，传统CPSR的各个组成部分被提供为可以独立访问的字段。它们统称为处理器状态。</p>
<p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/AArch64-special-registers/Saved-Process-Status-Register?lang=en">PSTATE每个bit的含义</a></p>
<p>AArch64的处理器状态（PSTATE）字段具有以下定义：<br><br>Table 4.4. PSTATE field definitions<br></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>N</td>
<td>Negative condition flag.</td>
</tr>
<tr>
<td>Z</td>
<td>Zero condition flag.</td>
</tr>
<tr>
<td>C</td>
<td>Carry condition flag.</td>
</tr>
<tr>
<td>V</td>
<td>oVerflow condition flag.</td>
</tr>
<tr>
<td>D</td>
<td>Debug mask bit.</td>
</tr>
<tr>
<td>A</td>
<td>SError mask bit.</td>
</tr>
<tr>
<td>I</td>
<td>IRQ mask bit.</td>
</tr>
<tr>
<td>F</td>
<td>FIQ mask bit.</td>
</tr>
<tr>
<td>SS</td>
<td>Software Step bit.</td>
</tr>
<tr>
<td>IL</td>
<td>Illegal execution state bit.</td>
</tr>
<tr>
<td>EL(2)</td>
<td>Exception level.</td>
</tr>
<tr>
<td>nRW</td>
<td>Execution state; 0 &#x3D; 64-bit, 1 &#x3D; 32-bit</td>
</tr>
<tr>
<td>SP</td>
<td>Stack Pointer selector. 0 &#x3D; SP_EL0, 1 &#x3D; SP_ELn</td>
</tr>
</tbody></table>
<p>在AArch64中，通过<em>执行ERET指令来从异常返回，并且这会导致将SPSR_ELn复制到PSTATE中</em>。这将恢复ALU标志、执行状态、异常级别和处理器分支。从这里，您将从ELR_ELn中的地址继续执行。</p>
<p>PSTATE.{N, Z, C, V}字段可以在EL0级别进行访问。所有其他PSTATE字段可以在EL1或更高级别执行，并且在EL0级别未定义。</p>
<h2 id="System-registers"><a href="#System-registers" class="headerlink" title="System registers"></a>System registers</h2><p>在AArch64中，系统配置通过系统寄存器进行控制，并使用MSR和MRS指令进行访问。这与ARMv7-A不同，后者通常通过协处理器15（CP15）操作来访问这些寄存器。寄存器的名称告诉您可以从中访问的最低异常级别。</p>
<p>例如：</p>
<ul>
<li>TTBR0_EL1可以从EL1、EL2和EL3级别进行访问。</li>
<li>TTBR0_EL2可以从EL2和EL3级别进行访问。</li>
</ul>
<p>具有后缀_ELn的寄存器在某些或所有级别中有一个单独的备份，尽管通常不包括EL0。很少有系统寄存器可以从EL0级别进行访问，尽管Cache Type Register (CTR_EL0)是一个可以访问的例子。</p>
<p>访问系统寄存器的代码形式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MRS  x0, TTBR0_EL1          // Move TTBR0_EL1 into x0</span><br><span class="line"></span><br><span class="line">MSR  TTBR0_EL1, x0          // Move x0 into TTBR0_EL1</span><br></pre></td></tr></table></figure>
<p>先前的ARM架构版本使用协处理器进行系统配置。然而，AArch64不支持协处理器。表<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/System-registers?lang=en#BABHJIIB">4.5</a>列出了本书提到的系统寄存器。</p>
<p>完整列表请参阅《ARM体系结构参考手册-ARMv8，ARMv8-A架构配置文件》附录J。</p>
<p>该表显示了每个寄存器具有单独副本的异常级别。例如，独立的辅助控制寄存器（ACTLRs）存在于ACTLR_EL1、ACTLR_EL2和ACTLR_EL3中。</p>
<h3 id="The-system-control-register-系统控制寄存器"><a href="#The-system-control-register-系统控制寄存器" class="headerlink" title="The system control register &#x2F; 系统控制寄存器"></a>The system control register &#x2F; 系统控制寄存器</h3><p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/System-registers/The-system-control-register?lang=en">系统控制寄存器</a>（System Control Register，简称SCTLR）是一个寄存器，用于控制标准内存、系统功能，并为内核中实现的功能提供状态信息。</p>
<h2 id="Endianness"><a href="#Endianness" class="headerlink" title="Endianness"></a>Endianness</h2><p>在内存中查看字节的方式有两种基本方法，即小端序（Little-Endian，LE）和大端序（Big-Endian，BE）。在大端序的计算机上，一个对象在内存中的最高有效字节存储在最低地址，也就是离零地址最近的地址。而在小端序的计算机上，最低有效字节存储在最低地址。字节顺序也可以用字节序来表示，而非字节序。</p>
<p>数据字节序独立地由每个执行级别控制。对于EL3、EL2和EL1，SCTLR_ELn.EE寄存器设置字节序。在EL1级别上，SCTLR_EL1.E0E寄存器控制EL0的数据字节序设置。在AArch64执行状态下，数据访问可以是小端序或大端序，而指令获取始终为小端序。</p>
<p>处理器是否同时支持小端序和大端序取决于处理器的实现。如果仅支持小端序，则EE和E0E位始终为0。同样，如果仅支持大端序，则EE和E0E位的值为静态1。</p>
<p>在使用AArch32时，在EL1、EL2或EL3级别上，CPSR.E位与对应的系统控制寄存器EE位具有不同的值已经被弃用。ARMv7的SETEND指令的使用也已经被弃用。通过设置SCTLR.SED位，可以导致在执行SETEND指令时引发未定义异常。</p>
<h2 id="Changing-execution-state-again"><a href="#Changing-execution-state-again" class="headerlink" title="Changing execution state (again)"></a>Changing execution state (again)</h2><p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/Changing-execution-state--again-?lang=en">Changing execution state (again)</a><br>在从AArch32执行状态进入AArch64执行状态时，从寄存器的角度考虑，以下情况发生变化：</p>
<p>对于在AArch32执行状态下可访问的任何较低异常级别的寄存器的上32位值是未知的。</p>
<p>在AArch32执行状态下不可访问的寄存器将保留它们在AArch32执行之前的状态。</p>
<p>在从使用AArch32的EL2进入EL3的异常入口处，ELR_EL2的上32位值是未知的。</p>
<p>与AArch32执行状态下不可访问的异常级别相关联的AArch64堆栈指针（SPs）和异常链接寄存器（ELRs），在该异常级别中保留它们在AArch32执行之前的状态。这适用于以下寄存器：</p>
<p>SP_EL0</p>
<p>SP_EL1</p>
<p>SP_EL2</p>
<p>ELR_EL1</p>
<p>一般而言，应用程序员编写的应用程序针对AArch32或AArch64中的一种执行状态。只有操作系统需要考虑这两种执行状态以及它们之间的切换。</p>
<h2 id="NEON-and-floating-point-registers"><a href="#NEON-and-floating-point-registers" class="headerlink" title="NEON and floating-point registers"></a>NEON and floating-point registers</h2><p>除了通用寄存器外，ARMv8还具有32个128位浮点寄存器，标记为V0-V31。这32个寄存器用于存储标量浮点指令的浮点操作数，以及NEON操作的标量和矢量操作数。浮点寄存器和NEON寄存器也在<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/AArch64-Floating-point-and-NEON?lang=en">AArch64浮点和NEON</a>中进行了介绍。</p>
<h1 id="4-An-Introduction-to-the-ARMv8-Instruction-Sets-ARMv8指令集简介"><a href="#4-An-Introduction-to-the-ARMv8-Instruction-Sets-ARMv8指令集简介" class="headerlink" title="4. An Introduction to the ARMv8 Instruction Sets &#x2F; ARMv8指令集简介"></a>4. An Introduction to the ARMv8 Instruction Sets &#x2F; ARMv8指令集简介</h1><p>ARMv8架构引入的最重要的变化之一是增加了64位指令集。这个指令集与现有的32位指令集架构相辅相成。这个增加使得可以访问64位宽整数寄存器和数据操作，并且能够使用64位大小的内存指针。这些新指令被称为A64指令，运行在AArch64执行状态下。ARMv8还包括原始的ARM指令集，现在称为A32指令集，以及Thumb (T32)指令集。A32和T32都在AArch32状态下执行，与ARMv7保持向后兼容。</p>
<p>尽管ARMv8-A与32位ARM体系结构保持向后兼容，但A64指令集与旧的指令集架构是独立的并且编码方式不同。A64添加了一些额外的功能，同时去除了可能限制高性能实现速度或能量效率的其他特性。ARMv8架构还对32位指令集(A32和T32)进行了一些增强。然而，使用这些功能的代码与旧的ARMv7实现不兼容。然而，A64指令集中的指令操作码仍然是32位长，而不是64位。</p>
<p>寻求更详细的A64汇编语言描述的程序员还可以参考ARM编译器armasm参考指南v6.01。</p>
<h2 id="The-ARMv8-instruction-sets"><a href="#The-ARMv8-instruction-sets" class="headerlink" title="The ARMv8 instruction sets"></a>The ARMv8 instruction sets</h2><p>新的A64指令集与现有的A32指令集相似。指令长度为32位，具有类似的语法。</p>
<p>在AArch64状态下，引入了一种新的指令集供内核使用。遵循命名约定，并反映64位操作，该指令集称为：<strong>A64</strong><br>A64提供了与AArch32或ARMv7中的A32和T32指令集类似的功能。新的A64指令集的设计带来了几个改进：</p>
<h4 id="一致的编码方案"><a href="#一致的编码方案" class="headerlink" title="一致的编码方案"></a>一致的编码方案</h4><p>A32中一些指令的晚期添加导致编码方案的一些不一致性。例如，LDR和STR对半字节的支持在编码上与主流的字节和字传输指令稍有不同。结果是寻址模式稍有不同。</p>
<h4 id="广泛的常量范围"><a href="#广泛的常量范围" class="headerlink" title="广泛的常量范围"></a>广泛的常量范围</h4><p>A64指令提供了广泛的常量选项，每个选项都适用于特定指令类型的要求。</p>
<ul>
<li>算术指令通常接受12位立即数常量。</li>
<li>逻辑指令通常接受32位或64位常量，其编码具有一定的限制。</li>
<li>MOV指令接受16位立即数，可以移动到任何16位边界。</li>
<li>地址生成指令适用于与4KB页面大小对齐的地址。</li>
</ul>
<p>对于用于位操作指令的常量，存在稍微复杂的规则。然而，位字段操作指令可以在源操作数或目标操作数中处理任何连续的位序列。</p>
<p>A64提供了灵活的常量，但是编码这些常量，甚至确定特定常量是否可以在特定上下文中合法编码，可能并不简单。</p>
<h4 id="数据类型更容易处理"><a href="#数据类型更容易处理" class="headerlink" title="数据类型更容易处理"></a>数据类型更容易处理</h4><p>A64天然支持64位有符号和无符号数据类型，提供更简洁和高效的操作64位整数的方法。这对于提供64位整数的所有语言，如C或Java，都是有利的。</p>
<h4 id="长偏移量"><a href="#长偏移量" class="headerlink" title="长偏移量"></a>长偏移量</h4><p>A64指令通常提供更长的偏移量，用于<em>PC相对分支和偏移寻址</em>。</p>
<p>增加的分支范围使得管理交叉段跳转更容易。动态生成的代码通常放置在堆上，因此实际上可以位于任何位置。运行时系统通过增加分支范围更容易管理这个过程，并且需要的修复次数更少。</p>
<p>字面池（嵌入在代码流中的字面数据块）的需求一直是ARM指令集的特性。这在A64中仍然存在。然而，更大的PC相对加载偏移量在字面池的管理方面提供了很大帮助，使得每个编译单元可以使用一个字面池。这消除了在长代码序列中为多个池制造位置的需要。</p>
<h4 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h4><p>在AArch64中，指针是64位的，这允许更大的虚拟内存寻址，并提供更大的地址映射自由度。然而，使用64位指针确实会带来一些成本。相同的代码片段在使用64位指针时通常使用更多内存，而不是32位指针。每个指针都存储在内存中，需要8字节而不是4字节。这听起来可能微不足道，但可能累积到显著的性能损失。此外，由于转向64位的内存空间增加使用，可能导致<em>缓存命中的访问次数下降</em>。缓存命中的下降可能会降低性能。</p>
<p>某些语言可以使用压缩指针来解决性能问题，例如Java。</p>
<h4 id="条件构造代替IT块"><a href="#条件构造代替IT块" class="headerlink" title="条件构造代替IT块"></a>条件构造代替IT块</h4><p>IT块是T32的一个有用特性，可以实现避免对未执行指令周围进行短程前向分支的高效序列。然而，它们有时对硬件的高效处理具有一定困难。A64移除了这些块，并用条件指令（如CSEL或条件选择和CINC或条件递增）替换它们。这些条件构造更直观和更容易处理，无需特殊情况。</p>
<h4 id="移位和旋转行为更直观"><a href="#移位和旋转行为更直观" class="headerlink" title="移位和旋转行为更直观"></a>移位和旋转行为更直观</h4><p>A32或T32的移位和旋转行为并不总是与高级语言预期的行为相匹配。</p>
<p>ARMv7提供了一个可用于数据处理指令的位移器。然而，指定移位类型和移位量需要一定数量的操作码位，这些位可以在其他地方使用。</p>
<p>因此，A64指令删除了很少使用的选项，并添加了新的显式指令来执行更复杂的移位操作。</p>
<h4 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h4><p>在静态和动态生成常见算术函数的代码时，A32和T32通常需要不同的指令或指令序列。这是为了处理不同的数据类型。A64中这些操作更加一致，因此更容易生成在不同大小数据类型上进行简单操作的常见序列。</p>
<p>例如，在T32中，相同的指令可以具有不同的编码，具体取决于使用的寄存器（低寄存器还是高寄存器）。</p>
<p>A64指令集编码更加规则和合理。因此，与T32相比，A64汇编器通常需要更少的代码行数。</p>
<h4 id="固定长度指令"><a href="#固定长度指令" class="headerlink" title="固定长度指令"></a>固定长度指令</h4><p>所有A64指令的长度都相同，而T32是一种可变长度指令集。这使得管理和跟踪生成的代码序列更容易，特别是对动态代码生成器有影响。</p>
<h4 id="三个操作数更好地映射"><a href="#三个操作数更好地映射" class="headerlink" title="三个操作数更好地映射"></a>三个操作数更好地映射</h4><p>A32通常保留了用于数据处理操作的真正的三个操作数结构。而T32则包含大量的双操作数指令格式，这在生成代码时稍微不够灵活。A64坚持使用一致的三个操作数语法，进一步增加了指令集的规则性和统一性，有利于编译器。</p>
<h3 id="C-C-inline-assembly"><a href="#C-C-inline-assembly" class="headerlink" title="C&#x2F;C++ inline assembly"></a>C&#x2F;C++ inline assembly</h3><p>在C和C++中，你可以使用<code>asm</code>关键字来包含内联汇编代码。它允许你直接在C或C++函数中嵌入汇编代码。以下是一个示例：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> j)</span> &#123;</span><br><span class="line">  <span class="type">int</span> res = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">asm</span> (</span><br><span class="line">    <span class="string">&quot;ADD %w[result], %w[input_i], %w[input_j]&quot;</span></span><br><span class="line">    : [result] <span class="string">&quot;=r&quot;</span> (res)</span><br><span class="line">    : [input_i] <span class="string">&quot;r&quot;</span> (i), [input_j] <span class="string">&quot;r&quot;</span> (j)</span><br><span class="line">  );</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  <span class="type">int</span> a = <span class="number">1</span>;</span><br><span class="line">  <span class="type">int</span> b = <span class="number">2</span>;</span><br><span class="line">  <span class="type">int</span> c = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">  c = add(a, b);</span><br><span class="line">  </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Result of %d + %d = %d\n&quot;</span>, a, b, c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>asm</code>内联汇编语句的一般形式如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">asm</span>(code [: output_operand_list [: input_operand_list [: clobber_list]]]);</span><br></pre></td></tr></table></figure>

<p>以下是各个组成部分的说明：</p>
<ul>
<li><code>code</code>表示汇编代码本身。在示例中，它是<code>&quot;ADD %[result], %[input_i], %[input_j]&quot;</code>。</li>
<li><code>output_operand_list</code>是一个可选的以逗号分隔的输出操作数列表。每个操作数由方括号中的符号名称、约束字符串和括号中的C表达式组成。</li>
<li><code>input_operand_list</code>是一个可选的以逗号分隔的输入操作数列表。输入操作数使用与输出操作数相同的语法。</li>
<li><code>clobber_list</code>是一个可选的被破坏的寄存器或其他值的列表。</li>
</ul>
<p>当在C&#x2F;C++和汇编代码之间调用函数时，你必须遵循AAPCS64规则。</p>
<p>更多信息，请参考：<a target="_blank" rel="noopener" href="https://gcc.gnu.org/onlinedocs/gcc/Using-Assembly-Language-with-C.html#Using-Assembly-Language-with-C">https://gcc.gnu.org/onlinedocs/gcc/Using-Assembly-Language-with-C.html#Using-Assembly-Language-with-C</a>。</p>
<h1 id="The-A64-instruction-set"><a href="#The-A64-instruction-set" class="headerlink" title="The A64 instruction set"></a>The A64 instruction set</h1><p>尽管大多数应用级程序员在日常工作中不需要频繁编写汇编代码，但在某些情况下，了解汇编语言仍然具有重要价值。汇编代码在需要高度优化的情况下特别有用，例如编写编译器或使用C等高级语言无法直接访问的低级特性时。</p>
<p>在开发引导代码、设备驱动程序或操作系统时，可能需要使用汇编代码。这些领域通常需要对硬件有精细控制，并要求代码执行效率高。在这些情况下，使用汇编语言编写特定代码部分可以提高性能，并提供对硬件资源的低级访问能力。</p>
<p>此外，在调试C程序时，理解汇编代码变得至关重要。分析汇编指令与相应的C语句之间的映射有助于识别问题并优化代码。能够阅读汇编代码可以增强程序员理解和排查复杂软件行为的能力。</p>
<p>虽然汇编语言对大多数程序员来说不是主要工具，但在性能、低级控制和调试效率至关重要的专门领域中，汇编语言的重要性凸显出来。</p>
<h2 id="Instruction-mnemonics-指令助记符"><a href="#Instruction-mnemonics-指令助记符" class="headerlink" title="Instruction mnemonics &#x2F; 指令助记符"></a>Instruction mnemonics &#x2F; 指令助记符</h2><p>A64汇编语言中使用了指令助记符的重载，根据操作数寄存器名称的不同形式来区分不同的指令。例如，下面的ADD指令具有不同的编码，但您只需要记住一个助记符，汇编器会根据操作数自动选择正确的编码。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ADD W0, W1, W2             // 添加32位寄存器</span><br><span class="line"></span><br><span class="line">ADD X0, X1, X2             // 添加64位寄存器</span><br><span class="line"></span><br><span class="line">ADD X0, X1, W2, SXTW       // 将符号扩展的32位寄存器添加到64位扩展寄存器</span><br><span class="line"></span><br><span class="line">ADD X0, X1, #42            // 添加立即数到64位寄存器</span><br><span class="line"></span><br><span class="line">ADD V0.8H, V1.8H, V2.8H    // NEON中的16位逐个通道添加，共8个通道</span><br></pre></td></tr></table></figure>

<h2 id="Data-processing-instructions-数据处理指令"><a href="#Data-processing-instructions-数据处理指令" class="headerlink" title="Data processing instructions &#x2F; 数据处理指令"></a>Data processing instructions &#x2F; 数据处理指令</h2><p>数据处理指令是处理器的基本算术和逻辑操作，操作的对象是通用寄存器中的值，或者一个寄存器和一个立即值。乘法和除法指令可以看作是这些指令的特殊情况。</p>
<p>数据处理指令大多使用一个目标寄存器和两个源操作数。一般格式可以认为是指令，后面是操作数，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Instruction Rd, Rn, Operand2</span><br></pre></td></tr></table></figure>

<p>第二个操作数可以是一个寄存器、一个修改后的寄存器或一个立即值。使用 R 表示它可以是 X 寄存器或 W 寄存器。</p>
<p>数据处理操作包括：</p>
<ul>
<li>算术和逻辑操作。</li>
<li>移动和移位操作。</li>
<li>符号扩展和零扩展指令。</li>
<li>位和位域操作。</li>
<li>有条件的比较和数据处理操作。</li>
</ul>
<h2 id="Memory-access-instructions-访存指令"><a href="#Memory-access-instructions-访存指令" class="headerlink" title="Memory access instructions &#x2F; 访存指令"></a>Memory access instructions &#x2F; 访存指令</h2><p>和之前的所有ARM处理器一样，ARMv8架构也是一种加载&#x2F;存储（Load&#x2F;Store）架构。这意味着没有数据处理指令直接在内存中操作数据。数据首先必须加载到寄存器中，进行修改，然后再存储到内存中。程序必须指定一个地址、要传输的数据大小以及一个源或目标寄存器。还有其他的加载和存储指令提供了进一步的选项，比如非临时的加载&#x2F;存储、加载&#x2F;存储互斥和获取&#x2F;释放。</p>
<p>内存指令可以以非对齐的方式访问普通内存（参见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Memory-Ordering?lang=en">内存排序</a>）。但这在独占访问、加载获取或存储释放变体中是不支持的。如果不希望进行非对齐访问，可以配置为出错。</p>
<h3 id="Specifying-the-address-for-a-Load-or-Store-instruction"><a href="#Specifying-the-address-for-a-Load-or-Store-instruction" class="headerlink" title="Specifying the address for a Load or Store instruction"></a>Specifying the address for a Load or Store instruction</h3><p>在A64中，用于加载（Load）或存储（Store）指令的地址指定方式与A32和T32类似。虽然存在一些额外的限制和新特性，但对于熟悉A32或T32的人来说，A64提供的地址指定方式应该不会让人感到意外。</p>
<p>在A64中，地址操作数的基础寄存器必须始终是一个X寄存器。然而，有几条指令支持零扩展（zero-extension）或符号扩展（sign-extension），以便可以将32位偏移量作为W寄存器提供。</p>
<h4 id="Offset-modes"><a href="#Offset-modes" class="headerlink" title="Offset modes"></a>Offset modes</h4><p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/The-A64-instruction-set/Memory-access-instructions/Specifying-the-address-for-a-Load-or-Store-instruction?lang=en">https://developer.arm.com/documentation/den0024/a/The-A64-instruction-set/Memory-access-instructions/Specifying-the-address-for-a-Load-or-Store-instruction?lang=en</a></p>
<h4 id="Index-modes"><a href="#Index-modes" class="headerlink" title="Index modes"></a>Index modes</h4><p>索引模式（Index modes）与偏移模式（Offset modes）类似，但它们还会更新基础寄存器。其语法与A32和T32相同，但操作的集合更为限制。通常，只能为索引模式提供立即偏移量（immediate offsets）。</p>
<p>索引模式有两个变体：前索引模式（pre-index modes）在访问内存之前应用偏移量，而后索引模式（post-index modes）在访问内存之后应用偏移量。</p>
<table>
<thead>
<tr>
<th>Example instruction</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>LDR X0, [X1, #8]!</td>
<td>Pre-index: Update X1 first (to X1 + #8), then load from the new address</td>
</tr>
<tr>
<td>LDR X0, [X1], #8</td>
<td>Post-index: Load from the unmodified address in X1 first, then update X1 (to X1 + #8)</td>
</tr>
<tr>
<td>STP X0, X1, [SP, #-16]!</td>
<td>Push X0 and X1 to the stack.</td>
</tr>
<tr>
<td>LDP X0, X1, [SP], #16</td>
<td>Pop X0 and X1 off the stack.</td>
</tr>
</tbody></table>
<p>These options map cleanly onto some common C operations:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A C example showing accesses that a compiler is likely to generate.</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">example_strcpy</span><span class="params">(<span class="type">char</span> * dst, <span class="type">const</span> <span class="type">char</span> * src)</span> </span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> c;</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">    c = *(src++);             <span class="comment">// LDRB W2, [X1], #1</span></span><br><span class="line">    *(dst++) = c;             <span class="comment">// STRB W2, [X0], #1</span></span><br><span class="line">    &#125; <span class="keyword">while</span> (c != <span class="string">&#x27;\0&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="PC-relative-modes-load-literal"><a href="#PC-relative-modes-load-literal" class="headerlink" title="PC-relative modes (load-literal)"></a>PC-relative modes (load-literal)</h4><p>A64引入了另一种专门用于访问<strong>字面池（literal pools）</strong>的寻址模式，称为PC相对模式（PC-relative modes）。字面池是嵌入在指令流中的数据块。这些池不会被执行，但可以通过PC相对内存地址从周围的代码中访问它们的数据。字面池通常用于编码无法适应简单的立即数移动指令的常量值。</p>
<p>在A32和T32中，PC可以像通用寄存器一样读取，因此只需将PC指定为基础寄存器即可访问字面池。</p>
<p>在A64中，PC通常是不可访问的，但是有一种特殊的寻址模式（仅适用于加载指令）可以访问PC相对地址。这种专用的寻址模式的范围比A32和T32中的PC相对加载要大得多，因此字面池可以被更稀疏地定位。</p>
<table>
<thead>
<tr>
<th>Example instruction</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>LDR W0, &lt;label&gt;</td>
<td>Load 4 bytes from &lt;label&gt; into W0</td>
</tr>
<tr>
<td>LDR X0, &lt;label&gt;</td>
<td>Load 8 bytes from &lt;label&gt; into X0</td>
</tr>
<tr>
<td>LDRSW X0, &lt;label&gt;</td>
<td>Load 4 bytes from &lt;label&gt; and sign-extend into X0</td>
</tr>
<tr>
<td>LDR S0, &lt;label&gt;</td>
<td>Load 4 bytes from &lt;label&gt; into S0</td>
</tr>
<tr>
<td>LDR D0, &lt;label&gt;</td>
<td>Load 8 bytes from &lt;label&gt; into D0</td>
</tr>
<tr>
<td>LDR Q0, &lt;label&gt;</td>
<td>Load 16 bytes from &lt;label&gt; into Q0</td>
</tr>
<tr>
<td>Note:</td>
<td></td>
</tr>
<tr>
<td>&lt;label&gt; must be 4-byte-aligned for all variants.</td>
<td></td>
</tr>
</tbody></table>
<h3 id="Unprivileged-access"><a href="#Unprivileged-access" class="headerlink" title="Unprivileged access"></a>Unprivileged access</h3><p>A64 LDTR和STTR指令执行非特权的加载（Load）或存储（Store）操作（请参阅ARMv8-A架构参考手册中的LDTR和STTR）：</p>
<ul>
<li>在EL0、EL2或EL3级别下，它们的行为类似于普通的加载或存储指令。</li>
<li>当在EL1级别下执行时，它们的行为类似于在EL0特权级别下执行。</li>
</ul>
<p>这些指令与A32 LDRT和STRT指令是等效的。</p>
<h3 id="Non-temporal-load-and-store-pair-非暂态（non-temporal）加载和存储"><a href="#Non-temporal-load-and-store-pair-非暂态（non-temporal）加载和存储" class="headerlink" title="Non-temporal load and store pair &#x2F; 非暂态（non-temporal）加载和存储"></a>Non-temporal load and store pair &#x2F; 非暂态（non-temporal）加载和存储</h3><p>在ARMv8架构中引入了非暂态（non-temporal）加载和存储的概念。这些概念体现在LDNP和STNP指令中，它们用于读取或写入一对寄存器值。同时，它们向内存系统发出提示，表明对该数据进行缓存是无益的。这个提示并不禁止内存系统的活动，比如地址的缓存、预加载或者聚集。然而，它表明进行缓存不太可能提高性能。一个典型的用例可能是流式数据处理，但需要注意的是，有效地使用这些指令需要针对具体微架构的特定方法。</p>
<p>非暂态加载和存储放宽了内存排序要求。在上述例子中，LDNP指令可能在前面的LDR指令之前执行，这可能导致从不确定的X0地址读取数据。<br>For example:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LDR X0, [X3]</span><br><span class="line">LDNP X2, X1, [X0]      // Xo may not be loaded when the instruction executes!</span><br></pre></td></tr></table></figure>
<p>为了纠正上述问题，需要使用显式的加载屏障：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LDR X0, [X3]</span><br><span class="line">DMB nshld</span><br><span class="line">LDNP X2, X1, [X0]</span><br></pre></td></tr></table></figure>
<p>通过引入加载屏障，可以确保在LDNP指令执行之前先加载X0的值，从而避免了不确定的读取。这样，非暂态加载和存储指令才能够在程序中被正确使用。</p>
<h3 id="Memory-access-atomicity"><a href="#Memory-access-atomicity" class="headerlink" title="Memory access atomicity"></a>Memory access atomicity</h3><p>对齐的内存访问使用单个通用寄存器可以保证原子性。使用对齐的内存地址进行的一对通用寄存器的加载对（load pair）和存储对（store pair）指令可以保证作为两个独立的原子访问。非对齐访问不是原子的，因为通常需要进行两次独立的访问。此外，浮点数和SIMD（单指令多数据）内存访问不能保证原子性。</p>
<h3 id="Memory-barrier-and-fence-instructions"><a href="#Memory-barrier-and-fence-instructions" class="headerlink" title="Memory barrier and fence instructions"></a>Memory barrier and fence instructions</h3><p>ARMv7和ARMv8都支持不同类型的内存屏障操作。这些操作在<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Memory-Ordering?lang=en">Memory Ordering</a>中有更详细的描述：</p>
<p>数据内存屏障（Data Memory Barrier，DMB）：在继续执行后续访问之前，强制使程序顺序中较早的所有内存访问对全局可见。</p>
<p>数据同步屏障（Data Synchronization Barrier，DSB）：在程序继续执行之前，完成所有待处理的加载和存储、缓存维护指令以及TLB维护指令。DSB的行为类似于DMB，但具有附加属性。</p>
<p>指令同步屏障（Instruction Synchronization Barrier，ISB）：该指令刷新CPU流水线和预取缓冲区，导致ISB之后的指令从缓存或内存中获取（或重新获取）。</p>
<p>ARMv8引入了单向栅栏（one-sided fences），这与Release Consistency模型相关。这些栅栏被称为Load-Acquire（LDAR）和Store-Release（STLR），它们是基于地址的同步原语（见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Memory-Ordering?lang=en">One-way barriers</a>）。这两个操作可以配对形成一个完整的栅栏。这些指令仅支持基址寄存器寻址，不支持偏移量或其他类型的索引寻址。</p>
<h3 id="Synchronization-primitives"><a href="#Synchronization-primitives" class="headerlink" title="Synchronization primitives"></a>Synchronization primitives</h3><p>ARMv7-A和ARMv8-A架构都支持独占内存访问。在A64中，这是通过Load&#x2F;Store exclusive（LDXR&#x2F;STXR）指令对实现的。</p>
<p>LDXR指令从内存地址加载一个值，并尝试在该地址上默默地获取独占锁。然后，Store-Exclusive指令只有在成功获取并持有锁时才会将新值写入该位置。LDXR&#x2F;STXR配对用于构建标准的同步原语，例如自旋锁。还提供了一对配对的LDXRP和STXRP指令，以允许原子更新跨越两个寄存器的位置。可用的选项包括字节、半字、字和双字。与Load Acquire&#x2F;Store Release配对一样，只支持基址寄存器寻址，没有任何偏移量。</p>
<p>CLREX指令用于清除监视器，但与ARMv7不同，异常的进入或返回也会清除监视器。监视器也可能被意外地清除，例如由于缓存逐出或与应用程序无直接关联的其他原因。在配对的LDXR和STXR指令之间，软件必须避免任何显式的内存访问、系统控制寄存器更新或缓存维护指令。</p>
<p>此外，还有一对独占的Load Acquire&#x2F;Store Release指令，称为LDAXR和STLXR。详见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/Multi-core-processors/Multi-processing-systems/Synchronization?lang=en">同步</a>部分。</p>
<h2 id="Flow-control"><a href="#Flow-control" class="headerlink" title="Flow control"></a>Flow control</h2><p>A64指令集提供了多种不同类型的分支指令（参见表<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/The-A64-instruction-set/Flow-control?lang=en">6.12</a>）。对于简单的相对分支，即从当前地址偏移的分支，使用B指令。<em>无条件的简单相对分支可以向前或向后分支到距离当前程序计数器位置最多128MB的位置</em>。<em>有条件的简单相对分支，在B后附加条件码，其范围较小，为±1MB</em>。</p>
<p>对于需要将返回地址存储在链接寄存器（X30）中的子程序调用，使用BL指令。它没有条件版本。<em>BL的行为类似于B指令，同时额外存储返回地址，即BL指令后一条指令的地址，到寄存器X30中</em>。</p>
<h2 id="System-control-and-other-instructions-系统控制和其他指令"><a href="#System-control-and-other-instructions-系统控制和其他指令" class="headerlink" title="System control and other instructions &#x2F; 系统控制和其他指令"></a>System control and other instructions &#x2F; 系统控制和其他指令</h2><p>A64指令集包含与以下内容相关的指令：</p>
<ul>
<li>异常处理。</li>
<li>系统寄存器访问。</li>
<li>调试。</li>
<li>提示指令，在许多系统中具有电源管理应用。</li>
</ul>
<h3 id="Exception-handling-instructions"><a href="#Exception-handling-instructions" class="headerlink" title="Exception handling instructions"></a>Exception handling instructions</h3><p>有三条异常处理指令，其目的是引发异常。这些指令用于调用在操作系统中运行在更高异常级别的代码（EL1），虚拟机监控程序（EL2）或安全监控程序（EL3）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SVC #imm16   // 监管者调用，允许应用程序调用内核（EL1）。</span><br><span class="line"></span><br><span class="line">HVC #imm16   // 虚拟机监控程序调用，允许操作系统代码调用虚拟机监控程序（EL2）。</span><br><span class="line"></span><br><span class="line">SMC #imm16   // 安全监控程序调用，允许操作系统或虚拟机监控程序调用安全监控程序（EL3）。</span><br></pre></td></tr></table></figure>
<p>立即值将在异常综合寄存器中提供给处理程序。这与ARMv7不同，ARMv7需要通过读取调用指令的操作码来确定立即值。详细信息请参阅<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/AArch64-Exception-Handling?lang=en">AArch64异常处理</a>。</p>
<p>要从异常返回，请使用ERET指令。此指令通过将SPSR_ELn复制到PSTATE并跳转到ELR_ELn中保存的返回地址来恢复处理器状态。</p>
<h1 id="ARM-64位架构的ABI"><a href="#ARM-64位架构的ABI" class="headerlink" title="ARM 64位架构的ABI"></a>ARM 64位架构的ABI</h1><p>ARM体系结构的应用二进制接口（ABI）规定了所有可执行的本机代码模块必须遵循的基本规则，以便它们可以正确地协同工作。这些基本规则还可以通过特定编程语言（例如C++）的附加规则进行补充。各个操作系统或执行环境（例如Linux）可能会指定额外的规则以满足其自身特定的要求，超出了ARM ABI规定的规则。</p>
<h2 id="AArch64过程调用标准中的寄存器使用"><a href="#AArch64过程调用标准中的寄存器使用" class="headerlink" title="AArch64过程调用标准中的寄存器使用"></a>AArch64过程调用标准中的寄存器使用</h2><h3 id="通用寄存器中的参数"><a href="#通用寄存器中的参数" class="headerlink" title="通用寄存器中的参数"></a>通用寄存器中的参数</h3><p>为了函数调用的目的，通用寄存器被分为四组：</p>
<h4 id="参数寄存器（X0-X7）"><a href="#参数寄存器（X0-X7）" class="headerlink" title="参数寄存器（X0-X7）"></a>参数寄存器（X0-X7）</h4><p>这些寄存器用于将参数传递给函数并返回结果。它们可以用作临时寄存器或调用者保存的寄存器变量，在函数内部和调用其他函数之间保存中间值。提供了8个寄存器用于传递参数，相比于AArch32，减少了将参数保存到堆栈的需要。</p>
<h4 id="调用者保存的临时寄存器（X9-X15）"><a href="#调用者保存的临时寄存器（X9-X15）" class="headerlink" title="调用者保存的临时寄存器（X9-X15）"></a>调用者保存的临时寄存器（X9-X15）</h4><p>如果调用者需要在调用其他函数之后保留这些寄存器中的值，调用者必须在自己的堆栈帧中保存受影响的寄存器。被调用的子程序可以修改这些寄存器，而无需在返回给调用者之前保存和恢复它们。</p>
<h4 id="被调用者保存的寄存器（X19-X29）"><a href="#被调用者保存的寄存器（X19-X29）" class="headerlink" title="被调用者保存的寄存器（X19-X29）"></a>被调用者保存的寄存器（X19-X29）</h4><p>这些寄存器在被调用者的帧中保存。被调用的子程序可以修改这些寄存器，只要在返回之前保存和恢复它们。</p>
<h4 id="具有特殊用途的寄存器（X8，X16-X18，X29，X30）"><a href="#具有特殊用途的寄存器（X8，X16-X18，X29，X30）" class="headerlink" title="具有特殊用途的寄存器（X8，X16-X18，X29，X30）"></a>具有特殊用途的寄存器（X8，X16-X18，X29，X30）</h4><ul>
<li><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/The-ABI-for-ARM-64-bit-Architecture/Register-use-in-the-AArch64-Procedure-Call-Standard/Indirect-result-location?lang=en">X8</a>是间接结果寄存器。它用于传递间接结果的地址位置，例如函数返回大型结构体的情况。</li>
<li>X16和X17是IP0和IP1，函数内部调用的临时寄存器。这些寄存器可以由调用细节和类似代码使用，或者作为子例程调用之间的临时寄存器用于中间值。在函数中可以更改它们，但在返回给调用者之前需要保存和恢复。</li>
<li>X18是平台寄存器，保留用于平台ABI的使用。对于不分配特殊含义的平台来说，这是一个额外的临时寄存器。</li>
<li><strong>X29是帧指针寄存器（FP）</strong>。<br>X29寄存器是ARM64（AArch64）体系结构中的一个特殊寄存器，也被称为Frame Pointer（FP，帧指针）。在函数调用和栈操作中，X29寄存器用于指向当前函数的栈帧（stack frame）的起始位置。</li>
</ul>
<p>栈帧是用于管理函数调用和局部变量的内存区域。当一个函数被调用时，当前函数的栈帧会被创建，并且X29寄存器会被设置为指向栈帧的起始位置。栈帧通常包括函数的参数、局部变量、返回地址和其他与函数执行相关的数据。</p>
<p>X29寄存器在函数执行过程中保持不变，直到函数返回。在函数返回时，栈帧会被销毁，X29寄存器会被恢复为之前的值，以便返回到调用函数的位置。</p>
<p>除了作为帧指针的功能外，X29寄存器也可以用作通用寄存器，存储其他临时数据。</p>
<p>需要注意的是，X29寄存器在ARM64体系结构中具有固定的寄存器编号。在编程中，可以使用X29寄存器来访问和修改栈帧中的数据。</p>
<ul>
<li><strong>X30是链接寄存器（LR）</strong>。</li>
</ul>
<h1 id="AArch64-Exception-Handling"><a href="#AArch64-Exception-Handling" class="headerlink" title="AArch64 Exception Handling"></a>AArch64 Exception Handling</h1><p>严格来说，中断是指中断软件执行流程的事件。然而，在ARM术语中，这实际上被称为异常（Exception）。异常是指需要特权软件（异常处理程序）采取某些操作以确保系统正常运行的条件或系统事件。每种异常类型都有一个关联的异常处理程序。一旦异常被处理，特权软件会准备内核继续执行之前发生异常的操作。</p>
<p>以下是存在的异常类型：</p>
<h4 id="Interrupts-中断"><a href="#Interrupts-中断" class="headerlink" title="Interrupts &#x2F; 中断"></a>Interrupts &#x2F; 中断</h4><p>有两种类型的中断，称为IRQ和FIQ。</p>
<p>FIQ比IRQ具有更高的优先级。这两种异常类型通常与内核上的输入引脚相关联。外部硬件会断言一个中断请求线，当当前指令执行完成时（尽管一些指令，例如可以加载多个值的指令，可以被中断），相应的异常类型会被触发，前提是中断未被禁用。</p>
<p>Both FIQ and IRQ are physical signals to the core, and when asserted, 如果当前该中断启用，则内核会执行相应的异常处理。在几乎所有系统上，各种中断源使用中断控制器连接。中断控制器进行仲裁和优先级排序，并提供一个串行的单一信号，然后将其连接到内核的FIQ或IRQ信号。有关更多信息，请参阅通用中断控制器。</p>
<p>由于IRQ和FIQ中断的发生与内核在任何给定时间执行的软件没有直接关系，因此它们被归类为异步异常。</p>
<h4 id="Reset"><a href="#Reset" class="headerlink" title="Reset"></a>Reset</h4><p>重置（Reset）被视为最高实现的异常等级的特殊向量。这是ARM处理器在引发异常时跳转到的指令位置。该向量使用实现定义的地址。RVBAR_ELn包含此复位向量地址，其中n是最高实现的异常等级的编号。</p>
<p>所有内核都有一个复位输入，并在复位后立即执行复位异常。它是最高优先级的异常，无法屏蔽。此异常用于在上电后对内核进行初始化的代码执行。</p>
<h4 id="生成异常的指令"><a href="#生成异常的指令" class="headerlink" title="生成异常的指令"></a>生成异常的指令</h4><p>执行某些指令可能会生成异常。这些指令通常用于请求在更高特权级别下运行的软件提供服务：</p>
<ul>
<li>监控模式调用（Supervisor Call，SVC）指令使用户模式程序能够请求操作系统服务。</li>
<li>Hypervisor调用（Hypervisor Call，HVC）指令使客户操作系统能够请求hypervisor服务。</li>
<li>安全监控调用（Secure monitor Call，SMC）指令使正常世界能够请求安全世界服务。</li>
</ul>
<p>如果由于EL0处的指令获取而生成的异常，则将其视为对EL1的异常，除非在非安全状态下设置了HCR_EL2.TGE位，否则将其视为对EL2的异常。</p>
<p>如果异常是由于在其他任何异常等级处的指令获取而生成的，则异常等级保持不变。</p>
<h2 id="Exception-handling-registers"><a href="#Exception-handling-registers" class="headerlink" title="Exception handling registers"></a>Exception handling registers</h2><p>如果发生异常，PSTATE信息将保存在Saved Program Status Register（SPSR_ELn）中，其中SPSR_ELn存在于SPSR_EL3、SPSR_EL2和SPSR_EL1。</p>
<p>如果发生异常，处理器会将当前的处理状态信息保存到相应的SPSR_ELn寄存器中。SPSR_EL3用于保存EL3的状态信息，SPSR_EL2用于保存EL2的状态信息，SPSR_EL1用于保存EL1的状态信息。</p>
<p>这些寄存器保存了执行异常之前的处理器状态，包括程序状态寄存器（PSTATE）的值，如处理器模式、中断使能状态、条件标志等。通过保存当前状态，处理器可以在处理完异常后恢复到发生异常之前的状态，以便顺利继续执行。</p>
<p>SPSel字段选择当前异常等级的堆栈指针（Stack Pointer）或SP_EL0是否应该被使用。除EL0之外的任何异常等级都可以进行此选择。这将在本章后面进行讨论。</p>
<p>在发生引发异常的事件时，处理器硬件会自动执行某些操作。SPSR_ELn（其中n是发生异常的异常等级）将被更新，用于存储在异常结束时正确返回所需的PSTATE信息。PSTATE会更新以反映新的处理器状态（这可能意味着提升异常等级，也可能保持不变）。要在异常结束时使用的返回地址将存储在ELR_ELn中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> flow in EL0                           flow in EL1</span><br><span class="line"></span><br><span class="line">Exception occurs</span><br><span class="line">            PC -&gt;ELR_EL1</span><br><span class="line">            PSTATE -&gt;SPSR_EL1</span><br><span class="line">                                    ExceptionHandler</span><br><span class="line">            SPSR_EL1 -&gt; PSTATE</span><br><span class="line">            ELR_EL1 -&gt; PC</span><br></pre></td></tr></table></figure>

<p>请记住，寄存器名称中的_ELn后缀表示在不同的异常等级存在多个副本。例如，SPSR_EL1是与SPSR_EL2不同的物理寄存器。此外，在同步或SError异常的情况下，ESR_ELn还会更新为指示异常原因的值。</p>
<p>处理器需要通过软件告知何时从异常返回。这是通过执行ERET指令来完成的。该指令从SPSR_ELn中恢复先前的异常前PSTATE，并通过从ELR_ELn中恢复PC将程序执行返回到原始位置。</p>
<p>我们已经了解了SPSR如何记录异常返回所需的状态信息。现在我们来看一下用于存储程序地址信息的链接寄存器。架构为函数调用和异常返回提供了单独的链接寄存器。</p>
<p>正如我们在A64指令集中看到的那样，寄存器X30与RET指令一起用于从子程序返回。每当执行带链接的分支指令（BL或BLR）时，其值都会更新为要返回的指令的地址。</p>
<p>ELR_ELn寄存器用于存储异常的返回地址。该寄存器中的值（实际上是多个寄存器，正如我们所见）在进入异常时会自动写入，并作为执行ERET指令返回异常的效果之一写入PC。</p>
<p>注意：<br>当从异常返回时，如果SPSR中的值与系统寄存器的设置发生冲突，您将会看到错误。</p>
<p>ELR_ELn包含首选用于特定异常类型的返回地址。对于某些异常，这是生成异常的指令之后的下一条指令的地址。例如，当执行SVC（系统调用）指令时，我们只希望返回到应用程序中的下一条指令。在其他情况下，我们可能希望重新执行生成异常的指令。</p>
<p>对于异步异常，ELR_ELn指向由于接收中断而尚未执行或完全执行的第一条指令的地址。处理器代码可以修改ELR_En，例如，如果需要在中止同步异常后返回到指令之后。ARMv8-A模型比ARMv7-A中使用的模型要简单得多，因为出于向后兼容的原因，在从某些类型的异常返回时，需要从链接寄存器值中减去4或8。</p>
<p>除了SPSR和ELR寄存器之外，每个异常等级都有自己专用的堆栈指针寄存器。它们被命名为SP_EL0、SP_EL1、SP_EL2和SP_EL3。这些寄存器用于指向专用堆栈，例如，可用于存储由异常处理程序破坏的寄存器，以便在返回到原始代码之前将它们恢复到原始值。</p>
<p>处理器代码可以从使用SP_ELn切换到SP_EL0。例如，可能是SP_EL1指向保存了内核始终保证有效的小型堆栈的内存区域。而SP_EL0可能指向一个更大的内核任务堆栈，但不能保证免受溢出的影响。通过写入[SPSel]位来控制此切换，如下面的代码所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MSR SPSel, #0  // 切换到SP_EL0</span><br><span class="line">MSR SPSel, #1  // 切换到SP_ELn</span><br></pre></td></tr></table></figure>

<h2 id="Synchronous-and-asynchronous-exceptions-同步和异步异常"><a href="#Synchronous-and-asynchronous-exceptions-同步和异步异常" class="headerlink" title="Synchronous and asynchronous exceptions &#x2F; 同步和异步异常"></a>Synchronous and asynchronous exceptions &#x2F; 同步和异步异常</h2><p>在AArch64架构中，异常可以是同步的或异步的。如果异常是由执行或尝试执行指令流而产生的，并且返回地址提供了引发异常的指令的详细信息，那么该异常被称为同步异常。而异步异常不是通过执行指令而生成的，返回地址可能并不总是提供引发异常的详细信息。</p>
<p>异步异常的来源包括IRQ（普通优先级中断）、FIQ（快速中断）或SError（系统错误）。系统错误有多种可能的原因，其中最常见的是异步数据中止（例如，由缓存行向外部内存写回脏数据而触发的中止）。</p>
<p>同步异常有多种来源：</p>
<ul>
<li>来自MMU的指令中止。例如，通过从标记为”Execute Never”的内存位置读取指令。</li>
<li>来自MMU的数据中止。例如，权限失败或对齐检查。</li>
<li>SP和PC对齐检查。</li>
<li>同步外部中止。例如，在读取转换表时发生中止。</li>
<li>未分配的指令。</li>
<li>调试异常。</li>
</ul>
<h3 id="Synchronous-aborts-同步中止"><a href="#Synchronous-aborts-同步中止" class="headerlink" title="Synchronous aborts &#x2F; 同步中止"></a>Synchronous aborts &#x2F; 同步中止</h3><p>同步异常可能由多种原因引起：</p>
<ul>
<li>来自MMU的中止。例如，权限失败或被标记为访问标志错误的内存区域。</li>
<li>SP和PC对齐检查。</li>
<li>未分配的指令。</li>
<li>服务调用（SVC、SMC和HVC）。</li>
</ul>
<p>这些异常可能是操作系统正常运行的一部分。例如，在Linux中，当一个任务希望请求分配一个新的内存页面时，通过MMU中止机制(abort mechanism)来处理这个请求。</p>
<h3 id="Handling-synchronous-exceptions"><a href="#Handling-synchronous-exceptions" class="headerlink" title="Handling synchronous exceptions"></a>Handling synchronous exceptions</h3><p>为了向异常处理程序提供有关同步异常原因的信息，提供了一些寄存器。异常综合症寄存器(Exception Syndrome Register) (ESR_ELn) 提供有关异常原因的信息。故障地址寄存器（FAR_ELn）保存了所有同步指令和数据中止以及对齐错误的故障虚拟地址。</p>
<p>异常链接寄存器（ELR_ELn）保存导致数据访问中止的指令地址（对于数据中止）。这通常在发生内存故障后更新，但在其他情况下也可能被设置，例如通过跳转到一个不对齐的地址。</p>
<p>对于实现EL2（虚拟化监控器）或EL3（安全内核）的系统，同步异常通常在当前或更高的异常级别中进行处理。异步异常（如果需要）可以被路由到更高的异常级别，由虚拟化监控器或安全内核处理。SCR_EL3寄存器指定了应将哪些异常路由到EL3，类似地，HCR_EL2指定了应将哪些异常路由到EL2。有单独的位允许对IRQ、FIQ和SError的路由进行个别控制。</p>
<h3 id="System-calls-系统调用"><a href="#System-calls-系统调用" class="headerlink" title="System calls &#x2F; 系统调用"></a>System calls &#x2F; 系统调用</h3><p>某些指令或系统功能只能在特定的异常级别下执行。如果在较低的异常级别下运行的代码需要执行特权操作，例如应用程序代码请求内核功能。一种方法是使用SVC指令。这允许应用程序生成一个异常。参数可以通过寄存器传递，也可以在系统调用中进行编码。</p>
<h3 id="Unallocated-instructions-未分配的指令"><a href="#Unallocated-instructions-未分配的指令" class="headerlink" title="Unallocated instructions &#x2F; 未分配的指令"></a>Unallocated instructions &#x2F; 未分配的指令</h3><p>在AArch64中，未分配的指令会引发同步中止异常。当处理器执行以下情况之一时，会生成此异常类型：</p>
<ul>
<li>未分配的指令操作码。</li>
<li>要求比当前异常级别更高特权级别的指令。</li>
<li>已禁用的指令。</li>
<li>当设置了PSTATE.IL字段时的任何指令。</li>
</ul>
<h3 id="The-Exception-Syndrome-Register"><a href="#The-Exception-Syndrome-Register" class="headerlink" title="The Exception Syndrome Register"></a>The Exception Syndrome Register</h3><p>异常综合症寄存器（ESR_ELn）包含的信息可以帮助异常处理程序确定异常的原因。它仅针对同步异常和SError进行更新。对于IRQ或FIQ，它不会更新，因为这些中断处理程序通常从通用中断控制器（GIC）的寄存器中获取状态信息。（参见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/AArch64-Exception-Handling/The-Generic-Interrupt-Controller?lang=en">通用中断控制器</a>。）该寄存器的位编码如下：</p>
<ul>
<li>ESR_ELn的位[31:26]指示异常类别，使处理程序能够区分各种可能的异常原因（例如，未分配的指令、来自MCR&#x2F;MRC到CP15的异常、浮点操作异常、执行的SVC、HVC或SMC、数据中止和对齐异常，见<a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/ddi0595/2021-03/AArch64-Registers/ESR-EL3--Exception-Syndrome-Register--EL3-">EC</a>。<ul>
<li>0b100100 &#x3D;&#x3D;&gt;&gt; Data Abort</li>
<li>0b100100 &#x3D;&#x3D;&gt;&gt; Instruction Abort (Used for MMU faults generated by instruction accesses)</li>
</ul>
</li>
</ul>
<p>Used for MMU faults generated by data accesses, alignment faults other than those caused by Stack Pointer misalignment, and synchronous External aborts, including synchronous parity or ECC errors. Not used for debug-related exceptions.</p>
<ul>
<li>位[25]指示被捕获指令的长度（对于16位指令为0，对于32位指令为1），并且对某些异常类别也会设置。</li>
<li>位[24:0]形成指令特定综合症（ISS）字段，其中包含特定于该异常类型的信息。例如，当执行系统调用指令（SVC、HVC或SMC）时，该字段包含与操作码相关联的立即数值，如对于<code>SVC 0x123456</code>，该字段包含0x123456。</li>
</ul>
<h2 id="AArch64异常向量表"><a href="#AArch64异常向量表" class="headerlink" title="AArch64异常向量表"></a>AArch64异常向量表</h2><p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/AArch64-Exception-Handling/AArch64-exception-table?lang=en">AArch64异常向量表</a>是存储异常处理程序代码的内存位置，用于处理发生的异常。在ARM架构中，异常向量表被存储在一个称为异常向量表的表中。每个异常级别都有自己的向量表，即EL3、EL2和EL1各有一个。该表包含要执行的指令，而不是一组地址。各个异常的向量位于距离表开始处的固定偏移量位置。每个表基地址的虚拟地址由向量基地址寄存器VBAR_EL3、VBAR_EL2和VBAR_EL1设置。</p>
<p>向量表中的每个条目长度为16条指令。与ARMv7相比，这本身就代表了一个重要的变化，因为ARMv7的每个条目长度为4字节。ARMv7向量表的这种间隔意味着每个条目几乎总是某种形式的分支，指向内存中实际的异常处理程序。在AArch64中，向量之间的间隔更大，因此顶级处理程序可以直接编写在向量表中。</p>
<h2 id="Interrupt-handling"><a href="#Interrupt-handling" class="headerlink" title="Interrupt handling"></a>Interrupt handling</h2><p>在ARM中，通常使用”interrupt”来表示中断信号。在ARM A-profile和R-profile处理器上，这意味着外部的IRQ或FIQ中断信号。架构没有规定这些信号如何使用。FIQ通常用于保留安全中断源。在早期的架构版本中，FIQ和IRQ用于表示高优先级和标准优先级的中断，但在ARMv8-A中不再适用这种情况。</p>
<p>当处理器执行到AArch64执行状态时，所有的PSTATE中断屏蔽位都会自动设置。这意味着进一步的异常被禁用。如果软件需要支持嵌套异常，例如允许更高优先级的中断打断低优先级源的处理，那么软件需要显式地重新启用中断。</p>
<h2 id="GIC"><a href="#GIC" class="headerlink" title="GIC"></a>GIC</h2><p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/AArch64-Exception-Handling/The-Generic-Interrupt-Controller?lang=en">GIC</a>架构提供了寄存器，用于管理中断源和行为，并在多核系统中将中断路由到各个内核。它使软件能够屏蔽、使能和禁用来自各个源的中断，对各个源进行硬件优先级排序，并生成软件中断。GIC接受在系统级别被触发的中断，并将其传递给每个连接的内核，可能导致触发IRQ或FIQ异常。</p>
<p>从软件的角度来看，GIC具有两个主要的功能块：</p>
<p>分配器（Distributor）<br>连接系统中的所有中断源。分配器具有用于控制单个中断属性的寄存器，例如优先级、状态、安全性、路由信息和使能状态。分配器通过连接的CPU接口确定要转发给内核的中断。</p>
<p>CPU接口（CPU Interface）<br>内核接收中断的接口。CPU接口包含用于屏蔽、识别和控制转发到该内核的中断状态的寄存器。系统中的每个内核都有一个独立的CPU接口。</p>
<p>中断在软件中通过一个称为中断ID的编号来进行标识。中断ID唯一对应一个中断源。软件可以使用中断ID来识别中断源，并调用相应的处理程序来处理中断。实际呈现给软件的确切中断ID由系统设计确定，</p>
<h3 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h3><p>在分配器中，软件必须配置每个中断的优先级、目标、安全性和使能状态。然后，通过控制寄存器（GICD_CTLR）启用分配器。对于每个CPU接口，软件必须设置优先级掩码和抢占设置。</p>
<p>每个CPU接口模块本身也必须通过其控制寄存器（GICD_CTLR）进行启用。这样可以准备GIC将中断传递给内核</p>
<h3 id="Interrupt-handling-1"><a href="#Interrupt-handling-1" class="headerlink" title="Interrupt handling"></a>Interrupt handling</h3><p>当内核接收到中断时，它会跳转到从向量表获取的顶级中断向量，并开始执行。</p>
<p>顶级中断处理程序从CPU接口模块读取中断确认寄存器以获取中断ID。</p>
<p>除了返回中断ID外，读取操作还会将中断标记为在分配器中处于活动状态。一旦知道中断ID（标识中断源），顶级处理程序现在可以调度一个特定于设备的处理程序来处理中断。</p>
<p>当设备特定的处理程序执行完成后，顶级处理程序将相同的中断ID写入CPU接口模块中的结束中断（EoI）寄存器，表示中断处理结束。</p>
<p>除了取消活动状态，使最终中断状态变为非活动状态或挂起状态（如果状态既是活动又是挂起），这还使得CPU接口能够将更多待处理的中断转发给内核。这完成了单个中断的处理过程。</p>
<p>在同一个内核上可能有多个等待处理的中断，但CPU接口一次只能发送一个中断。顶级中断处理程序可以重复上述序列，直到读取到特殊的中断ID值1023，表示在该内核上没有更多待处理的中断。这个特殊的中断ID称为虚假中断ID。</p>
<p>虚假中断ID是一个保留值，不能分配给系统中的任何设备。当顶级处理程序读取到虚假中断ID时，它可以完成执行，并准备内核继续执行中断之前的任务。</p>
<p>通用中断控制器（GIC）通常管理来自多个中断源的输入，并将它们分发给IRQ或FIQ请求。</p>
<h1 id="Multi-core-processors"><a href="#Multi-core-processors" class="headerlink" title="Multi-core processors"></a>Multi-core processors</h1><h2 id="Multi-core-processors-system"><a href="#Multi-core-processors-system" class="headerlink" title="Multi-core processors system"></a>Multi-core processors system</h2><h3 id="Timers"><a href="#Timers" class="headerlink" title="Timers"></a>Timers</h3><p>Symmetric Multi-Processing (SMP)<br>一个支持SMP(Symmetric Multi-Processing)操作的操作系统内核通常具有任务调度器，该调度器负责在多个任务之间对内核上的可用周期进行时间切片。它动态确定各个任务的优先级，并决定在每个内核上下一个要运行的任务。通常需要一个定时器，以便可以周期性地中断每个内核上的活动任务的执行，使调度器有机会选择不同的任务进行进展。</p>
<p>当所有内核都竞争同一个关键资源时可能会出现问题。每个内核运行调度器以决定它应该执行哪个任务，这发生在固定的时间间隔内。内核调度器代码需要使用一些共享数据，例如任务列表，可以通过互斥锁进行并发访问保护。互斥锁一次只允许一个内核有用地运行调度器。</p>
<p>系统定时器架构描述了一个常见的系统计数器，每个内核提供多达四个定时器通道。该系统计数器应具有固定的时钟频率。有安全和非安全的物理定时器以及两个用于虚拟化目的的定时器。每个通道都有一个比较器，该比较器与一个系统范围的64位计数进行比较，该计数从零开始递增。您可以配置定时器，使得当计数大于或等于编程的比较器值时生成中断。</p>
<p>尽管系统定时器必须具有固定的频率（通常以MHz为单位），但允许变化的更新粒度。这意味着您可以在每个时钟节拍上将计数增加1，也可以以较大的增量（例如10或100）进行增加，对应地以每10或100个周期的较低速率进行增加。这会产生相同的有效频率，但更新粒度较小。这对于实现较低的功耗状态非常有用。</p>
<p><code>CNTFRQ_EL0</code>寄存器报告了系统定时器的频率。</p>
<p>一个常见的误解是CNTFRQ_EL0由所有内核共享。它只是寄存器按内核独立，但仅从固件的角度来看：所有其他软件应在所有内核上看到该寄存器已初始化为正确的共享值。然而，计数器频率是全局的，对所有内核而言是固定的。CNTFRQ_EL0为引导ROM或固件提供了一种方便的方式来告知其他软件全局计数器频率是多少，但不控制任何硬件行为的方面。</p>
<p>CNTPCT_EL0寄存器报告当前的计数值。<code>CNTKCTL_EL1</code>控制EL0是否可以访问系统定时器。</p>
<p>要配置定时器，请完成以下步骤：</p>
<ol>
<li>将比较器值写入CNTP_CVAL_EL0，一个64位寄存器。</li>
<li>在CNTP_CTL_EL0中启用计数器和中断生成。</li>
<li>轮询CTP_CTL_EL0以报告EL0定时器中断的原始状态。</li>
</ol>
<p>您可以将系统定时器用作倒计时定时器。在这种情况下，所需的计数将写入32位的CNTP_TVAL_EL0寄存器。硬件将为您计算正确的CNTP_CVAL_EL0值。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/05/19/Arrch64%20MMU/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/05/19/Arrch64%20MMU/" class="post-title-link" itemprop="url">Arrch64 CPU Structure</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-19 20:45:50" itemprop="dateCreated datePublished" datetime="2023-05-19T20:45:50+08:00">2023-05-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:50" itemprop="dateModified" datetime="2023-07-30T18:15:50+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Qemu/" itemprop="url" rel="index"><span itemprop="name">Qemu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="The-Memory-Management-Unit"><a href="#The-Memory-Management-Unit" class="headerlink" title="The Memory Management Unit"></a>The Memory Management Unit</h1><p>内存管理单元（Memory Management Unit，MMU）的一个重要功能是使系统能够运行多个任务，这些任务作为独立的程序在它们自己的私有虚拟内存空间中运行。它们不需要知道系统的物理内存映射，也就是硬件实际使用的地址，或者其他可能同时执行的程序。</p>
<p>您可以为每个程序使用相同的虚拟内存地址空间。即使物理内存是碎片化的，您也可以使用连续的虚拟内存映射。这个虚拟地址空间与系统中实际的物理内存映射是分离的。您可以编写、编译和链接应用程序以在虚拟内存空间中运行。</p>
<p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/The-Memory-Management-Unit?lang=en#BABBEBII">图12.2</a>展示了一个示例系统，说明了内存的虚拟视图和物理视图。在单个系统中，不同的处理器和设备可能具有不同的虚拟和物理地址映射。操作系统会对MMU进行编程，以在这两个内存视图之间进行转换。</p>
<p>为了实现这一点，在虚拟内存系统中的硬件必须提供地址转换，即将处理器发出的虚拟地址转换为主内存中的物理地址。</p>
<p>虚拟地址是您、编译器和链接器在将代码放入内存时使用的地址。物理地址是实际硬件系统使用的地址。</p>
<p>MMU使用虚拟地址的最高有效位来索引翻译表中的条目，并确定正在访问的块。MMU将代码和数据的虚拟地址转换为实际系统中的物理地址。这种转换是在硬件中自动进行的，并且对应用程序是透明的。除了地址转换之外，MMU还控制每个内存区域的内存访问权限、内存排序和缓存策略。</p>
<h2 id="The-Translation-Lookaside-Buffer"><a href="#The-Translation-Lookaside-Buffer" class="headerlink" title="The Translation Lookaside Buffer"></a>The Translation Lookaside Buffer</h2><p>Translation Lookaside Buffer (TLB)是MMU中最近访问的页面转换的高速缓存。对于处理器执行的每个内存访问，MMU都会检查TLB中是否缓存了相应的转换。如果请求的地址转换在TLB中命中，地址的转换结果将立即可用。</p>
<p>每个TLB条目通常不仅包含物理地址和虚拟地址，还包括诸如内存类型、缓存策略、访问权限、地址空间ID（ASID）和虚拟机ID（VMID）等属性。如果TLB中没有包含处理器发出的虚拟地址的有效转换，即TLB未命中，就会执行外部的转换表查找或遍历。MMU内的专用硬件使其能够读取内存中的转换表。新加载的转换结果可以被缓存到TLB中，以备后续使用，如果转换表的遍历过程不会导致页面错误。TLB的具体结构在不同的ARM处理器实现之间会有所不同。</p>
<p>如果操作系统修改了可能缓存在TLB中的转换条目，那么操作系统有责任使这些过时的TLB条目失效。</p>
<h2 id="Separation-of-kernel-and-application-Virtual-Address-spaces"><a href="#Separation-of-kernel-and-application-Virtual-Address-spaces" class="headerlink" title="Separation of kernel and application Virtual Address spaces"></a>Separation of kernel and application Virtual Address spaces</h2><p>操作系统通常会同时运行多个应用程序或任务。每个应用程序都有自己独特的转换表集合，并且内核在切换上下文时会从一个转换表切换到另一个。然而，大部分内存系统只被内核使用，并具有固定的虚拟到物理地址映射，其中转换表条目很少改变。ARMv8架构提供了一些功能来有效地处理这一要求。</p>
<p>转换表的基地址在Translation Table Base Registers (TTBR0_EL1)和(TTBR1_EL1)中指定。当VA的高位全为0时，选择TTBR0指向的转换表。当VA的高位全部设置为1时，选择TTBR1指向的转换表。您可以启用VA标记以排除检查过程中的前8位。</p>
<p>处理器从指令获取或数据访问的虚拟地址是64位。然而，在48位物理地址内存映射中，您必须同时映射上述两个定义的区域。</p>
<p>EL2和EL3都有一个TTBR0，但没有TTBR1。这意味着：</p>
<p>如果EL2正在使用AArch64，它只能使用范围为0x0至0x0000FFFF_FFFFFFFF的虚拟地址。</p>
<p>如果EL3正在使用AArch64，它只能使用范围为0x0至0x0000FFFF_FFFFFFFF的虚拟地址。</p>
<p><a target="_blank" rel="noopener" href="https://developer.arm.com/documentation/den0024/a/The-Memory-Management-Unit/Separation-of-kernel-and-application-Virtual-Address-spaces?lang=en#CDDFFEJB">图12.4</a>显示了内核空间如何映射到内存的最高有效区域，每个应用程序关联的虚拟地址空间映射到内存的最低有效区域。然而，这两者都映射到一个更小的物理地址空间。</p>
<p>TCR_EL1是转换控制寄存器，它定义了需要进行检查的最高有效位的确切数量。TCR_EL1包含了大小字段T0SZ[5:0]和T1SZ[5:0]。字段中的整数表示必须是全0或全1的最高有效位的数量。这些字段有指定的最小和最大值，这些值随着颗粒大小和起始表级别的不同而变化。因此，在所有系统中，您必须始终使用两个转换表，并且至少需要两个转换表。即使是一个没有操作系统的简单裸机系统，也需要一个包含错误条目的小型上层表。</p>
<h2 id="Context-switching-上下文切换"><a href="#Context-switching-上下文切换" class="headerlink" title="Context switching 上下文切换"></a>Context switching 上下文切换</h2><p>实现ARMv8-A架构的处理器通常用于运行具有许多并发应用程序或任务的复杂操作系统的系统中。每个进程在物理内存中都有自己独特的转换表。当一个应用程序启动时，操作系统会为其分配一组转换表条目，将应用程序使用的代码和数据映射到物理内存。这些表可以随后由内核进行修改，例如映射额外的空间，并在应用程序不再运行时被删除。</p>
<p>因此，内存系统中可能存在多个任务。内核调度程序定期将执行从一个任务转移至另一个任务。这被称为上下文切换，要求内核保存与进程关联的所有执行状态，并恢复要运行的进程的状态。内核还切换转换表条目到下一个要运行的进程的条目。当前未运行的任务的内存完全受到正在运行的任务的保护。</p>
<p>实际上需要保存和恢复的内容因不同操作系统而异，但通常进程上下文切换包括保存或恢复以下一些或全部元素：</p>
<ul>
<li>通用寄存器 X0-X30。</li>
<li>高级SIMD和浮点寄存器 V0-V31。</li>
<li>一些状态寄存器。</li>
<li>TTBR0_EL1 和 TTBR0。</li>
<li>线程进程ID（TPIDxxx）寄存器。</li>
<li>地址空间ID（ASID）。</li>
</ul>
<p>对于EL0和EL1，有两个转换表。TTBR0_EL1为虚拟地址空间底部（通常是应用程序空间）提供转换，而TTBR1_EL1覆盖虚拟地址空间的顶部（通常是内核空间）。这种分割意味着操作系统映射不必复制到每个任务的转换表中。</p>
<p>转换表条目包含一个非全局（nG）位。如果nG位设置为特定页面，则与特定任务或应用程序相关联。如果该位标记为0，则条目是全局的，适用于所有任务。</p>
<p>对于非全局条目，在更新TLB并将条目标记为非全局时，除了常规转换信息之外，还在TLB条目中存储一个值。该值称为地址空间ID（ASID），由操作系统分配给每个单独的任务。仅当当前ASID与存储在条目中的ASID匹配时，后续的TLB查找才与该条目匹配。这允许多个有效的TLB条目存在于标记为非全局的特定页面中，但具有不同的ASID值。换句话说，我们在上下文切换时不一定需要刷新TLB。</p>
<p>在AArch64中，ASID值可以指定为8位或16位的值，由TCR_EL1.AS位控制。当前ASID值在TTBR0_EL1或TTBR1_EL1中指定。TCR_EL1控制哪个TTBR持有ASID，但通常是TTBR0_EL1，因为它对应应用程序空间。</p>
<p>注意</p>
<ul>
<li>将当前ASID值存储在转换表寄存器中意味着您可以在一条指令中原子地修改转换表和ASID。与ARMv7-A架构相比，这简化了更改表和ASID的过程。</li>
</ul>
<p>此外，ARMv8-A架构提供了用于操作系统软件的线程ID寄存器。这些寄存器在硬件上没有特殊意义，通常由线程库用作每个线程数据的基指针。这通常称为线程本地存储（TLS）。例如，pthread库使用了这个特性，并包括以下寄存器：</p>
<ul>
<li>用户读写线程ID寄存器（TPIDR_EL0）。</li>
<li>用户只读线程ID寄存器（TPIDRRO_EL0）。</li>
<li>线程ID寄存器，仅特权访问（TPIDR_EL1）。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">        <span class="type">uint64_t</span> c14_cntfrq; <span class="comment">/* Counter Frequency register */</span></span><br><span class="line">        <span class="type">uint64_t</span> c14_cntkctl; <span class="comment">/* Timer Control register */</span></span><br><span class="line">        <span class="type">uint32_t</span> cnthctl_el2; <span class="comment">/* Counter/Timer Hyp Control register */</span></span><br><span class="line">        <span class="type">uint64_t</span> cntvoff_el2; <span class="comment">/* Counter Virtual Offset register */</span></span><br><span class="line">        ARMGenericTimer c14_timer[NUM_GTIMERS];</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        <span class="comment">/* Stores the architectural value of the counter *the last time it was</span></span><br><span class="line"><span class="comment">         * updated* by pmccntr_op_start. Accesses should always be surrounded</span></span><br><span class="line"><span class="comment">         * by pmccntr_op_start/pmccntr_op_finish to guarantee the latest</span></span><br><span class="line"><span class="comment">         * architecturally-correct value is being read/set.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">uint64_t</span> c15_ccnt;</span><br><span class="line">        <span class="comment">/* Stores the delta between the architectural value and the underlying</span></span><br><span class="line"><span class="comment">         * cycle count during normal operation. It is used to update c15_ccnt</span></span><br><span class="line"><span class="comment">         * to be the correct architectural value before accesses. During</span></span><br><span class="line"><span class="comment">         * accesses, c15_ccnt_delta contains the underlying count being used</span></span><br><span class="line"><span class="comment">         * for the access, after which it reverts to the delta value in</span></span><br><span class="line"><span class="comment">         * pmccntr_op_finish.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">uint64_t</span> c15_ccnt_delta;</span><br><span class="line">        <span class="type">uint64_t</span> c14_pmevcntr[<span class="number">31</span>];</span><br><span class="line">        <span class="type">uint64_t</span> c14_pmevcntr_delta[<span class="number">31</span>];</span><br><span class="line">        <span class="type">uint64_t</span> c14_pmevtyper[<span class="number">31</span>];</span><br><span class="line">        <span class="type">uint64_t</span> pmccfiltr_el0; <span class="comment">/* Performance Monitor Filter Register */</span></span><br><span class="line">    &#125; cp15;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/05/18/Qemu%20TCG%20IR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/05/18/Qemu%20TCG%20IR/" class="post-title-link" itemprop="url">Qemu TCG IR</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-18 20:46:50" itemprop="dateCreated datePublished" datetime="2023-05-18T20:46:50+08:00">2023-05-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:50" itemprop="dateModified" datetime="2023-07-30T18:15:50+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Qemu/" itemprop="url" rel="index"><span itemprop="name">Qemu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="TCG-Intermediate-Representation-TCG（Tiny-Code-Generator）中间表示"><a href="#TCG-Intermediate-Representation-TCG（Tiny-Code-Generator）中间表示" class="headerlink" title="TCG Intermediate Representation &#x2F; TCG（Tiny Code Generator）中间表示"></a>TCG Intermediate Representation &#x2F; TCG（Tiny Code Generator）中间表示</h1><h2 id="Introduction-介绍"><a href="#Introduction-介绍" class="headerlink" title="Introduction &#x2F; 介绍"></a>Introduction &#x2F; 介绍</h2><ul>
<li>TCG（Tiny Code Generator）最初是作为一个C编译器的通用后端而开始的。它经过简化后用于QEMU。</li>
<li>它还源于由Paul Brook编写的QOP代码生成器。</li>
</ul>
<h2 id="Definitions-定义"><a href="#Definitions-定义" class="headerlink" title="Definitions &#x2F; 定义"></a>Definitions &#x2F; 定义</h2><ul>
<li><p>TCG的<em>目标</em>是我们生成代码的架构。</p>
</li>
<li><p>它当然不同于QEMU的”目标”，QEMU的目标是被模拟的架构。</p>
</li>
<li><p>当TCG作为一个用于交叉编译的通用C后端开始时，假设TCG的目标可能与主机不同，尽管对于QEMU来说永远不会是这种情况。</p>
</li>
<li><p>在这个文档中，我们使用<em>guest</em>来指定我们正在模拟的架构；<em>target</em>始终指的是TCG的目标，也就是我们运行QEMU的机器。</p>
</li>
<li><p>具有<em>未定义行为</em>的操作可能导致崩溃。</p>
</li>
<li><p>具有<em>未指定行为</em>的操作不会崩溃。然而，结果可能是多种可能性之一，因此可能被视为<em>未定义的结果</em>。</p>
</li>
</ul>
<h2 id="Basic-Blocks-基本块"><a href="#Basic-Blocks-基本块" class="headerlink" title="Basic Blocks &#x2F; 基本块"></a>Basic Blocks &#x2F; 基本块</h2><ul>
<li><p>TCG的<em>基本块</em>是一个单入口、多出口的区域，对应于一系列指令，并以标签或任何跳转指令结尾。</p>
</li>
<li><p>TCG的<em>扩展基本块</em>是一个单入口、多出口的区域，对应于一系列指令，并以标签或无条件跳转指令结尾。</p>
</li>
<li><p>具体来说，扩展基本块是由零个或多个条件跳转指令的顺序连接起来的一系列基本块。</p>
</li>
</ul>
<h2 id="Operations-操作"><a href="#Operations-操作" class="headerlink" title="Operations &#x2F; 操作"></a>Operations &#x2F; 操作</h2><ul>
<li><p>在TCG中，TCG指令或操作（ops）作用于TCG变量，它们都具有强类型。</p>
</li>
<li><p>每个指令都有固定数量的输出变量操作数、输入变量操作数和常量操作数。</p>
</li>
<li><p>向量指令具有指定向量中元素大小的字段。需要注意的例外是调用指令，它具有可变数量的输出和输入。</p>
</li>
<li><p>在文本形式中，输出操作数通常首先出现，然后是输入操作数，最后是常量操作数。</p>
</li>
<li><p>指令名称中包含输出类型。</p>
</li>
<li><p>常量以’$’前缀表示。</p>
</li>
<li><p>例如：</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_i32 t0, t1, t2    /* (t0 &lt;- t1 + t2) */</span><br></pre></td></tr></table></figure>

<ul>
<li>上述示例中，<code>add_i32</code>表示整数相加的指令，<code>t0</code>是输出变量，<code>t1</code>和<code>t2</code>是输入变量。指令执行后，<code>t0</code>的值将等于<code>t1</code>和<code>t2</code>的和。</li>
</ul>
<h1 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h1><ul>
<li><p><code>TEMP_FIXED</code></p>
<p>There is one TCG <em>fixed global</em> variable, <code>cpu_env</code>, which is<br>live in all translation blocks, and holds a pointer to <code>CPUArchState</code>.<br>This variable is held in a host cpu register at all times in all<br>translation blocks.</p>
</li>
<li><p><code>TEMP_GLOBAL</code></p>
<p>A TCG <em>global</em> is a variable which is live in all translation blocks,<br>and corresponds to memory location that is within <code>CPUArchState</code>.<br>These may be specified as an offset from <code>cpu_env</code>, in which case<br>they are called <em>direct globals</em>, or may be specified as an offset<br>from a direct global, in which case they are called <em>indirect globals</em>.<br>Even indirect globals should still reference memory within<br><code>CPUArchState</code>.  All TCG globals are defined during<br><code>TCGCPUOps.initialize</code>, before any translation blocks are generated.</p>
</li>
<li><p><code>TEMP_CONST</code></p>
<p>A TCG <em>constant</em> is a variable which is live throughout the entire<br>translation block, and contains a constant value.  These variables<br>are allocated on demand during translation and are hashed so that<br>there is exactly one variable holding a given value.</p>
</li>
<li><p><code>TEMP_TB</code></p>
<p>A TCG <em>translation block temporary</em> is a variable which is live<br>throughout the entire translation block, but dies on any exit.<br>These temporaries are allocated explicitly during translation.</p>
</li>
<li><p><code>TEMP_EBB</code></p>
<p>A TCG <em>extended basic block temporary</em> is a variable which is live<br>throughout an extended basic block, but dies on any exit.<br>These temporaries are allocated explicitly during translation.</p>
</li>
</ul>
<h1 id="Types"><a href="#Types" class="headerlink" title="Types"></a>Types</h1><ul>
<li><p><code>TCG_TYPE_I32</code></p>
<p>A 32-bit integer.</p>
</li>
<li><p><code>TCG_TYPE_I64</code></p>
<p>A 64-bit integer.  For 32-bit hosts, such variables are split into a pair<br>of variables with <code>type=TCG_TYPE_I32</code> and <code>base_type=TCG_TYPE_I64</code>.<br>The <code>temp_subindex</code> for each indicates where it falls within the<br>host-endian representation.</p>
</li>
<li><p><code>TCG_TYPE_PTR</code></p>
<p>An alias for <code>TCG_TYPE_I32</code> or <code>TCG_TYPE_I64</code>, depending on the size<br>of a pointer for the host.</p>
</li>
<li><p><code>TCG_TYPE_REG</code></p>
<p>An alias for <code>TCG_TYPE_I32</code> or <code>TCG_TYPE_I64</code>, depending on the size<br>of the integer registers for the host.  This may be larger<br>than <code>TCG_TYPE_PTR</code> depending on the host ABI.</p>
</li>
<li><p><code>TCG_TYPE_I128</code></p>
<p>A 128-bit integer.  For all hosts, such variables are split into a number<br>of variables with <code>type=TCG_TYPE_REG</code> and <code>base_type=TCG_TYPE_I128</code>.<br>The <code>temp_subindex</code> for each indicates where it falls within the<br>host-endian representation.</p>
</li>
<li><p><code>TCG_TYPE_V64</code></p>
<p>A 64-bit vector.  This type is valid only if the TCG target<br>sets <code>TCG_TARGET_HAS_v64</code>.</p>
</li>
<li><p><code>TCG_TYPE_V128</code></p>
<p>A 128-bit vector.  This type is valid only if the TCG target<br>sets <code>TCG_TARGET_HAS_v128</code>.</p>
</li>
<li><p><code>TCG_TYPE_V256</code></p>
<p>A 256-bit vector.  This type is valid only if the TCG target<br>sets <code>TCG_TARGET_HAS_v256</code>.</p>
</li>
</ul>
<h2 id="Helpers-辅助函数"><a href="#Helpers-辅助函数" class="headerlink" title="Helpers &#x2F; 辅助函数"></a>Helpers &#x2F; 辅助函数</h2><ul>
<li><p>在TCG中，辅助函数（helpers）通过在特定于客户机的<code>helper.h</code>中注册，并处理生成<code>tcg_gen_helper_*</code>函数。</p>
</li>
<li><p>借助这些函数，可以调用接受i32、i64、i128或指针类型的函数。</p>
</li>
<li><p>默认情况下，在调用辅助函数之前，所有全局变量都会存储在其规范位置上。</p>
</li>
<li><p>默认情况下，辅助函数允许修改CPU状态（包括由tcg全局变量表示的状态）或引发异常。</p>
</li>
<li><p>可以使用以下函数修饰符来覆盖默认行为：</p>
<ul>
<li><p><code>TCG_CALL_NO_WRITE_GLOBALS</code></p>
<ul>
<li>辅助函数不会修改任何全局变量，但可能会读取它们。</li>
<li>在调用辅助函数之前，全局变量将保存在其规范位置，但在调用后不需要重新加载。</li>
</ul>
</li>
<li><p><code>TCG_CALL_NO_READ_GLOBALS</code></p>
<ul>
<li>辅助函数不会直接或通过异常读取全局变量。</li>
<li>在调用辅助函数之前，它们将不会保存到其规范位置。</li>
<li>这意味着它隐含了<code>TCG_CALL_NO_WRITE_GLOBALS</code>。</li>
</ul>
</li>
<li><p><code>TCG_CALL_NO_SIDE_EFFECTS</code></p>
<ul>
<li>如果没有使用返回值，则可以删除对辅助函数的调用。这意味着它不能修改任何CPU状态，也不能引发异常。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Code-Optimizations"><a href="#Code-Optimizations" class="headerlink" title="Code Optimizations"></a>Code Optimizations</h2><ul>
<li><p>在生成指令时，可以依赖至少以下优化：</p>
<ul>
<li>单个指令会进行简化，例如：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">and_i32 t0, t0, $0xffffffff</span><br></pre></td></tr></table></figure>
  会被抑制。</li>
</ul>
</li>
<li><p>在基本块级别进行寄存器活跃性分析。</p>
</li>
<li><p>这些信息用于消除从一个无用变量到另一个无用变量的移动操作。</p>
</li>
<li><p>还可以用于删除计算无用结果的指令。</p>
</li>
<li><p>这对于QEMU中的条件代码优化特别有用。</p>
<ul>
<li>在下面的示例中：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">add_i32 t0, t1, t2</span><br><span class="line">add_i32 t0, t0, $1</span><br><span class="line">mov_i32 t0, $1</span><br></pre></td></tr></table></figure>
  只会保留最后一条指令。</li>
</ul>
</li>
</ul>
<h2 id="Instruction-Reference"><a href="#Instruction-Reference" class="headerlink" title="Instruction Reference"></a>Instruction Reference</h2><h3 id="Function-call"><a href="#Function-call" class="headerlink" title="Function call"></a>Function call</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>call <em><ret></em> <em><params></em> ptr</p>
</li>
<li><p>|  call function ‘ptr’ (pointer type)<br>|<br>|  <em><ret></em> optional 32 bit or 64 bit return value<br>|  <em><params></em> optional 32 bit or 64 bit parameters</p>
</li>
</ul>
</li>
</ul>
<h3 id="Jumps-Labels"><a href="#Jumps-Labels" class="headerlink" title="Jumps&#x2F;Labels"></a>Jumps&#x2F;Labels</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>set_label $label</p>
</li>
<li><p>| Define label ‘label’ at the current program point.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>br $label</p>
</li>
<li><p>| Jump to label.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>brcond_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>cond</em>, <em>label</em></p>
</li>
<li><p>| Conditional jump if <em>t0</em> <em>cond</em> <em>t1</em> is true. <em>cond</em> can be:<br>|<br>|   <code>TCG_COND_EQ</code><br>|   <code>TCG_COND_NE</code><br>|   <code>TCG_COND_LT /* signed */</code><br>|   <code>TCG_COND_GE /* signed */</code><br>|   <code>TCG_COND_LE /* signed */</code><br>|   <code>TCG_COND_GT /* signed */</code><br>|   <code>TCG_COND_LTU /* unsigned */</code><br>|   <code>TCG_COND_GEU /* unsigned */</code><br>|   <code>TCG_COND_LEU /* unsigned */</code><br>|   <code>TCG_COND_GTU /* unsigned */</code></p>
</li>
</ul>
</li>
</ul>
<h3 id="Arithmetic"><a href="#Arithmetic" class="headerlink" title="Arithmetic"></a>Arithmetic</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>add_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> + <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>sub_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> - <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>neg_i32&#x2F;i64 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; -<em>t1</em> (two’s complement)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>mul_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> * <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>div_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> &#x2F; <em>t2</em> (signed)<br>| Undefined behavior if division by zero or overflow.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>divu_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> &#x2F; <em>t2</em> (unsigned)<br>| Undefined behavior if division by zero.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>rem_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> % <em>t2</em> (signed)<br>| Undefined behavior if division by zero or overflow.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>remu_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> % <em>t2</em> (unsigned)<br>| Undefined behavior if division by zero.</p>
</li>
</ul>
</li>
</ul>
<h3 id="Logical"><a href="#Logical" class="headerlink" title="Logical"></a>Logical</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>and_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> &amp; <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>or_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> | <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>xor_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> ^ <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>not_i32&#x2F;i64 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; ~\ <em>t1</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>andc_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> &amp; ~\ <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>eqv_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; ~(<em>t1</em> ^ <em>t2</em>), or equivalently, <em>t0</em> &#x3D; <em>t1</em> ^ ~\ <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>nand_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; ~(<em>t1</em> &amp; <em>t2</em>)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>nor_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; ~(<em>t1</em> | <em>t2</em>)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>orc_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> | ~\ <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>clz_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> ? clz(<em>t1</em>) : <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>ctz_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> ? ctz(<em>t1</em>) : <em>t2</em></p>
</li>
</ul>
</li>
<li><ul>
<li><p>ctpop_i32&#x2F;i64 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; number of bits set in <em>t1</em><br>|<br>| With <em>ctpop</em> short for “count population”, matching<br>| the function name used in <code>include/qemu/host-utils.h</code>.</p>
</li>
</ul>
</li>
</ul>
<h3 id="Shifts-Rotates"><a href="#Shifts-Rotates" class="headerlink" title="Shifts&#x2F;Rotates"></a>Shifts&#x2F;Rotates</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>shl_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> &lt;&lt; *t2*<br>| Unspecified behavior if *t2* &lt; 0 or *t2* &gt;&#x3D; 32 (resp 64)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>shr_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> &gt;&gt; <em>t2</em> (unsigned)<br>| Unspecified behavior if <em>t2</em> &lt; 0 or *t2* &gt;&#x3D; 32 (resp 64)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>sar_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em> &gt;&gt; <em>t2</em> (signed)<br>| Unspecified behavior if <em>t2</em> &lt; 0 or *t2* &gt;&#x3D; 32 (resp 64)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>rotl_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| Rotation of <em>t2</em> bits to the left<br>| Unspecified behavior if <em>t2</em> &lt; 0 or *t2* &gt;&#x3D; 32 (resp 64)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>rotr_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| Rotation of <em>t2</em> bits to the right.<br>| Unspecified behavior if <em>t2</em> &lt; 0 or *t2* &gt;&#x3D; 32 (resp 64)</p>
</li>
</ul>
</li>
</ul>
<h3 id="Misc"><a href="#Misc" class="headerlink" title="Misc"></a>Misc</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>mov_i32&#x2F;i64 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; <em>t1</em><br>| Move <em>t1</em> to <em>t0</em> (both operands must have the same type).</p>
</li>
</ul>
</li>
<li><ul>
<li><p>ext8s_i32&#x2F;i64 <em>t0</em>, <em>t1</em></p>
<p>ext8u_i32&#x2F;i64 <em>t0</em>, <em>t1</em></p>
<p>ext16s_i32&#x2F;i64 <em>t0</em>, <em>t1</em></p>
<p>ext16u_i32&#x2F;i64 <em>t0</em>, <em>t1</em></p>
<p>ext32s_i64 <em>t0</em>, <em>t1</em></p>
<p>ext32u_i64 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| 8, 16 or 32 bit sign&#x2F;zero extension (both operands must have the same type)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>bswap16_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>flags</em></p>
</li>
<li><p>| 16 bit byte swap on the low bits of a 32&#x2F;64 bit input.<br>|<br>| If <em>flags</em> &amp; <code>TCG_BSWAP_IZ</code>, then <em>t1</em> is known to be zero-extended from bit 15.<br>| If <em>flags</em> &amp; <code>TCG_BSWAP_OZ</code>, then <em>t0</em> will be zero-extended from bit 15.<br>| If <em>flags</em> &amp; <code>TCG_BSWAP_OS</code>, then <em>t0</em> will be sign-extended from bit 15.<br>|<br>| If neither <code>TCG_BSWAP_OZ</code> nor <code>TCG_BSWAP_OS</code> are set, then the bits of <em>t0</em> above bit 15 may contain any value.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>bswap32_i64 <em>t0</em>, <em>t1</em>, <em>flags</em></p>
</li>
<li><p>| 32 bit byte swap on a 64-bit value.  The flags are the same as for bswap16,<br>  except they apply from bit 31 instead of bit 15.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>bswap32_i32 <em>t0</em>, <em>t1</em>, <em>flags</em></p>
<p>bswap64_i64 <em>t0</em>, <em>t1</em>, <em>flags</em></p>
</li>
<li><p>| 32&#x2F;64 bit byte swap. The flags are ignored, but still present<br>  for consistency with the other bswap opcodes.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>discard_i32&#x2F;i64 <em>t0</em></p>
</li>
<li><p>| Indicate that the value of <em>t0</em> won’t be used later. It is useful to<br>  force dead code elimination.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>deposit_i32&#x2F;i64 <em>dest</em>, <em>t1</em>, <em>t2</em>, <em>pos</em>, <em>len</em></p>
</li>
<li><p>| Deposit <em>t2</em> as a bitfield into <em>t1</em>, placing the result in <em>dest</em>.<br>|<br>| The bitfield is described by <em>pos</em>&#x2F;<em>len</em>, which are immediate values:<br>|<br>|     <em>len</em> - the length of the bitfield<br>|     <em>pos</em> - the position of the first bit, counting from the LSB<br>|<br>| For example, “deposit_i32 dest, t1, t2, 8, 4” indicates a 4-bit field<br>  at bit 8. This operation would be equivalent to<br>|<br>|     <em>dest</em> &#x3D; (<em>t1</em> &amp; ~0x0f00) | ((<em>t2</em> &lt;&lt; 8) &amp; 0x0f00)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>extract_i32&#x2F;i64 <em>dest</em>, <em>t1</em>, <em>pos</em>, <em>len</em></p>
<p>sextract_i32&#x2F;i64 <em>dest</em>, <em>t1</em>, <em>pos</em>, <em>len</em></p>
</li>
<li><p>| Extract a bitfield from <em>t1</em>, placing the result in <em>dest</em>.<br>|<br>| The bitfield is described by <em>pos</em>&#x2F;<em>len</em>, which are immediate values,<br>  as above for deposit.  For extract_*, the result will be extended<br>  to the left with zeros; for sextract_*, the result will be extended<br>  to the left with copies of the bitfield sign bit at <em>pos</em> + <em>len</em> - 1.<br>|<br>| For example, “sextract_i32 dest, t1, 8, 4” indicates a 4-bit field<br>  at bit 8. This operation would be equivalent to<br>|<br>|    <em>dest</em> &#x3D; (<em>t1</em> &lt;&lt; 20) &gt;&gt; 28<br>|<br>| (using an arithmetic right shift).</p>
</li>
</ul>
</li>
<li><ul>
<li><p>extract2_i32&#x2F;i64 <em>dest</em>, <em>t1</em>, <em>t2</em>, <em>pos</em></p>
</li>
<li><p>| For N &#x3D; {32,64}, extract an N-bit quantity from the concatenation<br>  of <em>t2</em>:<em>t1</em>, beginning at <em>pos</em>. The tcg_gen_extract2_{i32,i64} expander<br>  accepts 0 &lt;&#x3D; <em>pos</em> &lt;&#x3D; N as inputs. The backend code generator will<br>  not see either 0 or N as inputs for these opcodes.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>extrl_i64_i32 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| For 64-bit hosts only, extract the low 32-bits of input <em>t1</em> and place it<br>  into 32-bit output <em>t0</em>.  Depending on the host, this may be a simple move,<br>  or may require additional canonicalization.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>extrh_i64_i32 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| For 64-bit hosts only, extract the high 32-bits of input <em>t1</em> and place it<br>  into 32-bit output <em>t0</em>.  Depending on the host, this may be a simple shift,<br>  or may require additional canonicalization.</p>
</li>
</ul>
</li>
</ul>
<h3 id="Conditional-moves"><a href="#Conditional-moves" class="headerlink" title="Conditional moves"></a>Conditional moves</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>setcond_i32&#x2F;i64 <em>dest</em>, <em>t1</em>, <em>t2</em>, <em>cond</em></p>
</li>
<li><p>| <em>dest</em> &#x3D; (<em>t1</em> <em>cond</em> <em>t2</em>)<br>|<br>| Set <em>dest</em> to 1 if (<em>t1</em> <em>cond</em> <em>t2</em>) is true, otherwise set to 0.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>movcond_i32&#x2F;i64 <em>dest</em>, <em>c1</em>, <em>c2</em>, <em>v1</em>, <em>v2</em>, <em>cond</em></p>
</li>
<li><p>| <em>dest</em> &#x3D; (<em>c1</em> <em>cond</em> <em>c2</em> ? <em>v1</em> : <em>v2</em>)<br>|<br>| Set <em>dest</em> to <em>v1</em> if (<em>c1</em> <em>cond</em> <em>c2</em>) is true, otherwise set to <em>v2</em>.</p>
</li>
</ul>
</li>
</ul>
<h3 id="Type-conversions"><a href="#Type-conversions" class="headerlink" title="Type conversions"></a>Type conversions</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>ext_i32_i64 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| Convert <em>t1</em> (32 bit) to <em>t0</em> (64 bit) and does sign extension</p>
</li>
</ul>
</li>
<li><ul>
<li><p>extu_i32_i64 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| Convert <em>t1</em> (32 bit) to <em>t0</em> (64 bit) and does zero extension</p>
</li>
</ul>
</li>
<li><ul>
<li><p>trunc_i64_i32 <em>t0</em>, <em>t1</em></p>
</li>
<li><p>| Truncate <em>t1</em> (64 bit) to <em>t0</em> (32 bit)</p>
</li>
</ul>
</li>
<li><ul>
<li><p>concat_i32_i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| Construct <em>t0</em> (64-bit) taking the low half from <em>t1</em> (32 bit) and the high half<br>  from <em>t2</em> (32 bit).</p>
</li>
</ul>
</li>
<li><ul>
<li><p>concat32_i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| Construct <em>t0</em> (64-bit) taking the low half from <em>t1</em> (64 bit) and the high half<br>  from <em>t2</em> (64 bit).</p>
</li>
</ul>
</li>
</ul>
<h3 id="Load-Store"><a href="#Load-Store" class="headerlink" title="Load&#x2F;Store"></a>Load&#x2F;Store</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>ld_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
<p>ld8s_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
<p>ld8u_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
<p>ld16s_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
<p>ld16u_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
<p>ld32s_i64 t0, <em>t1</em>, <em>offset</em></p>
<p>ld32u_i64 t0, <em>t1</em>, <em>offset</em></p>
</li>
<li><p>| <em>t0</em> &#x3D; read(<em>t1</em> + <em>offset</em>)<br>|<br>| Load 8, 16, 32 or 64 bits with or without sign extension from host memory.<br>  <em>offset</em> must be a constant.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>st_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
<p>st8_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
<p>st16_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
<p>st32_i64 <em>t0</em>, <em>t1</em>, <em>offset</em></p>
</li>
<li><p>| write(<em>t0</em>, <em>t1</em> + <em>offset</em>)<br>|<br>| Write 8, 16, 32 or 64 bits to host memory.</p>
</li>
</ul>
</li>
</ul>
<p>All this opcodes assume that the pointed host memory doesn’t correspond<br>to a global. In the latter case the behaviour is unpredictable.</p>
<h3 id="Multiword-arithmetic-support"><a href="#Multiword-arithmetic-support" class="headerlink" title="Multiword arithmetic support"></a>Multiword arithmetic support</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>add2_i32&#x2F;i64 <em>t0_low</em>, <em>t0_high</em>, <em>t1_low</em>, <em>t1_high</em>, <em>t2_low</em>, <em>t2_high</em></p>
<p>sub2_i32&#x2F;i64 <em>t0_low</em>, <em>t0_high</em>, <em>t1_low</em>, <em>t1_high</em>, <em>t2_low</em>, <em>t2_high</em></p>
</li>
<li><p>| Similar to add&#x2F;sub, except that the double-word inputs <em>t1</em> and <em>t2</em> are<br>  formed from two single-word arguments, and the double-word output <em>t0</em><br>  is returned in two single-word outputs.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>mulu2_i32&#x2F;i64 <em>t0_low</em>, <em>t0_high</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| Similar to mul, except two unsigned inputs <em>t1</em> and <em>t2</em> yielding the full<br>  double-word product <em>t0</em>. The latter is returned in two single-word outputs.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>muls2_i32&#x2F;i64 <em>t0_low</em>, <em>t0_high</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| Similar to mulu2, except the two inputs <em>t1</em> and <em>t2</em> are signed.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>mulsh_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
<p>muluh_i32&#x2F;i64 <em>t0</em>, <em>t1</em>, <em>t2</em></p>
</li>
<li><p>| Provide the high part of a signed or unsigned multiply, respectively.<br>|<br>| If mulu2&#x2F;muls2 are not provided by the backend, the tcg-op generator<br>  can obtain the same results by emitting a pair of opcodes, mul + muluh&#x2F;mulsh.</p>
</li>
</ul>
</li>
</ul>
<h3 id="Memory-Barrier-support"><a href="#Memory-Barrier-support" class="headerlink" title="Memory Barrier support"></a>Memory Barrier support</h3><p>.. list-table::</p>
<ul>
<li><ul>
<li><p>mb <em>&lt;$arg&gt;</em></p>
</li>
<li><p>| Generate a target memory barrier instruction to ensure memory ordering<br>  as being  enforced by a corresponding guest memory barrier instruction.<br>|<br>| The ordering enforced by the backend may be stricter than the ordering<br>  required by the guest. It cannot be weaker. This opcode takes a constant<br>  argument which is required to generate the appropriate barrier<br>  instruction. The backend should take care to emit the target barrier<br>  instruction only when necessary i.e., for SMP guests and when MTTCG is<br>  enabled.<br>|<br>| The guest translators should generate this opcode for all guest instructions<br>  which have ordering side effects.<br>|<br>| Please see :ref:<code>atomics-ref</code> for more information on memory barriers.</p>
</li>
</ul>
</li>
</ul>
<h3 id="64-bit-guest-on-32-bit-host-support"><a href="#64-bit-guest-on-32-bit-host-support" class="headerlink" title="64-bit guest on 32-bit host support"></a>64-bit guest on 32-bit host support</h3><p>The following opcodes are internal to TCG.  Thus they are to be implemented by<br>32-bit host code generators, but are not to be emitted by guest translators.<br>They are emitted as needed by inline functions within <code>tcg-op.h</code>.</p>
<p>.. list-table::</p>
<ul>
<li><ul>
<li><p>brcond2_i32 <em>t0_low</em>, <em>t0_high</em>, <em>t1_low</em>, <em>t1_high</em>, <em>cond</em>, <em>label</em></p>
</li>
<li><p>| Similar to brcond, except that the 64-bit values <em>t0</em> and <em>t1</em><br>  are formed from two 32-bit arguments.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>setcond2_i32 <em>dest</em>, <em>t1_low</em>, <em>t1_high</em>, <em>t2_low</em>, <em>t2_high</em>, <em>cond</em></p>
</li>
<li><p>| Similar to setcond, except that the 64-bit values <em>t1</em> and <em>t2</em> are<br>  formed from two 32-bit arguments. The result is a 32-bit value.</p>
</li>
</ul>
</li>
</ul>
<h3 id="QEMU-specific-operations"><a href="#QEMU-specific-operations" class="headerlink" title="QEMU specific operations"></a>QEMU specific operations</h3><table>
<thead>
<tr>
<th>operations</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>exit_tb <em>t0</em></td>
<td>退出当前的翻译块（Translation Block）并返回变量<em>t0</em>的值（字类型）</td>
</tr>
<tr>
<td>goto_tb <em>index</em></td>
<td>退出当前的翻译块（Translation Block）并根据条件跳转到索引为 index 的翻译块，如果当前的翻译块与目标翻译块相连。否则，继续执行下一条指令。只有索引为 0 和 1 是有效的，每个翻译块最多可以使用一次 tcg_gen_goto_tb 指令来跳转到每个索引。 tcg_gen_goto_tb may be issued at most once with each slot index per TB.</td>
</tr>
<tr>
<td>lookup_and_goto_ptr <em>tb_addr</em></td>
<td>查找一个翻译块的地址<em>tb_addr</em>，并根据其有效性进行跳转。如果翻译块地址有效，则跳转到该地址；如果无效，则跳转到TCG的收尾部分以返回执行循环。</td>
</tr>
<tr>
<td>qemu_ld_i32&#x2F;i64&#x2F;i128 <em>t0</em>, <em>t1</em>, <em>flags</em>, <em>memidx</em><br>qemu_st_i32&#x2F;i64&#x2F;i128 <em>t0</em>, <em>t1</em>, <em>flags</em>, <em>memidx</em><br>qemu_st8_i32 <em>t0</em>, <em>t1</em>, <em>flags</em>, <em>memidx</em></td>
<td>加载位于虚拟地址 t1 处的数据到 t0，或者将 t0 中的数据存储到虚拟地址 t1 处。_i32&#x2F;_i64&#x2F;_i128 大小适用于输入&#x2F;输出寄存器 t0 的大小。地址 t1 总是根据虚拟机的大小进行定位，而内存操作的宽度由 flags 控制。<br>在处理 64 位数据（在 32 位主机上）或 128 位数据（在 64 位主机上）时，t0 和 t1 可能会被拆分为按小端顺序排列的寄存器对。<br>memidx 用于选择要使用的 QEMU TLB 索引（例如，用户或内核访问）。flags 是 MemOp 位，用于选择内存访问的符号、宽度和字节顺序。<br>对于 32 位主机，保证仅在 flags 中指定了 64 位内存访问时才使用 qemu_ld&#x2F;st_i64。<br>对于 qemu_ld&#x2F;st_i128，仅在 64 位主机上支持。<br>对于 i386，qemu_st8_i32 与 qemu_st_i32 完全相同，只是内存操作的大小已知为 8 位。这允许后端提供不同的寄存器约束。</td>
</tr>
</tbody></table>
<h2 id="Host-vector-operations"><a href="#Host-vector-operations" class="headerlink" title="Host vector operations"></a>Host vector operations</h2><p>All of the vector ops have two parameters, <code>TCGOP_VECL</code> &amp; <code>TCGOP_VECE</code>.<br>The former specifies the length of the vector in log2 64-bit units; the<br>latter specifies the length of the element (if applicable) in log2 8-bit units.<br>E.g. VECL &#x3D; 1 -&gt; 64 &lt;&lt; 1 -&gt; v128, and VECE &#x3D; 2 -&gt; 1 &lt;&lt; 2 -&gt; i32.</p>
<p>.. list-table::</p>
<ul>
<li><ul>
<li><p>mov_vec <em>v0</em>, <em>v1</em><br>ld_vec <em>v0</em>, <em>t1</em><br>st_vec <em>v0</em>, <em>t1</em></p>
</li>
<li><p>| Move, load and store.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>dup_vec <em>v0</em>, <em>r1</em></p>
</li>
<li><p>| Duplicate the low N bits of <em>r1</em> into VECL&#x2F;VECE copies across <em>v0</em>.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>dupi_vec <em>v0</em>, <em>c</em></p>
</li>
<li><p>| Similarly, for a constant.<br>| Smaller values will be replicated to host register size by the expanders.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>dup2_vec <em>v0</em>, <em>r1</em>, <em>r2</em></p>
</li>
<li><p>| Duplicate <em>r2</em>:<em>r1</em> into VECL&#x2F;64 copies across <em>v0</em>. This opcode is<br>  only present for 32-bit hosts.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>add_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
</li>
<li><p>| <em>v0</em> &#x3D; <em>v1</em> + <em>v2</em>, in elements across the vector.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>sub_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
</li>
<li><p>| Similarly, <em>v0</em> &#x3D; <em>v1</em> - <em>v2</em>.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>mul_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
</li>
<li><p>| Similarly, <em>v0</em> &#x3D; <em>v1</em> * <em>v2</em>.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>neg_vec <em>v0</em>, <em>v1</em></p>
</li>
<li><p>| Similarly, <em>v0</em> &#x3D; -<em>v1</em>.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>abs_vec <em>v0</em>, <em>v1</em></p>
</li>
<li><p>| Similarly, <em>v0</em> &#x3D; <em>v1</em> &lt; 0 ? -<em>v1</em> : <em>v1</em>, in elements across the vector.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>smin_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>umin_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
</li>
<li><p>| Similarly, <em>v0</em> &#x3D; MIN(<em>v1</em>, <em>v2</em>), for signed and unsigned element types.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>smax_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>umax_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
</li>
<li><p>| Similarly, <em>v0</em> &#x3D; MAX(<em>v1</em>, <em>v2</em>), for signed and unsigned element types.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>ssadd_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>sssub_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>usadd_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>ussub_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
</li>
<li><p>| Signed and unsigned saturating addition and subtraction.<br>|<br>| If the true result is not representable within the element type, the<br>  element is set to the minimum or maximum value for the type.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>and_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>or_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>xor_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>andc_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>orc_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>not_vec <em>v0</em>, <em>v1</em></p>
</li>
<li><p>| Similarly, logical operations with and without complement.<br>|<br>| Note that VECE is unused.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>shli_vec <em>v0</em>, <em>v1</em>, <em>i2</em></p>
<p>shls_vec <em>v0</em>, <em>v1</em>, <em>s2</em></p>
</li>
<li><p>| Shift all elements from v1 by a scalar <em>i2</em>&#x2F;<em>s2</em>. I.e.</p>
<p>.. code-block:: c</p>
<p>   for (i &#x3D; 0; i &lt; VECL&#x2F;VECE; ++i) {<br>   v0[i] &#x3D; v1[i] &lt;&lt; s2;<br>   }</p>
</li>
</ul>
</li>
<li><ul>
<li><p>shri_vec <em>v0</em>, <em>v1</em>, <em>i2</em></p>
<p>sari_vec <em>v0</em>, <em>v1</em>, <em>i2</em></p>
<p>rotli_vec <em>v0</em>, <em>v1</em>, <em>i2</em></p>
<p>shrs_vec <em>v0</em>, <em>v1</em>, <em>s2</em></p>
<p>sars_vec <em>v0</em>, <em>v1</em>, <em>s2</em></p>
</li>
<li><p>| Similarly for logical and arithmetic right shift, and left rotate.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>shlv_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
</li>
<li><p>| Shift elements from <em>v1</em> by elements from <em>v2</em>. I.e.</p>
<p>.. code-block:: c</p>
<p>   for (i &#x3D; 0; i &lt; VECL&#x2F;VECE; ++i) {<br>   v0[i] &#x3D; v1[i] &lt;&lt; v2[i];<br>   }</p>
</li>
</ul>
</li>
<li><ul>
<li><p>shrv_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>sarv_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>rotlv_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
<p>rotrv_vec <em>v0</em>, <em>v1</em>, <em>v2</em></p>
</li>
<li><p>| Similarly for logical and arithmetic right shift, and rotates.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>cmp_vec <em>v0</em>, <em>v1</em>, <em>v2</em>, <em>cond</em></p>
</li>
<li><p>| Compare vectors by element, storing -1 for true and 0 for false.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>bitsel_vec <em>v0</em>, <em>v1</em>, <em>v2</em>, <em>v3</em></p>
</li>
<li><p>| Bitwise select, <em>v0</em> &#x3D; (<em>v2</em> &amp; <em>v1</em>) | (<em>v3</em> &amp; ~\ <em>v1</em>), across the entire vector.</p>
</li>
</ul>
</li>
<li><ul>
<li><p>cmpsel_vec <em>v0</em>, <em>c1</em>, <em>c2</em>, <em>v3</em>, <em>v4</em>, <em>cond</em></p>
</li>
<li><p>| Select elements based on comparison results:</p>
<p>.. code-block:: c</p>
<p>   for (i &#x3D; 0; i &lt; n; ++i) {<br>   v0[i] &#x3D; (c1[i] cond c2[i]) ? v3[i] : v4[i].<br>   }</p>
</li>
</ul>
</li>
</ul>
<p><strong>Note 1</strong>: Some shortcuts are defined when the last operand is known to be<br>a constant (e.g. addi for add, movi for mov).</p>
<p><strong>Note 2</strong>: When using TCG, the opcodes must never be generated directly<br>as some of them may not be available as “real” opcodes. Always use the<br>function tcg_gen_xxx(args).</p>
<h2 id="Backend-后端"><a href="#Backend-后端" class="headerlink" title="Backend &#x2F; 后端"></a>Backend &#x2F; 后端</h2><ul>
<li><code>tcg-target.h</code> 是包含目标特定定义的文件。</li>
<li><code>tcg-target.c.inc</code> 是目标特定代码的文件，它通过 <code>#include</code> 被 <code>tcg/tcg.c</code> 包含，而不是作为一个独立的 C 文件存在。</li>
</ul>
<h3 id="Assumptions-假设"><a href="#Assumptions-假设" class="headerlink" title="Assumptions &#x2F; 假设"></a>Assumptions &#x2F; 假设</h3><ul>
<li><p>目标字长（<code>TCG_TARGET_REG_BITS</code>）预期为32位或64位。</p>
</li>
<li><p>假设指针的大小与字长相同。</p>
</li>
<li><p>在32位目标上，所有64位操作都会转换为32位。</p>
</li>
<li><p>需要实现一些特定的操作来支持这一点（参见<code>add2_i32</code>，<code>sub2_i32</code>，<code>brcond2_i32</code>）。</p>
</li>
<li><p>在64位目标上，通过以下操作在32位和64位寄存器之间传输值：</p>
<ul>
<li><code>trunc_shr_i64_i32</code></li>
<li><code>ext_i32_i64</code></li>
<li><code>extu_i32_i64</code></li>
</ul>
</li>
<li><p>它们确保在从32位寄存器移动到64位寄存器或反之时，值被正确截断或扩展。请注意，<code>trunc_shr_i64_i32</code>是一个可选的操作。</p>
</li>
<li><p>如果满足以下所有条件，则不需要实现它：</p>
<ul>
<li>64位寄存器可以容纳32位值</li>
<li>64位寄存器中的32位值不需要保持零扩展或符号扩展</li>
<li>所有32位TCG操作忽略64位寄存器的高位部分</li>
</ul>
</li>
<li><p>此版本不支持浮点操作。代码生成器的先前版本对其有全面支持，但最好先集中精力处理整数操作。</p>
</li>
</ul>
<h3 id="Constraints-限制"><a href="#Constraints-限制" class="headerlink" title="Constraints &#x2F; 限制"></a>Constraints &#x2F; 限制</h3><ul>
<li><p>这个版本使用类似GCC的约束来定义每个指令的限制条件。</p>
</li>
<li><p>不支持内存约束。</p>
</li>
<li><p>别名可以像GCC一样在输入操作数中指定。</p>
</li>
<li><p>即使没有明确指定别名，同一个寄存器可以用作输入和输出。</p>
</li>
<li><p>如果一个操作扩展为多个目标指令，需要注意避免破坏输入值。</p>
</li>
<li><p>支持GCC风格的”早期占用”输出，使用’<code>&amp;</code>‘符号。</p>
</li>
<li><p>目标可以定义特定的寄存器或常量约束。</p>
</li>
<li><p>如果一个操作使用不允许所有常量的常量输入约束，为了有备用选项，必须同时接受寄存器。 （If an operation uses a constant input constraint which does not allow all constants, it must also accept registers in order to have a fallback.）</p>
</li>
<li><p>约束’<code>i</code>‘是通用定义的，接受任何常量。</p>
</li>
<li><p>约束’<code>r</code>‘没有通用定义，但每个后端一致使用它来表示所有寄存器。</p>
</li>
<li><p>movi_i32和movi_i64操作必须接受任何常量。</p>
</li>
<li><p>mov_i32和mov_i64操作必须接受相同类型的任何寄存器。</p>
</li>
<li><p>ld&#x2F;st&#x2F;sti指令必须接受带符号的32位常量偏移量。</p>
</li>
<li><p>如果偏移量太大，可以通过保留一个特定的寄存器来计算地址。</p>
</li>
<li><p>ld&#x2F;st指令必须接受任何目标寄存器（ld）或源寄存器（st）。</p>
</li>
<li><p>sti指令可能会因无法存储给定的常量而失败。</p>
</li>
</ul>
<h3 id="Function-call-assumptions-函数调用的假设"><a href="#Function-call-assumptions-函数调用的假设" class="headerlink" title="Function call assumptions &#x2F; 函数调用的假设"></a>Function call assumptions &#x2F; 函数调用的假设</h3><ul>
<li>参数和返回值的支持类型仅限于32位和64位整数以及指针。</li>
<li>栈向下增长。</li>
<li>前N个参数通过寄存器传递。</li>
<li>接下来的参数通过将它们存储为字节的方式通过栈传递。</li>
<li>在调用期间，一些寄存器的值可能会被覆盖。</li>
<li>函数可以在寄存器中返回0或1个值。在32位目标平台上，函数必须能够以寄存器返回2个值，用于64位返回类型。</li>
</ul>
<h2 id="Recommended-coding-rules-for-best-performance"><a href="#Recommended-coding-rules-for-best-performance" class="headerlink" title="Recommended coding rules for best performance"></a>Recommended coding rules for best performance</h2><ul>
<li><p>使用全局变量来表示经常被修改的QEMU CPU状态的部分，例如整数寄存器和条件码。</p>
</li>
<li><p>TCG将能够使用主机寄存器来存储它们。</p>
</li>
<li><p>对于复杂或不常用的客户指令，不要犹豫使用辅助函数。</p>
</li>
<li><p>在使用TCG实现的客户指令中，使用超过约二十条TCG指令的性能优势很小。</p>
</li>
<li><p>需要注意的是，这个经验法则更适用于执行复杂逻辑或算术运算的辅助函数，因为C编译器可以进行有效的优化；在大部分是加载和存储操作的指令中，这个规则的适用性较小，并且在这些情况下，内联TCG仍然可能比较长的序列更快。</p>
</li>
<li><p>如果你知道TCG无法证明在给定程序点上某个全局变量是”无用”的，可以使用”discard”指令。</p>
</li>
<li><p>x86客户机使用它来改进条件码的优化。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/05/18/Qemu%E7%BF%BB%E8%AF%91%E6%B5%81%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/05/18/Qemu%E7%BF%BB%E8%AF%91%E6%B5%81%E7%A8%8B/" class="post-title-link" itemprop="url">Qemu翻译器的内部机制</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-18 19:23:50" itemprop="dateCreated datePublished" datetime="2023-05-18T19:23:50+08:00">2023-05-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:50" itemprop="dateModified" datetime="2023-07-30T18:15:50+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Qemu/" itemprop="url" rel="index"><span itemprop="name">Qemu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Translator-Internals-翻译器的内部机制"><a href="#Translator-Internals-翻译器的内部机制" class="headerlink" title="Translator Internals &#x2F; 翻译器的内部机制"></a>Translator Internals &#x2F; 翻译器的内部机制</h1><ul>
<li><p>QEMU是一个动态翻译器。</p>
</li>
<li><p>当它首次遇到一段代码时，它会将其转换为宿主机指令集。</p>
</li>
<li><p>通常，动态翻译器非常复杂且高度依赖于CPU。</p>
</li>
<li><p>QEMU使用一些技巧使其相对容易进行移植和简化，同时实现良好的性能。</p>
</li>
<li><p>QEMU的动态翻译后端称为TCG（Tiny Code Generator），见另一篇文章TCG IR。</p>
</li>
<li><p>以下部分概述了QEMU动态翻译器的一些显著特点和实现细节。</p>
</li>
</ul>
<h1 id="CPU-state-optimisations-CPU状态优化"><a href="#CPU-state-optimisations-CPU状态优化" class="headerlink" title="CPU state optimisations &#x2F; CPU状态优化"></a>CPU state optimisations &#x2F; CPU状态优化</h1><ul>
<li>目标CPU具有许多内部状态，这些状态会影响它们执行指令的方式。</li>
<li>为了实现良好的速度，翻译阶段考虑到虚拟CPU的某些状态信息在其中不会改变。</li>
<li>状态信息被记录在翻译块（Translation Block，TB）中。</li>
<li>如果状态发生变化（例如特权级别），将生成一个新的TB，并且之前的TB将不再使用，直到状态与之前记录在先的TB中的状态匹配。</li>
<li>对于CPU状态的其他方面也可以应用相同的思想。例如，在x86架构中，如果SS、DS和ES段具有零基址，那么翻译器甚至不会为段基址生成一个加法操作。</li>
</ul>
<h2 id="Direct-block-chaining-直接块链接"><a href="#Direct-block-chaining-直接块链接" class="headerlink" title="Direct block chaining &#x2F; 直接块链接"></a>Direct block chaining &#x2F; 直接块链接</h2><ul>
<li><p>在每个已执行的翻译的基本块之后，QEMU使用模拟的程序计数器（PC）和其他CPU状态信息（例如CS段基址）来找到下一个基本块。</p>
</li>
<li><p>在简单且未经优化的形式中，这是通过退出当前的翻译块，经过翻译块的收尾处理，然后返回到主循环来完成的。</p>
</li>
<li><p>在主循环中，QEMU寻找要执行的下一个翻译块，如果它尚未在内存中，则将其从客户体系结构翻译出来。</p>
</li>
<li><p>然后，QEMU继续执行下一个翻译块，从序言开始，然后继续执行已翻译的指令。</p>
</li>
<li><p>以这种方式退出翻译块将导致在执行其他指令之前重新评估<code>cpu_exec_interrupt()</code>回调函数。</p>
</li>
<li><p>在发生可能解除中断屏蔽的任何CPU状态更改后，以这种方式退出是必需的。</p>
</li>
<li><p>为了加速当新的模拟PC对应的翻译块已经可用的情况，QEMU具有机制允许直接链接多个翻译块，而无需返回到上述的主循环。这些机制包括：</p>
</li>
</ul>
<h3 id="lookup-and-goto-ptr"><a href="#lookup-and-goto-ptr" class="headerlink" title="lookup_and_goto_ptr"></a><code>lookup_and_goto_ptr</code></h3><ul>
<li>调用<code>tcg_gen_lookup_and_goto_ptr()</code>将生成对<code>helper_lookup_tb_ptr</code>的调用。</li>
<li>该辅助函数将查找与当前CPU状态匹配的现有翻译块。</li>
<li>如果目标翻译块可用，则返回其代码地址；否则返回JIT（即时编译）收尾部分的地址。</li>
<li>在调用辅助函数之后，总是紧随着tcg <code>goto_ptr</code>指令，它会跳转到返回的地址。</li>
<li>这样，我们要么跳转到下一个翻译块，要么返回到主循环。</li>
</ul>
<h3 id="goto-tb-exit-tb"><a href="#goto-tb-exit-tb" class="headerlink" title="goto_tb + exit_tb"></a><code>goto_tb + exit_tb</code></h3><ul>
<li><p>翻译代码通常通过以下步骤来实现分支：</p>
<ol>
<li>调用<code>tcg_gen_goto_tb()</code>，并将跳转槽索引（0或1）作为参数传递。</li>
<li>发出TCG指令来更新CPU状态，其中包括已假定为常量且主循环需要正确定位和执行下一个翻译块所需的信息。对于大多数客户机，这仅仅是分支目标的PC，但其他一些客户机可能会存储附加数据。在此步骤中更新的信息必须可以从<code>cpu_get_tb_cpu_state()</code>和<code>cpu_restore_state()</code>中推断出来。</li>
<li>调用<code>tcg_gen_exit_tb()</code>，再次传递当前翻译块的地址和跳转槽索引。</li>
</ol>
</li>
<li><p>第1步<code>tcg_gen_goto_tb()</code>将生成一个<code>goto_tb</code> TCG指令，稍后会被翻译为跳转到与指定跳转槽相关联的地址。</p>
</li>
<li><p>初始时，这是第2步的指令的地址，用于更新CPU状态信息。</p>
</li>
<li><p>第3步<code>tcg_gen_exit_tb()</code>从当前翻译块退出，并返回由上一个执行的翻译块地址和跳转槽索引组成的标记指针。</p>
</li>
<li><p>第一次执行整个序列时，第1步简单地跳转到第2步。</p>
</li>
<li><p>然后，CPU状态信息会被更新，并从当前翻译块退出。</p>
</li>
<li><p>结果，行为与前面在本节中描述的较少优化的形式非常相似。</p>
</li>
<li><p>接下来，主循环使用当前CPU状态信息寻找要执行的下一个翻译块（如果尚未可用，则创建该翻译块），并在开始执行新翻译块的指令之前，通过将其跳转槽之一（在调用<code>tcg_gen_exit_tb()</code>时指定）与新翻译块的地址关联起来，来修补先前执行的翻译块。</p>
</li>
<li><p>下一次执行这个先前的翻译块，并到达同样的<code>goto_tb</code>步骤时，它将已经被修补（假设目标翻译块仍然在内存中），并直接跳转到目标翻译块的第一条指令，而无需返回到主循环。</p>
</li>
<li><p>要使用<code>goto_tb + exit_tb</code>机制，需要满足以下条件：</p>
<ul>
<li><p>CPU状态的更改必须是常量，例如直接分支而不是间接分支。</p>
</li>
<li><p>直接分支不能跨越页边界。内存映射可能会改变，导致目标地址的代码发生变化。</p>
</li>
</ul>
</li>
<li><p>需要注意的是，在第3步（<code>tcg_gen_exit_tb()</code>）中，除了跳转槽索引之外，还返回了刚刚执行的翻译块的地址。</p>
</li>
<li><p>这个地址对应于将要被修补的翻译块；如果该翻译块已经链接到其他翻译块，那么它可能与直接从主循环执行的翻译块不同。</p>
</li>
<li><p>Note that, on step 3 (<code>tcg_gen_exit_tb()</code>), in addition to the jump slot index, the address of the TB just executed is also returned.</p>
</li>
<li><p>This address corresponds to the TB that will be patched; it may be different than the one that was directly executed from the main loop if the latter had already been chained to other TBs.</p>
</li>
</ul>
<h2 id="Self-modifying-code-and-translated-code-invalidation-自修改代码和翻译代码失效"><a href="#Self-modifying-code-and-translated-code-invalidation-自修改代码和翻译代码失效" class="headerlink" title="Self-modifying code and translated code invalidation &#x2F; 自修改代码和翻译代码失效"></a>Self-modifying code and translated code invalidation &#x2F; 自修改代码和翻译代码失效</h2><ul>
<li><p>在x86仿真中，自修改代码是一个特殊的挑战，因为当代码被修改时，应用程序不会向系统发出指示来使指令缓存失效。</p>
</li>
<li><p>在用户模式仿真中，每当为基本块生成翻译代码时，会将主机页面标记为写保护（如果它尚未是只读）。</p>
</li>
<li><p>然后，如果对该页面进行写访问，Linux会触发一个SEGV信号。</p>
</li>
<li><p>然后，QEMU会使该页面中的所有翻译代码失效，并允许对该页面进行写访问。</p>
</li>
<li><p>对于系统仿真，写保护是通过软件MMU实现的。</p>
</li>
<li><p>通过维护一个链接列表来高效地进行正确的翻译代码失效，该列表包含在给定页面中的每个翻译块。</p>
</li>
<li><p>还维护其他链接列表以撤消直接块链接。</p>
</li>
<li><p>Correct translated code invalidation is done efficiently by maintaining a linked list of every translated block contained in a given page. </p>
</li>
<li><p>Other linked lists are also maintained to undo direct block chaining.</p>
</li>
<li><p>在RISC目标中，正确编写的软件使用内存屏障和缓存刷新，因此上述保护措施可能不是必需的。</p>
</li>
<li><p>然而，QEMU仍然要求生成的代码始终与目标指令在内存中匹配，以便正确处理异常情况。</p>
</li>
</ul>
<h2 id="Exception-support-异常支持"><a href="#Exception-support-异常支持" class="headerlink" title="Exception support &#x2F; 异常支持"></a>Exception support &#x2F; 异常支持</h2><ul>
<li><p>在遇到诸如除零等异常时，会使用longjmp()函数。</p>
</li>
<li><p>主机的SIGSEGV和SIGBUS信号处理程序用于获取无效的内存访问。</p>
</li>
<li><p>QEMU保持了一个从主机程序计数器（PC）到目标程序计数器（PC）的映射，并根据异常点处的主机程序计数器查找异常发生的位置。</p>
</li>
<li><p>在某些目标平台上，虚拟CPU状态的某些位直到翻译块结束之前才会刷新到内存中。</p>
</li>
<li><p>这是为了保存内部仿真状态，该状态很少直接被程序访问，且在翻译块的执行过程中经常发生变化，例如x86上的条件码、SPARC上的延迟槽、Arm上的条件执行等。</p>
</li>
<li><p>这些状态针对每个目标指令进行存储，并在发生异常时进行查找。</p>
</li>
</ul>
<h2 id="MMU-emulation-MMU（Memory-Management-Unit）仿真"><a href="#MMU-emulation-MMU（Memory-Management-Unit）仿真" class="headerlink" title="MMU emulation &#x2F; MMU（Memory Management Unit）仿真"></a>MMU emulation &#x2F; MMU（Memory Management Unit）仿真</h2><hr>
<ul>
<li><p>在系统仿真中，QEMU使用软件MMU。</p>
</li>
<li><p>在这种模式下，MMU会在每次内存访问时进行虚拟地址到物理地址的转换。</p>
</li>
<li><p>为了加快转换速度并避免在MMU映射发生变化时每次都刷新已翻译的代码，QEMU使用地址转换缓存（TLB）。</p>
</li>
<li><p>在QEMU中，所有缓存都是物理索引的，这意味着每个基本块都与其物理地址相关联。</p>
</li>
<li><p>为了避免在MMU映射发生变化时使基本块链无效，只有当跳转目标与执行跳转的基本块共享同一页时，才会执行链式操作。</p>
</li>
<li><p>MMU还可以区分RAM（随机存储器）和ROM（只读存储器）区域与MMIO（内存映射输入&#x2F;输出）内存区域。</p>
</li>
<li><p>对于RAM和ROM的访问速度更快，因为转换缓存还存储了来宾地址和主机内存之间的偏移量。</p>
</li>
<li><p>而对MMIO内存区域的访问则调用C代码进行设备仿真。</p>
</li>
<li><p>最后，MMU有助于跟踪脏页和被翻译块引用的页。</p>
</li>
<li><p>这样可以有效地管理内存页面，并进行必要的操作，如脏页回写或内存页面回收。</p>
</li>
</ul>
<h2 id="Profiling-JITted-code-对JIT（即时编译）代码进行性能分析"><a href="#Profiling-JITted-code-对JIT（即时编译）代码进行性能分析" class="headerlink" title="Profiling JITted code &#x2F; 对JIT（即时编译）代码进行性能分析"></a>Profiling JITted code &#x2F; 对JIT（即时编译）代码进行性能分析</h2><ul>
<li><p>Linux的perf工具在处理JIT（即时编译）代码时会将其视为单个代码块，因为与主要代码不同，它无法使用调试信息将单个程序计数器样本与较大的函数关联起来。</p>
</li>
<li><p>为了克服这个限制，可以使用<code>-perfmap</code>或<code>-jitdump</code>选项生成映射文件。</p>
</li>
<li><p><code>-perfmap</code>是轻量级的，只生成客户机-主机映射关系。</p>
</li>
<li><p><code>-jitdump</code>除此之外，还会保存JIT代码和客户机调试信息（如果有的话）；它的输出需要与<code>perf.data</code>文件集成，然后才能查看最终的报告。</p>
</li>
<li><p>示例代码如下：</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">perf record $QEMU -perfmap $REMAINING_ARGS</span><br><span class="line">perf report</span><br><span class="line"></span><br><span class="line">perf record -k 1 $QEMU -jitdump $REMAINING_ARGS</span><br><span class="line">DEBUGINFOD_URLS= perf inject -j -i perf.data -o perf.data.jitted</span><br><span class="line">perf report -i perf.data.jitted</span><br></pre></td></tr></table></figure>

<ul>
<li><p>请注意，qemu-system仅为ELF格式的<code>-kernel</code>文件生成映射。</p>
</li>
<li><p>使用这些命令和选项，可以将JIT代码的性能分析结果与perf工具的报告集成在一起，以便更好地理解和分析JIT代码的性能。这将帮助开发人员针对性地进行优化和改进，提高QEMU的性能。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/05/18/Qemu%20icount/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/05/18/Qemu%20icount/" class="post-title-link" itemprop="url">Qemu icount</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-18 11:23:50" itemprop="dateCreated datePublished" datetime="2023-05-18T11:23:50+08:00">2023-05-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:50" itemprop="dateModified" datetime="2023-07-30T18:15:50+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Qemu/" itemprop="url" rel="index"><span itemprop="name">Qemu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="TCG-Instruction-Counting-TCG指令计数"><a href="#TCG-Instruction-Counting-TCG指令计数" class="headerlink" title="TCG Instruction Counting &#x2F; TCG指令计数"></a>TCG Instruction Counting &#x2F; TCG指令计数</h1><ul>
<li><p>TCG长期支持一种称为icount的功能，允许在执行过程中进行指令计数。</p>
</li>
<li><p>这与周期精确的仿真不应混淆——QEMU不会尝试模拟指令在实际硬件上所需的时间。这是其他更详细（但更慢）的工具来模拟微体系结构的工作。</p>
</li>
<li><p>这个功能仅适用于系统仿真，并且与多线程TCG不兼容。它可用于更好地与挂钟时间（wall-clock time）对齐执行时间，以防止“慢速”设备在现代硬件上运行过快。它还提供了一定程度的确定性执行，并且是QEMU中记录&#x2F;回放支持的关键部分。</p>
</li>
</ul>
<h2 id="Core-Concepts-核心概念"><a href="#Core-Concepts-核心概念" class="headerlink" title="Core Concepts &#x2F; 核心概念"></a>Core Concepts &#x2F; 核心概念</h2><ul>
<li><p>icount本质上是一个在QEMU计时器子系统的TimersState中存储的已执行指令计数。</p>
</li>
<li><p>已执行指令的数量可以用来计算QEMU_CLOCK_VIRTUAL，该值表示自执行开始以来系统中经过的时间。根据icount模式，这可能是每条指令固定的纳秒数，或者在执行过程中进行调整，以保持挂钟时间和虚拟时间同步。</p>
</li>
<li><p>为了能够计算已执行指令的数量，翻译器首先分配一定数量的待执行指令预算。指令预算受限于下一个定时器到期之前的时间长度。我们将这个预算作为vCPU的icount_decr字段的一部分进行存储，该字段与处理cpu_exit()的机制共享。在每个翻译块的开始处检查整个字段，并在退出时返回到外部循环以处理导致退出的原因。</p>
</li>
<li><p>对于icount，再检查标志之前，我们会减去翻译块将要执行的指令数。如果这会导致指令预算变为负数，我们将退出主循环，并重新生成一个新的翻译块，其中包含恰好足够数量的指令，使预算减为0，这意味着无论何时我们退出主运行循环，定时器都将会在该时刻到期。</p>
</li>
</ul>
<h2 id="Dealing-with-MMIO-处理MMIO"><a href="#Dealing-with-MMIO-处理MMIO" class="headerlink" title="Dealing with MMIO &#x2F; 处理MMIO"></a>Dealing with MMIO &#x2F; 处理MMIO</h2><ul>
<li><p>虽然我们可以调整已知事件（如计时器到期）的指令预算，但对于MMIO来说我们无法做到同样的调整。</p>
</li>
<li><p>我们执行的每个加载&#x2F;存储操作都可能触发一个I&#x2F;O事件，在这种情况下，我们需要一个最新且准确的icount数的读取。</p>
</li>
<li><p>为了处理这种情况，当进行I&#x2F;O访问时，我们会：</p>
<ol>
<li>将未执行的指令恢复到icount预算中</li>
<li>为当前PC重新编译一个[1]指令块</li>
<li>退出CPU循环并执行重新编译的块</li>
</ol>
</li>
<li><p>新的块被创建时带有CF_LAST_IO编译标志，确保最终的指令转换从调用gen_io_start()开始，这样我们就不会进入一个永久循环，不断重新编译一个单独的指令块。对于使用常见的translator_loop的翻译器，这是自动完成的。</p>
</li>
</ul>
<h2 id="Other-I-O-operations-其他IO操作"><a href="#Other-I-O-operations-其他IO操作" class="headerlink" title="Other I&#x2F;O operations &#x2F; 其他IO操作"></a>Other I&#x2F;O operations &#x2F; 其他IO操作</h2><ul>
<li><p>MMIO不是唯一可能需要正确和准确时钟的操作类型。</p>
</li>
<li><p>IO端口指令和对系统寄存器的访问是常见的例子。</p>
</li>
<li><p>这些指令必须由具有了解哪些操作是I&#x2F;O操作的各个翻译器处理。</p>
</li>
<li><p>当翻译器处理此类指令时：</p>
<ul>
<li>如果启用了icount，它必须在实际执行I&#x2F;O操作的代码生成之前的某个时刻调用gen_io_start()，使用类似以下代码片段的代码：  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (tb_cflags(s-&gt;base.tb) &amp; CF_USE_ICOUNT) &#123;</span><br><span class="line">    gen_io_start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>必须立即结束该TB（翻译块）在执行完这条指令之后。</li>
</ul>
</li>
<li><p>以上是处理这类指令的要求。通过调用gen_io_start()，我们可以确保在执行I&#x2F;O操作之前记录正确的icount计数，并且在完成指令后结束TB以防止进一步执行不必要的指令。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/05/18/CPU%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/05/18/CPU%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/" class="post-title-link" itemprop="url">CPU体系结构专业术语</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-05-18 11:23:50" itemprop="dateCreated datePublished" datetime="2023-05-18T11:23:50+08:00">2023-05-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:18" itemprop="dateModified" datetime="2023-07-30T18:15:18+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Qemu/" itemprop="url" rel="index"><span itemprop="name">Qemu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="MMIO（Memory-Mapped-I-O）"><a href="#MMIO（Memory-Mapped-I-O）" class="headerlink" title="MMIO（Memory-Mapped I&#x2F;O）"></a>MMIO（Memory-Mapped I&#x2F;O）</h1><ul>
<li><p>代表内存映射输入&#x2F;输出。</p>
</li>
<li><p>它是一种计算机系统中用于与外部设备进行通信的技术。在MMIO中，外部设备的寄存器或状态被映射到计算机的内存地址空间中的特定区域。通过读取或写入这些内存地址，计算机可以与外部设备进行数据交换和控制操作。</p>
</li>
<li><p>MMIO的基本原理是通过在内存地址空间中保留一些特定的地址范围，让计算机能够直接访问外部设备的寄存器或状态。当计算机读取或写入这些地址时，数据被传递到或从外部设备进行处理。这种方式相对于使用专门的I&#x2F;O指令进行输入&#x2F;输出操作，提供了更简化和统一的编程界面。</p>
</li>
<li><p>常见的MMIO设备包括网络接口卡、图形显示控制器、声卡、串口控制器等。通过使用MMIO技术，计算机可以通过内存访问方式与这些设备进行通信，从而实现数据传输、设备控制和信息交换等功能。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/04/12/Chiplets/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/04/12/Chiplets/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-12 00:00:00" itemprop="dateCreated datePublished" datetime="2023-04-12T00:00:00+08:00">2023-04-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:18" itemprop="dateModified" datetime="2023-07-30T18:15:18+08:00">2023-07-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>该论文讨论了系统级芯片（SoC）的复杂性和硅成本的增加促使将SoC分解为更小的“芯片块”。基于芯片块的SoC设计过程有望通过使用先进的封装技术将多个不同的芯片（例如CPU、GPU、内存、FPGA）紧密集成到一起来实现快速的SoC构建。然而，当将芯片块组装成单个SoC时，由于芯片块之间路由的复杂性增加，会出现正确性和性能问题。该论文提出了一种模块化但无死锁的路由方法，用于具有各种拓扑结构的基于芯片块的系统。</p>
<h1 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h1><p>在越来越复杂的工艺技术中，大型片上系统（SoC）的成本不断上升，这促使了基于“芯片”设计的SoC的出现。这个概念将传统的单片式SoC分解成几个更小的芯片，每个芯片都可以更便宜地开发，更容易在多个产品中重复使用，并使用最合适的工艺技术进行实现。芯片方法正在学术界[1]-[4]、工业界[5]-[11]和政府机构[12]中得到积极的研究<br>基于芯片的体系结构存在许多研究和工程挑战；我们关注其中一个具体但关键的问题。遵循模块化设计方法，每个单独的芯片都应该在不了解整个系统的情况下进行设计和验证。当从多个芯片构建SoC时，即使每个单独的组件都经过了正确的验证，完全集成的系统仍然可能存在正确性问题。互连网络特别容易受到这种影响。每个单独的芯片可能包含其自己的本地网络芯片（NoC），该NoC对于芯片内部流量是本地死锁自由且正常运行的。但是，连接多个NoC在一起可能会引入新的资源周期，从而导致跨芯片的循环依赖关系。”<br>虽然已经宣布了相对简单的基于芯片的体系结构[13]，或者甚至已经可用[14]，但这项工作进一步展望了基于在活动硅中间层上堆叠多个芯片的新兴体系结构（尽管我们也解释了如何将我们的方法应用于更接近的集成方法，例如被动中间层）。我们首先提供一些有关芯片的背景，并描述现有多芯片体系结构所涉及的模块化挑战。然后，我们介绍了一种新的基于芯片的路由方法，使每个芯片都可以独立设计，而不需要了解其他芯片或中间层的NoC细节，这是先前技术不支持的关键属性。我们的可组合路由方法利用了一个简单而强大的见解：从单个芯片的角度来看，整个系统可以抽象为单个虚拟节点。转向限制仅应用于连接芯片与虚拟节点之间的边界路由器，从而实现了以单个芯片为粒度的可处理分析和优化。</p>
<h1 id="II-CHIPLET-BASED-SYSTEMS"><a href="#II-CHIPLET-BASED-SYSTEMS" class="headerlink" title="II. CHIPLET-BASED SYSTEMS"></a>II. CHIPLET-BASED SYSTEMS</h1><p>“摩尔定律”和“丹纳德缩放定律”的减速使得先进工艺技术变得越来越复杂和昂贵。为了抵消缩放的减速，许多芯片变得更大，以继续在功能和性能上进行世代改进；最近的例子是使用了815平方毫米芯片的NVidia“Volta”GPU [15]。最近，行业和政府正在追求和倡导基于“芯片组”的SoC设计概念，其中一个大型昂贵的SoC可以分解成多个较小、产量更高、成本更低的芯片组，然后使用先进的封装技术重新组装起来。这些技术包括AMD的超级计算APU愿景[6]，[10]，NVidia的MCM-GPU [11]，TSMC的CoWoS（芯片-在-晶片-在-基板）服务，Marvell的MoChiTM（模块化芯片）架构[7]，[8]和DARPA的CHIPS项目[12]。芯片组方法还使得SoC可以结合来自不同公司的硅，例如最近宣布的Intel Core处理器与AMD Radeon Graphics技术[13]。计算机体系结构研究文献也反映了这些趋势，涉及使用被动硅中间层[16]、带微流控冷却的被动中间层[17]、有源硅中间层[2]、[18]和光子芯片组[3]、[4]等芯片组类似体系结构的研究。</p>
<h2 id="A-Active-interposer-Chiplet-SoCs"><a href="#A-Active-interposer-Chiplet-SoCs" class="headerlink" title="A. Active-interposer Chiplet SoCs"></a>A. Active-interposer Chiplet SoCs</h2><p>尽管当前的多芯片架构采用硅中间层[6]和多芯片模块[11]，[14]等被动集成技术，但本文展望了基于新兴活性硅中间层的芯片组SoC设计，如图1所示（我们在第VI节中探讨了其他封装技术）。尽管被动基板（仅有线而没有逻辑）[19]-[21]是近期商业关注的焦点，但越来越多的学术界[2]，[4]，[22]，工业界和政府研究机构[23]-[28]正在关注活性中间层。已经展示了一种带有3D NoC的工作活性中间层原型[29]。<br>多常见的SoC功能可以移动到有源中间层，例如外部存储器接口、芯片间连接（即NoC）、外部IO和系统管理和调试（例如复位、JTAG）。这使得单个芯片可以更简单（减少设计时间）和更小（提高产量&#x2F;成本）。如果芯片在更昂贵的技术节点（例如14nm）上实现，而中间层在更成熟和更便宜的工艺（例如28nm、20nm）上实现，则从更昂贵的芯片中移动逻辑到中间层可以获得额外的成本效益[2]。最近的分析得出结论，与被动硅中间层相比，有源中间层对于大型SoC来说也可以具有成本效益[30]。</p>
<h2 id="B-Baseline-Assumptions"><a href="#B-Baseline-Assumptions" class="headerlink" title="B. Baseline Assumptions"></a>B. Baseline Assumptions</h2><p>虽然我们提出的方法适用于各种可能的基于芯片的SoC，但我们专注于特定的架构作为工作示例。我们考虑了一个多芯片异构计算系统（“APU”），由CPU和GPU组件组成。图2显示了针对GPU计算进行优化的基线系统。有四个GPU芯片，每个芯片提供16个GPU SIMD计算单元（CUs），以及一个中央CPU芯片，用于支持GPGPU工作负载的CPU阶段。这五个芯片堆叠在一个实现自己的NoC以相互连接芯片和其他常见系统功能的活动中间层上。<br>我们的基线配置使用网格拓扑结构来连接芯片和互连器的NoC子网络。每个GPU芯片的16个CU排列成4×4网格，互连器层也有一个4×4网格连接芯片。所有NoC组件都使用静态路由，采用路由表实现，这是当前商业系统（例如HyperTransport [31]或QuickPath Interconnect（QPI）[32]）的典型特征。每个芯片的本地网格和互连器网格使用X-Y路由。有关其他详细信息，例如NoC路由器配置（例如缓冲区大小，管道深度），请参见第V-A节。我们的基线提供了一个APU，其中包含64个GPU计算单元，4个CPU核心和8个外部内存通道，同时保持相对简单的结构以帮助我们的解释、评估和分析。</p>
<h1 id="3-MOTIVATION"><a href="#3-MOTIVATION" class="headerlink" title="3. MOTIVATION"></a>3. MOTIVATION</h1><h2 id="A"><a href="#A" class="headerlink" title="A"></a>A</h2><ul>
<li>NoC提供了一种统一的接口，用于连接不同系统组件。与强制系统设计者在每对通信块之间实现特定接口并(更糟糕的是)验证每个接口的正确行为相比,NoC方法使得更模块化和可扩展的设计方法成为可能，这是将不同芯片连接在一起的自然选择。</li>
<li>路由可以显著影响网络性能、可靠性和功能性 。设计不良的路由算法可能会导致网络中的资源依赖关系，从而导致死锁，这可能对系统产生致命影响。我们在基于芯片片的系统中开发了一种模块化但无死锁的路由方法，该方法具有各种拓扑结构。</li>
</ul>
<h2 id="B-Chiplet-Composability-Challenges"><a href="#B-Chiplet-Composability-Challenges" class="headerlink" title="B. Chiplet Composability Challenges"></a>B. Chiplet Composability Challenges</h2><ul>
<li>对于多芯片SoC，小芯片可能来自不同的供应商[13]，即使由单个供应商提供，也可能由不同的团队独立设计。小芯片可能部署在多个产品中，包括在小芯片设计时甚至没有定义的未来产品，全局SoC路由信息可能不可用。因此，设计用于可扩展SoC或拓扑的小芯片变得极具挑战性，因为尽管每个小芯片的NoC可能是无死锁的，但它们仍然可以以在最终SoC中引入死锁的方式连接在一起。图3a显示了一个例子，其中两个4×4网状小芯片通过额外的链路连接。尽管每个单独的小芯片使用无死锁的X-Y路由，但仍然存在可能导致死锁的信道依赖性。图3b显示了一个基于两个小芯片插入器的系统，其中突出显示了一些潜在的依赖循环</li>
<li>大多数现有的无死锁路由算法都假设有完整的系统级信息可用，而这在基于小芯片的系统中并不一定有效。因此，这些方法不适用于路由可在多种SoC设计和拓扑中重复使用的模块化、独立设计的小芯片。我们解决了这个问题，并为未来SoC的模块化设计提出了一种可组合的路由算法。</li>
</ul>
<h2 id="C-Deadlock-Avoidance"><a href="#C-Deadlock-Avoidance" class="headerlink" title="C. Deadlock Avoidance"></a>C. Deadlock Avoidance</h2><ul>
<li>死锁是通过防止NoC的资源依赖关系图中的循环来避免的。有两种主要技术可以避免循环依赖：（1）<code>虚拟通道</code>（<code>VC</code>）方法[34]，以及（2）转弯模型[35]，[36]。转向模型不依赖于额外的虚拟通道来防止死锁。相反，它们对某些路径施加转向限制，以防止循环形成。在这项工作中，我们利用转弯限制来确保多芯片、基于插入器的NoC的死锁自由度，但我们引入了一种路由方法，该方法只需要在小芯片和插入器之间的“边界”处选择一些转弯限制。我们现在讨论相关工作，并在基于可重复使用的模块化小芯片的SoC的背景下解释其限制。</li>
</ul>
<h3 id="VC-based-Approaches"><a href="#VC-based-Approaches" class="headerlink" title="VC-based Approaches"></a>VC-based Approaches</h3><ul>
<li>基于VC的方法以<em>时间复用</em>的方式将物理信道划分为多个虚拟信道。每个VC都是独立管理的，并且在每个NoC路由器中都有专用的（每个VC）微片缓冲区。通过将不同的网络流分配给不相交的VC来消除循环依赖。请注意，除了避免协议级死锁所需的虚拟网络之外，还有路由死锁自由的VC。因此，对于需要复杂一致性协议的异构系统，所需的VC数量可能相当大（影响NoC路由器面积、功率等）。对于可组合的基于小芯片的系统，<em>必须预先配置VC数量，以支持最大的系统</em>，系统中的所有个体都必须为最大数量的VC实现这一点，导致小型系统的过度供应和单个小芯片的更高成本。</li>
<li>增加VC的数量会直接影响NoC路由器的面积和功率，因为每个VC都有自己的输入缓冲器，并且仲裁逻辑会随着VC的数量而扩展。从基于小芯片的系统的角度来看，单个小芯片的NoC可以设计成具有不同数量的VC，以保证死锁自由，这取决于本地拓扑和路由方案；这使得在集成多个这样的网络时设计和验证VC分配&#x2F;仲裁逻辑极其复杂。为了使用VC消除死锁，设计人员需要提前了解完整的系统细节，过度配置VC，和&#x2F;或限制每个小芯片和&#x2F;或插入器的允许NoC。出于这些原因，我们寻求基于VC的方法的替代方案，以解决多芯片、基于插入器的SoC中的死锁。</li>
</ul>
<h3 id="Flat-Networks"><a href="#Flat-Networks" class="headerlink" title="Flat Networks"></a>Flat Networks</h3><ul>
<li>将整个系统作为一个平面网络，并应用统一的全局路由算法。在这种背景下，已经提出了许多拓扑不可知的路由算法。第一个这样的算法是up*&#x2F;down*[37]，它使用由根节点形成的广度优先搜索（BFS）生成树。指向根的链接是上行链路，而其余的是下行链路。通过禁止消息从下行链路切换到上行链路来避免信道依赖性。上行*&#x2F;下行路由需要以全局方式分析和编程所有路由表，这<strong>不允许单个芯片使用（更好的）本地路由决策。这也严重降低了系统的模块性和可组合性</strong>。我们还发现，上下路由会导致<strong>流量不平衡</strong>，因为<strong>根节点附近的链路往往比叶节点附近的更拥塞</strong>。</li>
<li>基于分段的路由将网络划分为子网，将子网划分为分段，并在每个分段内设置双向切换限制[38]。对于形成循环的起始段，除了起始路由器外，任何路由器都可以设置转弯限制；对于常规段，通过在任何路由器上设置双向转向限制来打破循环；对于仅由一条链路组成的一个路段，不允许任何流量穿过该链路（因此，在链路的一侧，必须在该链路和其他相邻链路之间设置双向转弯限制）。优化是可能的，因为转弯限制可以在一个路段内自由设置，而不依赖于其他路段。</li>
<li>Nue[39]是InfiniBand的一种基于目的地的遗忘路由实现。在网络的完全信道依赖图（CDG）的基础上，Nue构建了一个生成树，保证了死锁的自由性和连通性。然后，它使用Dijkstra算法计算从一个源节点到完整CDG中所有其他节点的最短路径，同时保持无循环约束。Nue不依赖VC来提供死锁自由，尽管额外的VC确实提高了负载平衡和性能</li>
</ul>
<h3 id="ALL"><a href="#ALL" class="headerlink" title="ALL"></a>ALL</h3><ul>
<li>所有这些平面路由方法都需要目标SoC的全局信息来构建CDG，在CDG上可以实现死锁自由。对CDG进行全面分析的成本可能高得令人望而却步[40]。如前所述，完整的SoC配置和拓扑信息预计不可用于基于小芯片的系统（例如，小芯片可能用于未来尚未指定的SoC）。虽然我们提供了与其中几种方法的实验比较，但我们强调，这些现有方法都不能满足实现真正模块化和可重复使用的小芯片与独立优化的小芯片本地NoC的目标。</li>
</ul>
<h3 id="Hierarchical-Approaches"><a href="#Hierarchical-Approaches" class="headerlink" title="Hierarchical Approaches:"></a>Hierarchical Approaches:</h3><ul>
<li>另一种方法是将NoC拓扑分解为几个层次结构层。在内部路由中，设计者可以自由地为单个级别选择任何现有的路由算法；并且每个节点只知道其级别内的本地节点。目的地为另一个级别的消息首先转发到连接到另一个层次结构级别的富时路由器。消息从源边界路由器指向其目的地通过其他边界路由器。分层路由的一个优点是独立分析本地网络的每一级，并且可以应用局部最优路由算法。然而，正如我们前面所讨论的，当<strong>将单个网络组合在一起时，全局网络仍然可能出现死锁</strong>。因此，必须小心避免全局死锁，这通常会导致对所有可能的全局路由路径进行逐案分析[41]，[42]。先前的工作提出了基于规则拓扑（如总线、环形、网格和树）的分层NoC[42]-[44]。然而，<strong>来自不同制造商的小芯片可能没有使用规则NoC进行设计，并且集成SoC系统可能不是对称的</strong>。因此，系统级的死锁避免仍然需要付出很大的努力，而且很容易出错。</li>
</ul>
<h2 id="D-Comparison-of-Modularity"><a href="#D-Comparison-of-Modularity" class="headerlink" title="D. Comparison of Modularity"></a>D. Comparison of Modularity</h2><ul>
<li>虽然“模块化”可能有很多可能的定义，但我们将重点放在表I中列出的关键属性上。</li>
<li>Table I: Comparison of deadlock avoidance approaches</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Independently Designed Chiplets</th>
<th>Enables Local Op-timization</th>
<th>Global CDG</th>
<th>Not Required Future-proof Chiplets</th>
<th>HW Cost</th>
</tr>
</thead>
<tbody><tr>
<td>VC-based</td>
<td>-</td>
<td>++</td>
<td>+</td>
<td>-</td>
<td>High</td>
</tr>
<tr>
<td>Flat NoCs</td>
<td>–</td>
<td>-</td>
<td>–</td>
<td>-</td>
<td>Low</td>
</tr>
<tr>
<td>Hierarchical</td>
<td>-</td>
<td>+</td>
<td>-</td>
<td>–</td>
<td>Low</td>
</tr>
<tr>
<td>Composable(this work)</td>
<td>+</td>
<td>++</td>
<td>++</td>
<td>++</td>
<td>Low</td>
</tr>
</tbody></table>
<h3 id="Independently-Designed-Chiplets"><a href="#Independently-Designed-Chiplets" class="headerlink" title="Independently  Designed  Chiplets:"></a>Independently  Designed  Chiplets:</h3><ul>
<li>单个芯片的架构师应该能够设计和优化他们的本地NoC，而对整个SoC的其余部分知之甚少。基于VC的方法要求小芯片架构要么拥有整个SoC组织的信息（小芯片设计不再独立），要么过度提供VC的数量，以支持所有可能使用小芯片的SoC。扁平和分层的NoC通常也需要完整的SoC信息来分析和确保锁定自由</li>
</ul>
<h3 id="Enables-Local-Optimization"><a href="#Enables-Local-Optimization" class="headerlink" title="Enables  Local  Optimization"></a>Enables  Local  Optimization</h3><ul>
<li>模块化设计方法应允许小芯片架构师在独立于最终SoC组织的情况下局部优化一个chiplet的NoC。扁平化方法需要全局SoC信息，因此影响本地拓扑、路由算法、负载平衡等的芯片内优化，不能孤立地进行。分层NoC确实实现了一定程度的局部小芯片级优化，尽管这可能仍然受到完整CDG的全局分析的限制，以消除死锁。基于VC的方法以及本文提出的可组合方案有效地允许任意小芯片级别的NoC组织和优化</li>
</ul>
<h3 id="Global-CDG-Not-Required"><a href="#Global-CDG-Not-Required" class="headerlink" title="Global CDG Not Required"></a>Global CDG Not Required</h3><ul>
<li>平面和分层的NoC不是模块化的，因为构建依赖图需要所有通道的连接，并且在所有小芯片网络最终确定之前无法执行路由分配。在不影响全局路由决策的情况下优化本地NoC也是极其困难的，因为修改本地网络会改变全局CDG。基于VC的方法在局部优化方面提供了更大的灵活性，并且不需要全局CDG；他们需要一些全局信息来分配VC。我们的可组合方法要求与SoC集成商共享关于小芯片的一些有限信息（但远低于全套信道依赖性），并要求在独立的小芯片设计之间共享节点依赖性信息。</li>
</ul>
<h3 id="Future-proof-Chiplets"><a href="#Future-proof-Chiplets" class="headerlink" title="Future-proof Chiplets"></a>Future-proof Chiplets</h3><ul>
<li>一个小芯片可能会集成到未来尚未设计的SoC中。由于扁平化和分层NoC方法需要全局CDG，小芯片将很难重复使用，因为本地NoC设计和优化可能已经固定。基于风险投资的方法可能会更好，但为尚未考虑的SoC过度提供风险投资可能会很昂贵。我们的可组合方法将与到&#x2F;从中介器到SoC设计时间的流量相关的NoC决策延迟绑定（与设计小芯片时相反），从而在新的SoC组织中部署小芯片所需的效率和返工最少</li>
</ul>
<h3 id="Hardware-Cost"><a href="#Hardware-Cost" class="headerlink" title="Hardware Cost:"></a>Hardware Cost:</h3><ul>
<li>除了基于VC的设计外，其他方法修改不同NoC组件的路由表，因此硬件开销很小。对于基于VC的方法，特别是如果需要为未来的系统进行超额配置，则支持更多VC的区域影响可能会相对昂贵。</li>
</ul>
<h1 id="IV-MULTI-CHIPLET-ROUTING"><a href="#IV-MULTI-CHIPLET-ROUTING" class="headerlink" title="IV. MULTI-CHIPLET ROUTING"></a>IV. MULTI-CHIPLET ROUTING</h1><p>在本节中，我们为芯片组系统提出了一种可组合、拓扑无关、无死锁的路由方法。关键的洞察力是简单而强大的：从任何单个芯片的角度来看，整个系统（与其他芯片的总数或中间层复杂性无关）都可以抽象成一个单一的虚拟节点，这使得在芯片粒度上进行可处理性分析、优化和正确性成为可能。我们详细介绍了一种基于芯片的路由具体方法，但这只是我们的关键洞察力所能实现的一种可能解决方案。</p>
<h2 id="A-Overview"><a href="#A-Overview" class="headerlink" title="A. Overview"></a>A. Overview</h2><ul>
<li>Before describing our methodology, we define some terms.</li>
</ul>
<h3 id="定义1："><a href="#定义1：" class="headerlink" title="定义1："></a>定义1：</h3><ul>
<li>芯片组的边界路由器通过边界链路将芯片组连接到中间层。从中间层到芯片组的流量称为入站流量；从芯片组到中间层的流量称为出站流量。</li>
</ul>
<h3 id="定义2："><a href="#定义2：" class="headerlink" title="定义2："></a>定义2：</h3><ul>
<li>边界路由器b的入站可达性InR(b)是从中间层通过路由器b可以到达的芯片上路由器的比例；0 &lt; <em>InR(b)</em> ≤ 1。</li>
</ul>
<h3 id="定义3："><a href="#定义3：" class="headerlink" title="定义3："></a>定义3：</h3><ul>
<li>边界路由器b的出站可达性OutR(b)是可以通过路由器b到达中间层的芯片上路由器的比例；0 &lt; <em>OutR(b)</em> ≤ 1。</li>
</ul>
<h3 id="定义4："><a href="#定义4：" class="headerlink" title="定义4："></a>定义4：</h3><ul>
<li>*InD(r)*是芯片路由器r的入站距离，是从最近的可以到达r的边界路由器到路由器r的拓扑距离。</li>
</ul>
<h3 id="定义5："><a href="#定义5：" class="headerlink" title="定义5："></a>定义5：</h3><ul>
<li>芯片上路由器r的出站距离*OutD(r)*是从r到其最近可达边界路由器的拓扑距离。</li>
</ul>
<p>这段话是在讨论可组合路由方法的目标。该方法的目标是尽可能地隔离单个芯片和中间层的设计，允许对每个芯片和中间层进行独立的负载平衡优化，同时为整个系统提供无死锁路由。</p>
<p>具体来说，我们在每个芯片上的边界路由器上放置单向转向限制。当应用转向限制时，系统的其余部分被抽象为一个与所有边界路由器相连的单个节点。转向限制确定了每个边界路由器的入站和出站可达性，并保证每个芯片内不存在循环通道依赖关系。然后，可达性信息传播到中间层，中间层负责将消息从一个边界路由器路由到另一个边界路由器。有了边界路由器可达性的知识，消息就会被转发到正确的目标芯片。一旦消息到达目标边界路由器，本地芯片NoC将把消息路由到其最终目的地。这种分层方法使用两组路由表来为每个芯片提供服务。第一组表用于在同一芯片内本地路由消息（这是常规的芯片内部路由），而第二组表则将出站消息引导到适当的边界路由器。本节末提供了更多实现细节。与第一条路由表（芯片内部）相对应的路由决策可以完全独立于系统的其余部分进行，这可能甚至尚未定义。</p>
<h2 id="B-Chiplet-Design-Guidelines"><a href="#B-Chiplet-Design-Guidelines" class="headerlink" title="B. Chiplet Design Guidelines"></a>B. Chiplet Design Guidelines</h2><p>在设计芯片级NoC时，边界路由器的数量和位置是两个关键的设计参数，它们可以影响整个系统的性能。这些与芯片和中介器之间的垂直（微颗粒）链接数量有关</p>
<h3 id="Number-of-Boundary-Routers"><a href="#Number-of-Boundary-Routers" class="headerlink" title="Number of Boundary Routers:"></a>Number of Boundary Routers:</h3><ul>
<li>边界路由器的数量决定了芯片可以维持发送&#x2F;接收离片流量的吞吐量；边界路由器越多，离片流量带宽就越高。一个极端情况是将芯片上的每个路由器都连接到中介器上，使每个路由器都成为边界路由器，这是先前其他人考虑过的[2]，[22]。然而，这样的设计可能会超额配置预期的离片流量，并可能受到可用微颗粒密度的限制。</li>
<li>在确定每个芯片的边界路由器数量时，一个关键观察是，虽然可能的边界路由器最大数量是芯片面积的函数，但最大有用带宽是其周长的函数。对于一个n×n网格的芯片，我们已经分析确定，在本文考虑的中介器拓扑结构下，n个边界路由器就足够了（为简洁起见，完整分析被省略）。对于我们大多数实验中假定的4×4芯片，我们每个芯片使用四个边界路由器。虽然我们专注于网格，但我们的方法适用于其他拓扑结构（请参见第VI节）。</li>
</ul>
<h3 id="Turn-Restrictions-at-Boundary-Routers"><a href="#Turn-Restrictions-at-Boundary-Routers" class="headerlink" title="Turn Restrictions at Boundary Routers"></a>Turn Restrictions at Boundary Routers</h3><ul>
<li>图3中的简单示例表明，通过中介器、其他芯片等，可能存在大量潜在的依赖循环，导致需要分析的可能路径数量爆炸。为了使单个芯片级别的路由决策成为可能，并使芯片间依赖分析可行，我们将系统的其余部分抽象为单个节点，并将所有边界路由器连接到抽象节点上（图4）。与之前的工作不同，这种新颖的抽象步骤是实现芯片独立设计的关键，而不需要全局CDG信息。</li>
<li>我们使用转向限制来打破包含抽象节点和一对边界路由器的循环。抽象节点代表单个芯片设计者不需要了解的系统的其余部分，因此<strong>转向限制不适用于抽象节点</strong>。在为边界路由器选择禁止转向时，必须保持连通性（即，每个芯片路由器到抽象节点之间必须存在路径，反之亦然），因此<strong>禁止导致断开NoC的转向限制</strong>。</li>
<li>在保持连通性的同时打破所有循环足以确保与该芯片相关的操作的正确性。但是，为了性能原因，仍然需要仔细选择转向限制和路由。可以采用不同的启发式方法；我们描述了一种在实践中表现良好的可能方法。我们考虑负载平衡的入站和出站可达性。不平衡的入站或出站可达性可能会导致芯片和&#x2F;或中介器拥塞。同时，所有芯片路由器的入站和出站距离的平均值应该最小化，因为当路由到芯片外时，如果消息有多个边界路由器候选，则首选最近的边界路由器。总体而言，在选择禁止转向时，我们的目标是最小化平均距离&#x2F;平均可达性，其中距离和可达性在第IV-A节中定义，并且平均值是在所有芯片上计算的。具体而言，平均距离是芯片上所有路由器的入站和出站距离的平均值。平均可达性类似地计算每个边界路由器的入站和出站可达性。我们的启发式方法选择具有较低平均距离和较高平均可达性的组合。</li>
<li>为了可视化指标，图4给出了一个4×4网格的示例，其中有3个边界路由器a、b和c；其余的系统用x表示。假设本地芯片NoC采用X-Y路由，禁止转弯的箭头在边界路由器处被划掉。包含x和任意一对边界路由器的循环通过禁止某些转弯来打破。<br>在此示例中，a 的入站可达性 (InR(a)) 为 1&#x2F;2，因为其入站转向限制与小芯片的本地 X-Y 路由相结合，使得小芯片的左半部分无法从节点 x 通过 a 到达。 由于a没有出站转向限制，其出站可达性OutR(a)为1，即每台路由器都可以通过a到达x。 x → a → c → x 的环路在 c 处因出站转弯限制而中断，导致 OutR(c) &#x3D; 1&#x2F;2。<br>或者，不是在路由器 c 处断开环路，而是可以在路由器 a 处放置入站转弯限制 x → a → (3, 3) 以断开相同的环路，为此 InR(a) 变为 1&#x2F;4（仅列 编号 2 可通过路由器 a 到达，因为两个单独的入站转弯限制用于打破两个不同的环路），并且 OutR© 变为 1。<br>路由器 m 的入站距离为 3，从边界路由器 b 测量； 出站距离为 3，到 a 或 b。 同样，从路由器c测得的路由器InD(n)&#x3D;1； OutD(n) &#x3D; 2 到路由器 a。 虽然此示例出于说明目的有些特别，但我们提供了一个具体的算法来确定下面的所有这些。</li>
</ul>
<h3 id="Boundary-Router-Placement"><a href="#Boundary-Router-Placement" class="headerlink" title="Boundary Router Placement"></a>Boundary Router Placement</h3><ul>
<li>给定一个内部芯片级路由算法，边界路由器的选择会影响它们的入站和出站可达性以及芯片上的流量分布。我们提出了以下选择边界路由器的准则。<br>首先，避免将边界路由器聚集在一起，以减少创建网络热点的机会。<br>其次，应该以一种使所有边界路由器的入站&#x2F;出站可达性保持平衡的方式放置边界路由器。<br>第三，更喜欢具有较低基数的路由器。<br>前两个准则旨在优化网络性能和吞吐量。第三个准则旨在最小化电路复杂性。例如，在图4中，芯片中间的四个路由器每个都有五个端口（四个连接到相邻路由器，第五个连接到它连接的网络端点，例如GPU CU）。向其中一个“内部”路由器添加垂直链接将强制该路由器实现六个端口，这会增加面积并可能影响电路时序。但是，向芯片边缘上的任何一个路由器添加垂直链接都可以使所有路由器继续具有五个或更少的端口。</li>
</ul>
<h3 id="Boundary-Router-Placement-and-Turn-Restriction-Algorithm"><a href="#Boundary-Router-Placement-and-Turn-Restriction-Algorithm" class="headerlink" title="Boundary Router Placement and Turn Restriction Algorithm"></a>Boundary Router Placement and Turn Restriction Algorithm</h3><ul>
<li>算法1 确定每个芯片的边界路由器位置和转向限制。<br>PlaceBoundaryRouter通过调用SetTurns迭代所有边界路由器位置，以查找更好的位置和转向限制。<br>对于每个放置，函数identifyAllBoundaryTurns枚举所有可能的边界转弯并将它们存储在列表bturn []中。另一个列表pturn []存储禁止的边界转弯，这在SetTurns中递归更新。变量max是消除所有死锁所需的最大禁止边界转弯数。</li>
<li>过程 SetTurns 使用启发式方法检查所有边界转弯组合，如果当前限制改进了用户指定的目标函数，则更新迄今为止找到的最佳位置。 我们使用 CDG [39]、[45] 的矩阵表示。<br>最初，允许所有边界转弯。 更新函数（第 16 行）使用 Floyd Warshall 全对最短路径算法 [46] 传播到整个图的通道连接的禁止边界转弯列表 pt[] 更新 CDG。 这提供了来自更新的 CDG 的连接信息、边界路由器可达性和跳数。 下一步检查用户指定的目标函数是否得到改进（第 17 行）。 在第 19 行，connected 函数检查 CDG 是否仍然连接，因为任何导致网络断开的转向限制都应该被丢弃。 如果图是连通的，hasLoop 会检测入站通道（从抽象节点到边界路由器）是否连接到出站通道（从边界路由器到抽象节点）。 如果没有找到循环，则在第 22 行更新最佳位置，递归终止。 第 24 行控制递归的深度，因为只需要一定数量的边界限制就可以消除死锁。 如果 CDG 已连接但循环仍然存在，则第 27-29 行调用对 SetTurns 的递归调用以根据需要添加更多转弯限制。</li>
</ul>
<h2 id="C-Interposer-NoC-Configuration"><a href="#C-Interposer-NoC-Configuration" class="headerlink" title="C. Interposer NoC Configuration"></a>C. Interposer NoC Configuration</h2><ul>
<li>确定了芯片的进出转向限制后，我们现在解释如何编程中继器的路由表。请注意，当单独考虑中继器网络（不包括芯片）时，中继器网络本身也应该是无死锁的。中继器负责将消息从一个边界路由器路由到另一个边界路由器。为此，必须向中继器提供某些芯片级别的信息。<br>首先，我们需要知道每个单独边界路由器可达的芯片节点（终端节点）。我们使用这个来确保消息从可以到达目的地的芯片边界路由器路由。其次，我们可以选择使用每个边界路由器和其可达芯片节点之间的拓扑距离来优化路由距离和负载平衡。请注意，这些信息可以简单地以“列表”格式列出（例如，节点x可以从边界节点y到达）；不需要芯片的本地NoC的完整细节（例如，网络的拓扑和请求如何从y到x的路由决策），并且这些信息独立于interposer和任何其他芯片。<br>我们现在描述我们的互连路由方案。对于每个目标路由器的消息，以下算法决定将该消息发送到目标芯片的哪个边界路由器。如果目标只能通过单个边界路由器到达，则中间件必须将消息路由到该特定边界路由器。否则，我们选择边界路由器以在边界路由器之间平衡网络负载（平均利用芯片-中间件带宽），同时最小化路径长度（避免发送消息在高度迂回的情况下只是为了负载平衡）。下面，我们正式指定算法。</li>
<li>对于给定的边界路由器i，仅由i可到达的节点集合称为Ai。</li>
<li>对于可以被多个边界路由器到达的其余节点，列表Ci包含所有节点，这些节点在拓扑上比任何其他边界路由器更接近i。对于不同的边界路由器j和k，Cj∩Ck&#x3D;∅。 </li>
<li>剩余的节点与至少两个边界路由器等距。设Ei，j是同时等距于边界路由器i和j的节点列表。虽然可能等距于两个以上的边界路由器，但为简单起见，我们仅考虑两个路由器的情况。 • 执行以下步骤将芯片上的节点分配给边界路由器。 <ul>
<li>第1步。在所有边界路由器中，选择具有Ai中最小项目数的路由器i。 </li>
<li>第2步。逐个将Ci中的节点分配给Ai，直到Ai中的项目数不再是最小值。将项目分配给Ai时，从Ci中删除该项。如果Ai仍然具有最小数量的项目，则逐个从Ei，j中分配节点到Ai。将项目分配给Ai后，从Ei，j和Ej，i中删除该项。</li>
<li>第3步。如果无法进行进一步分配，则完成对边界路由器i的节点分配。重复步骤1-3，直到Ci &#x3D; ∅且Ei，j &#x3D; ∅对于所有边界路由器i和j。<br>完成后，每个边界路由器的节点分配信息都存储在Ai中。通过参考这些信息，配置相应的中间层路由表。系统集成商可以自由选择任何对于中间层网络来说是死锁自由的底层路由算法。</li>
</ul>
</li>
<li>考虑图4中的示例。对于边界路由器a、b和c，Aa &#x3D; {(2, 0),(2, 1),(2, 2), a}，Ab &#x3D; {(0, 0),(0, 1), m,(0, 3), b,(1, 1),(1, 2),(1, 3)}，Ac &#x3D; ∅；Ca &#x3D; {(3, 3)}，Cb &#x3D; ∅，Cc &#x3D; {(3, 0), c, n}。在这个网络中没有等距集。节点分配从边界路由器c开始，因为Ac为空。Cc中的所有元素都分配给Ac，Ac &#x3D; {(3, 0), c, n}。对于c，不能进行进一步的分配，因此算法选择下一个路由器a。Ca中唯一的元素被分配给Aa，Aa &#x3D; {(2, 0),(2, 1),(2, 2), a,(3, 3)}。到目前为止，每个芯片上的节点都被分配给了一个边界路由器；这些分配存储在Aa、Ab和Ac中。有了上述信息，互连器就能将消息路由到正确的边界路由器（a、b或c），如果消息是发送到该芯片的话。</li>
</ul>
<h2 id="D-Deadlock-Freedom-and-Connectivity"><a href="#D-Deadlock-Freedom-and-Connectivity" class="headerlink" title="D. Deadlock Freedom and Connectivity"></a>D. Deadlock Freedom and Connectivity</h2><ul>
<li>现在我们展示可组合路由方案是无死锁且连通的。假设存在一个循环r1，l1，r2，l2，…，rn，ln，其中r表示路由器，l是连接到r的链接。如果所有路由器和链接都属于同一个芯片，则与基本假设芯片级网络无死锁相矛盾。否则，如果循环的子集属于插板和其他芯片，则可以用单个节点x来抽象这个子集。因此，该循环转换为r1，l1，…，rj，x，rk，lk，…，rn，ln。因为删除了包含x的循环中的所有循环依赖项，所以新循环是无死锁的。因此，可组合路由方案是无死锁的。</li>
<li>单个芯片内的任何网络都是连接的，因为边界路由器转向限制不影响内部芯片网络。芯片上的任何节点都能通过至少一个边界路由器到达中间层。中间层网络是通过构造连接的（即，每个中间层路由器都可以到达其他中间层路由器）。对于任何一对芯片节点，都存在一条路径。因此，该系统是连接的。</li>
</ul>
<h2 id="E-Microarchitectural-Issues"><a href="#E-Microarchitectural-Issues" class="headerlink" title="E. Microarchitectural Issues"></a>E. Microarchitectural Issues</h2><ul>
<li>每个芯片需要实现两个不同的路由表。第一个处理从不到达互连器的芯片内部流量。这个路由表可以以芯片设计者认为合适的任何方式填充。第二个路由表将出站流量定向到适当的边界路由器。这种组织方式假定整个系统中所有路由器端点都有全局ID空间。类似于用于检测系统中所有内存和计算资源（特别是在多插槽SMP系统中）的引导序列，可组合的基于互连器的SoC需要一个类似的系统配置协议。这个过程的一部分将是检测可用的NoC端点，为每个端点分配唯一ID，并计算和填充次级路由表。与系统引导不同，这个过程只会由SoC集成器在物理组装SoC后执行一次（尽管也可以提供钩子以在以后的某个时间点更新表，例如处理失败的链接[32]）</li>
<li>在我们的设计中，每个网络接口（NI）都有一个查找表，将出站数据包的目标ID映射到边界路由器ID。然后将边界路由器ID嵌入标题flit中，并用于芯片内路由，直到数据包离开芯片。关于面积&#x2F;功率开销，每个NI中的查找表需要针对给定产品的最大系统大小进行配置。路由表通常比其他路由器组件（如缓冲区和交叉点）小得多。此外，每个芯片中第二个路由表的大小仅与边界路由器的数量成比例；因此，它比第一个路由表小得多。有几种实现互连路由器的方法：1）为最大系统大小提供路由表，导致相对较大的互连路由表；或2）添加另一层目标映射以将目标ID转换为目标边界路由器ID，导致更小的路由表但更复杂的边界路由器。总体而言，与规范的两级路由器相比，我们的设计不应产生显着的额外功率&#x2F;面积&#x2F;时间影响。</li>
</ul>
<h1 id="V-EVALUATION"><a href="#V-EVALUATION" class="headerlink" title="V. EVALUATION"></a>V. EVALUATION</h1><h2 id="A-Experimental-Methodology"><a href="#A-Experimental-Methodology" class="headerlink" title="A. Experimental Methodology"></a>A. Experimental Methodology</h2><ul>
<li>为了评估网络性能，我们使用由 gem5 [47] 和 GPU 模型 [48] 的修改版本组成的 APU 模拟平台进行周期级执行驱动模拟。 我们使用 Garnet [49] 来模拟使用每通道 4-flit 缓冲区的 2 级路由器的网络。 我们的初始实验使用图 2 所示的多芯片 APU 配置，包括四个 GPU 芯片、一个 CPU 芯片和一个有源中介层。 CPU chiplet 由 CPU 内核、专用 CPU L1 和 L2 缓存以及末级缓存组成。 每个 GPU 小芯片由 16 个计算单元 (CU) 和 8 个 GPU L2 缓存组组成。 我们的内存模型使用内置的 gem5 模型 [50]，每个通道有八个内存通道和八个存储体。 图 2 还显示了由我们的算法从第 IV 节确定的边界节点的位置。</li>
<li>我们同时使用合成流量和基于应用程序的模拟。对于合成流量，每个数据包宽度为8个flits，并且网络模拟了200万个周期。对于系统级（非合成）模拟，我们使用AMD SDK [51]、Rodinia [52]和Pannotia [53]套件中的APU应用程序，其中芯片外通信包括GPU CUs之间的缓存一致性和到主存储器的流量。</li>
</ul>
<h2 id="B-Comparison-Points"><a href="#B-Comparison-Points" class="headerlink" title="B. Comparison Points"></a>B. Comparison Points</h2><ul>
<li>即使从定性上看，基于VC的方法是昂贵且不太吸引人的，但为了完整性，我们提供了一个比较。使用与EbDa [40]类似的方法，我们实现了一个支持最小路径自适应路由的VC-based死锁避免机制：对于单个2D网格，需要两个VC来避免死锁；通过在芯片和interposer之间引入垂直连接，需要两个更多的VC来隔离入站和出站流量。我们还实现了第III-C节中描述的三种全局路由算法：up*&#x2F;down* [37]、基于段[38]和Nue路由[39]。请注意，所有三种算法都需要完整的CDG知识，并且不支持独立设计和芯片复用。我们将其与之进行比较作为我们所知道的最相关的工作，但它们无法满足我们的关键芯片模块化标准。</li>
<li>在应用转向限制之前，通过找到与所有其他节点的平均距离最小的节点来选择上*&#x2F;下*路由中的根节点。基于段的路由中的起始段是从系统的左上角（左上GPU芯片的左上路由器）形成的。在我们的可组合路由方案中，本地芯片算法和互连器算法都使用维度排序路由。为了与基于VC的方法进行公平比较，我们为每个基于转向的方案提供了四个VC。</li>
<li>我们还将我们的结果与理想化系统（表示为最短路径）进行比较，该系统使用不切实际的大量虚拟通道来避免死锁。 路由表是使用全对最短路径 (APSP) 算法配置的（与现有技术和我们自己提出的一些路由可能不是最短的方案形成对比）。 请注意，这个理想化的系统不一定能提供真正的最佳性能，因为 APSP 仍然会导致某些链路中的拥塞程度高于其他链路。 然而在实践中，我们发现这种最短路径配置通常优于实际的替代方案，因此它提供了一个乐观的性能目标来进行比较。</li>
</ul>
<h2 id="C-Basic-Throughput-Evaluations-with-Synthetic-Traffic-使用合成流量进行基本吞吐量评估"><a href="#C-Basic-Throughput-Evaluations-with-Synthetic-Traffic-使用合成流量进行基本吞吐量评估" class="headerlink" title="C. Basic Throughput Evaluations with Synthetic Traffic 使用合成流量进行基本吞吐量评估"></a>C. Basic Throughput Evaluations with Synthetic Traffic 使用合成流量进行基本吞吐量评估</h2><ul>
<li>在本节中，我们评估了一个由四个芯片组成的64-CU系统，每个芯片组由16个CU组成，组织为4×4网格。每个芯片组通过四个边界路由器连接到中间层。中间层网络是4×4网格。</li>
<li>图5a和图5b显示了均匀随机和位补码流量下的负载延迟曲线。我们观察到，许多异构多芯片工作负载与均匀随机流量相似：实际系统具有混合的芯片内、芯片间、芯片到互连器和芯片到内存的流量，涵盖了一致性和主存储器请求和响应；这些在总体上“平均”，使得均匀随机流量的高级性能趋势与我们的几项应用驱动研究大致相符。位补码流量模式强制所有数据包离开芯片，因此进一步加重了互连器的压力并创建了网络热点。我们运行了其他合成流量模式，但总体趋势非常相似，因此没有显示。</li>
<li>我们的可组合方案优于up*&#x2F;down*、基于段的和VC-based方法。在相同数量的虚拟通道下，可组合方案的性能优于VC-based方法，主要是因为额外的虚拟通道减少了头阻塞。典型的一致性协议需要3-5个虚拟网络，每个虚拟网络都需要四个VC以实现死锁自由。异构架构的一致性协议可能需要更多的虚拟网络，使得VC-based方法变得更加昂贵。虽然VC-based方法需要每个虚拟网络四个VC以实现正确性，但是由于VC-based和可组合方案之间的性能差距，需要更多的VC以实现更好的性能。</li>
<li>基于段的路由在零负载延迟方面存在问题，并且具有最低的饱和吞吐量。这主要是因为它是为2D网格状网络设计和优化的。虽然评估系统由多个网格网络组成，但全局拓扑结构仍然不规则，因此基于段的路由无法有效处理它。基线基于段的算法并不总是形成最优段；从边界路由器向中间件开始的段可能会绕到同一芯片上的路由器上结束，或者通过另一个芯片跨越多个跳跃，直到到达属于现有段的路由器。这样的链式段在较大的系统中可能非常长，并且在段内断开任何双向转弯将导致更多的非最小路径（对于基线APU，我们观察到平均路由距离近11个跳跃，而其他方法则为∼8个跳跃）。虽然拓扑感知优化可能会改善基于段的路由性能，但这超出了本文的范围。¹</li>
<li>上行*&#x2F;下行* 路由具有低零负载延迟，这表明消息可能会在评估系统中采用最少的路由。 然而，与其他方法相比，它相对较早地饱和。 根节点附近的链路本质上比叶节点附近的链路更拥塞。 当注入率增加时，这些环节会饱和并成为瓶颈。 Nue 路由优于我们的可组合方法，但这只是因为它具有利用完整 CDG 知识优化其路由的优势，从而导致与理想的最短路径算法类似的行为。 有了足够的 VC（我们为其提供），它会找到优化的路径来平衡网络工作负载。</li>
<li>我们的组合方案优于up*&#x2F;down和基于段的路由，因为芯片和互连网络更加负载平衡，芯片和互连器之间的垂直链接也是如此。Nue提供更好的负载平衡，因此表现接近理想的最短路径路由，但与其他先前的工作一样，它不适用于独立设计和重用芯片以进行模块化SoC构建。与理想的最短路径路由相比，我们的方案覆盖了从up&#x2F;down*到理想化最短路径路由的吞吐量差距的大部分，但仍然存在一些余地。这是因为1）由于转向限制而仍然存在一些负载不平衡，以及2）理想化网络具有更多的虚拟通道以改善头部阻塞。总体而言，尽管我们提出的方法没有实现全局负载平衡优化的全部性能，但我们的结果表明，我们的方案确保了正确性，并提供了高性能的多芯片SoC，它独特地实现了一种模块化芯片设计方法论，不需要对整个系统的CDG有先验知识。</li>
</ul>
<h2 id="D-Application-level-Impact"><a href="#D-Application-level-Impact" class="headerlink" title="D. Application-level Impact"></a>D. Application-level Impact</h2><h3 id="Network-Latency"><a href="#Network-Latency" class="headerlink" title="Network Latency:"></a>Network Latency:</h3><p>我们使用执行驱动模拟对非合成工作负载评估了我们的可组合路由方案。图6a显示了平均网络延迟，归一化为理想的最短路径方法。基于段的路由未显示，因为在给定的系统大小下，它始终表现出色并且明显优于其余方法。我们省略了基于VC的方案，因为评估的异构系统需要大量的VC才能避免路由和协议级死锁，同时保持性能。总体而言，我们的可组合方法实现的网络延迟几乎与最短路径相同。在一些情况下（bfs、nw、srad），可组合路由比最短路径表现略好；正如前面所讨论的，最短路径并不是真正的最优解，有时会出现局部流量突发（这种情况在GPU工作负载中比传统CPU应用程序更常见），会导致最短路径配置中的拥塞&#x2F;负载不平衡。<br>由于根节点在高负载下成为瓶颈，因此上下行方法的大多数基准测试的平均网络延迟增加了50%以上，如第V-C节所讨论的。这种瓶颈限制了系统的有效带宽，并导致了显着的网络缓冲延迟。</p>
<h3 id="Application-Performance"><a href="#Application-Performance" class="headerlink" title="Application Performance:"></a>Application Performance:</h3><p>图6b显示了程序执行时间，归一化为理想的最短路径方法。总体而言，可组合路由与最短路径相比实现了类似（在1%以内）的系统性能。虽然APU&#x2F;GPGPU应用程序会生成大量的NoC&#x2F;内存流量（这对于压力网络来说非常好），但对应用程序执行时间的总体影响却很小，因为大多数GPU应用程序本质上对延迟不太敏感（即，丰富的SIMD并行性可以更容易地容忍增加的延迟）。虽然有流量突发，但应用程序的大部分部分不会使NoC接近饱和，因此对总执行时间的影响较小。尽管如此，我们仍然观察到一些工作负载使用up*&#x2F;down*路由时性能下降了5-10%，而我们的方法在大约与最短路径方法相同的水平上执行。</p>
<h3 id="Case-Study-–-HotSpot"><a href="#Case-Study-–-HotSpot" class="headerlink" title="Case Study – HotSpot:"></a>Case Study – HotSpot:</h3><p>图7显示了执行HotSpot时最常用的链接的最大链接利用率。仅显示了互连网络和GPU芯片上的边界路由器，因为其余部分利用率较低。对于每个10000个周期，我们对每个链接的利用率进行了采样。链接的最大利用率是整个程序执行过程中观察到的最大采样结果。最大链接利用率向我们展示了在突发流量行为下最糟糕的链接拥塞发生在哪里，从而使我们能够可视化全局网络流量并定位任何NoC瓶颈。一般来说，可组合路由比最短路径具有更少的拥塞链接。但是，前者在互连器上具有略微不平衡的流量分布，这表明最大链接利用率更大。这是由于转向限制偏向边界路由器的可达性（即，某些边界路由器接收更多流量）。对于上*&#x2F;下*路由，根节点位于互连器上。如预期所示，靠近根节点的链接比其他链接更加利用。</p>
<h1 id="VI-BROADER-APPLICABILITY-更广泛的适用性"><a href="#VI-BROADER-APPLICABILITY-更广泛的适用性" class="headerlink" title="VI. BROADER APPLICABILITY 更广泛的适用性"></a>VI. BROADER APPLICABILITY 更广泛的适用性</h1><p>前一节展示了我们方法在一个特定的芯片组SoC上的有效性。在本节中，我们提供了额外的实验结果，因为各种系统假设被修改，然后我们还讨论了如何将该提议应用于没有活动互连器的芯片组系统。</p>
<h2 id="A-Design-Guideline-Justification-设计指南的证明"><a href="#A-Design-Guideline-Justification-设计指南的证明" class="headerlink" title="A. Design Guideline Justification 设计指南的证明"></a>A. Design Guideline Justification 设计指南的证明</h2><p>在第IV-B节中，我们描述了如何确定边界路由器的数量、选择转向限制的目标函数以及边界路由器的放置。为了证明所提出的指南的有效性，我们使用均匀随机流量评估了其他设计方案。图8a显示了从2个边界路由器增加到8个路由器时吞吐量的提高。在所有情况下，互连网络保持相同的大小；当有8个边界路由器时，2个边界路由器集中到一个互连路由器上，这增加了路由器的复杂性和面积。从4个边界路由器到8个边界路由器的改进要比从2个边界路由器到4个边界路由器的改进小得多。不足的边界路由器可能会影响系统吞吐量。通过提供更多的边界路由器，可以增加芯片外带宽，从而减少与芯片内通信的干扰。在16个边界路由器的极端情况下，每个芯片路由器都有一个垂直连接，与芯片外通信不会影响芯片内通信&#x2F;拥塞。然而，这样的设计是不切实际的，因为需要大量垂直线。总体而言，在性能和硬件成本方面，4个边界路由器是一个合理的设计选择。<br>图8b比较了不同目标函数的系统吞吐量，包括最小化平均距离、最大化平均可达性和我们提出的度量（即最小化平均距离&#x2F;平均可达性）。结果表明，我们提出的目标函数是有效的，并且与其他度量相比提供了最佳性能。仅考虑平均距离或平均可达性往往会创建不平衡的芯片内流量。<br>在某些情况下，设计者可能没有自由选择边界路由器放置位置的自由（例如，布局限制，物理设计约束）。图8c考虑了边界路由器位置已移动到较不理想的位置（例如，聚集在一起），分散到角落，位于同一行（即与我们的方法分配给它们的位置不同）。我们重新运行了确定转向限制的算法。结果表明，边界路由器的随机放置最终导致某些链接被使用得比其他链接更多，从而影响了系统吞吐量，但死锁自由仍然得以保持。</p>
<h2 id="B-Sensitivity-Studies"><a href="#B-Sensitivity-Studies" class="headerlink" title="B. Sensitivity Studies"></a>B. Sensitivity Studies</h2><p>我们考虑了以下基线的变体：<br>系统规模：基线具有4个GPU芯片，每个芯片有16个CU，总计算能力为64个CU。我们还考虑了两种128-CU配置（CPU数量保持不变），分别由（1）每个芯片32个CU的4个芯片和（2）每个芯片16个CU的8个芯片组成。在这两种情况下，每个芯片仍然有四个边界路由器。<br>Interposer NoC拓扑结构：为了支持这一论点，即中介器的NoC可以独立于芯片设计，我们评估了基线系统，但将中介器的网状NoC替换为“双蝴蝶”拓扑结构[22]<br>不规则芯片拓扑结构：为了支持芯片的NoC拓扑结构可以独立设计的类似主张，我们评估了一个系统，其中每个GPU芯片都实现了一个不同的本地NoC拓扑结构，包括网格、环、蝴蝶和树形拓扑结构<br>结果：本节中的分析仅呈现了均匀随机流量的负载延迟曲线。我们也进行了应用程序级别的实验，但总体趋势非常一致，因此我们由于空间原因和重复性而省略了这些附加图形。这些实验的主要目的是证明我们的提议是一种在广泛的基于芯片组的系统可能性范围内实现高性能并确保死锁自由的强大方法。<br>图9a和b显示了更大的128-CU配置的结果，我们的组合方法轻松地优于上&#x2F;下路由。这两个配置之间的主要区别是芯片内和芯片间流量的比例。与最短路径相比，我们的组合方法对流量分布不太敏感，因为具有更好的芯片级和互连器级负载平衡。” 的中文翻译是：“图9a和b显示了更大的128-CU配置的结果，我们的组合方法轻松地优于上&#x2F;下路由。这两个配置之间的主要区别是芯片内和芯片间流量的比例。与最短路径相比，我们的组合方法对流量分布不太敏感，因为具有更好的芯片级和互连器级负载平衡。<br>图9c显示了当插层NoC具有蝴蝶式拓扑结构时的结果。结果与网格的基准系统类似，总体上这有助于证明可以轻松地独立设计单个芯片，而不受插层NoC拓扑结构的影响。<br>图9d显示了当每个GPU芯片组具有不同的本地NoC拓扑时的结果。这里的结果更有趣，因为我们的提议导致的饱和吞吐量比具有丰富虚拟通道和最短路径路由的“理想”情况更高。这是因为在处理芯片间通信时，最短路径会偏向于靠近互连器中心的边界路由器，而我们的提议方法实现了更好的互连器流量分布。” 的中文翻译是 “图9d显示了当每个GPU芯片组具有不同的本地NoC拓扑时的结果。这里的结果更有趣，因为我们的提议导致的饱和吞吐量比具有丰富虚拟通道和最短路径路由的“理想”情况更高。这是因为在处理芯片间通信时，最短路径会偏向于靠近互连器中心的边界路由器，而我们的提议方法实现了更好的互连器流量分布。</p>
<h2 id="C-Other-Chiplet-Packaging-Options"><a href="#C-Other-Chiplet-Packaging-Options" class="headerlink" title="C. Other Chiplet Packaging Options"></a>C. Other Chiplet Packaging Options</h2><p>到目前为止，我们的研究集中在基于新兴活性硅中间层技术构建的芯片组系统上。虽然活性硅中间层可能是实用的，特别是如果可以将用于逻辑的总中间层面积最小化[2]，[30]，但近期芯片组系统可能会受到被动基板的限制。无论是使用被动硅中间层[19]-[21]还是更传统的封装基板[7]，[11]，[14]，[54]，一个可能的担忧是芯片组下方缺乏活性层可能会限制我们方法的适用性。<br>图10a显示了一个在被动基板上具有芯片的示例系统。此布局假定提供了常见功能的中央芯片（否则将放置在活动互连器上，例如内存控制器、NoC、系统管理），计算芯片以星形拓扑结构从中央芯片向外扩展。使用这种类型的布局，我们的建议方法可以直接应用于此系统，无需进行任何修改，方法是将中央芯片与我们之前的工作示例中的活动互连器相同对待。选择最佳边界节点放置的过程可以更有效，因为芯片上可供选择的合理节点较少（即最靠近中央芯片的节点）。</p>
<h2 id="D-Other-Chiplet-Topologies"><a href="#D-Other-Chiplet-Topologies" class="headerlink" title="D. Other Chiplet Topologies"></a>D. Other Chiplet Topologies</h2><p>即使对于非星型拓扑的芯片，他们的方法也可以进行适应。图10b显示了一个基于芯片的系统，其中两个CPU芯片具有额外的点对点链接（例如，用于低延迟高速缓存一致性），这些链接不通过中央芯片进行路由。为了支持这一点，这两个CPU芯片被有效地视为单个虚拟芯片，以应用他们的方法来确定路由限制。仍然需要CPU芯片设计人员确保两个CPU芯片之间的直接路由是正确的（即无死锁），但设计人员无需担心从&#x2F;到中央芯片进入&#x2F;离开任一芯片的流量，因为他们的方法确定适当的转向限制以确保整个SoC的正常运行。<br>同样，图10c显示了一个没有单个“中央”芯片的系统，而是有两个芯片连接到其他芯片。在这里，我们应用了类似的技术，其中两个芯片被视为单个虚拟芯片，以便于此方法。与上面的两个CPU芯片示例类似，SoC设计人员必须确保一对芯片是相互&#x2F;本地死锁自由的，但是任何剩余的与其他芯片的连接都将得到正确处理。大多数合理的芯片拓扑都可以迭代地合并，直到将拓扑转换为类似星形的组织为止，此时我们的方法可以直接应用。</p>
<h1 id="VII-RELATED-WORK"><a href="#VII-RELATED-WORK" class="headerlink" title="VII. RELATED WORK"></a>VII. RELATED WORK</h1><p>平面网络：在第III-C节中，我们介绍了一种避免死锁的平面网络方法。对up*&#x2F;down*路由的进一步优化已被提出：Koibuchi等人基于BFS生成树构建了一个从左到右的有向图，并在根节点周围分配流量[55]；Sancho等人使用深度优先搜索（DFS）生成树[56]；他们通过在每个周期中单独删除每个方向上的通道依赖关系来改善流量平衡[57]。<br>分层网络：HiRA [41]是一种用于分层NoC中无死锁路由的方法。在HiRA中，网络被划分为子网（具有独立无死锁路由算法的网络）和外部链接（子网之间的链接）。通过在每个子网中选择安全边界节点并在边界节点上应用转向限制来避免死锁。当连接到其他子网时，如果边界节点不会发生死锁并且可以保证连通性而不修改子网的内部路由算法，则边界节点是安全的。在应用边界节点上的转向限制时，使用包含所有边界节点的CDG。虽然HiRA可应用于具有被动互连器的芯片组系统，但对于两个主要原因，它不适用于主动互连器SoC。首先，仍需要系统级CDG，并且转向限制在很大程度上取决于子网路由算法。其次，HiRA缺乏中央网络（即主动互连器）的路由算法，该网络连接到所有芯片组。<br>“3D NoC中的路由：常规3D NoC的死锁避免技术包括DoR和基于转向的路由[35]，[58] - [60]和基于VC的方法[61] - [63]。其中许多技术不直接适用，因为它们的基于转向的算法要求每个路由器在堆栈中具有垂直连接（我们不做出这种假设），这会增加每个芯片TSV区域开销。其他3D VC技术创建与芯片在堆叠中的垂直位置相关联的单调VC排序；芯片在中间层上的物理拓扑结构使得很难强制实施总排序。我们不提供这些作品的实验评估，因为不明显如何将它们适应不仅由单个垂直3D芯片堆栈组成的拓扑结构。”</p>
<h1 id="VIII-CONCLUSIONS"><a href="#VIII-CONCLUSIONS" class="headerlink" title="VIII. CONCLUSIONS"></a>VIII. CONCLUSIONS</h1><p>基于芯片组的复杂SoCs的构建非常令人兴奋，因为它可以实现各种类型的系统，但这些系统必须易于设计和组装。当使用来自第三方硅IP供应商的黑盒芯片构建系统时，确保正确性变得更加具有挑战性和重要性。本文对基于芯片组的SoC设计方法论做出了重大贡献，重点是互连；然而，仍有其他有益的研究领域。如果系统中的不同芯片要具有高速缓存一致性，则必须设计一个正确运行并跨不同物理芯片扩展（以性能为准）的高速缓存一致性协议。虽然不是严格的正确性问题，但可能需要设计服务质量机制，以确保不同的芯片集成在一起“友好地协作”，特别是在实时组件（例如图形和音频）或更高级别的性能目标（例如数据中心服务级别协议）方面。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zyh-eric.gitee.io/zyhjy/2023/03/22/Clion%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/zyhjy/images/zyhjy.png">
      <meta itemprop="name" content="Yuhang Zhang">
      <meta itemprop="description" content="爱小雅，爱生活，爱物理!">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZYHJY">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/zyhjy/2023/03/22/Clion%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" class="post-title-link" itemprop="url">Clion使用指南!</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-03-22 11:00:50" itemprop="dateCreated datePublished" datetime="2023-03-22T11:00:50+08:00">2023-03-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-30 18:15:18" itemprop="dateModified" datetime="2023-07-30T18:15:18+08:00">2023-07-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/zyhjy/categories/Clion/" itemprop="url" rel="index"><span itemprop="name">Clion</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="常用快捷键"><a href="#常用快捷键" class="headerlink" title="常用快捷键"></a>常用快捷键</h2><table>
<thead>
<tr>
<th>｜shortcut</th>
<th>description</th>
</tr>
</thead>
<tbody><tr>
<td>cmd + opt + -&gt; &#x2F; &lt;-</td>
<td>恢复&#x2F;撤销光标上次操作</td>
</tr>
<tr>
<td>cmd+shift+ -</td>
<td>折叠所有代码块</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/zyhjy/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/zyhjy/">1</a><span class="page-number current">2</span><a class="page-number" href="/zyhjy/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/zyhjy/page/6/">6</a><a class="extend next" rel="next" href="/zyhjy/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yuhang Zhang"
      src="/zyhjy/images/zyhjy.png">
  <p class="site-author-name" itemprop="name">Yuhang Zhang</p>
  <div class="site-description" itemprop="description">爱小雅，爱生活，爱物理!</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/zyhjy/archives/">
        
          <span class="site-state-item-count">58</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/zyhjy/categories/">
          
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/zyhjy/tags/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2022 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yuhang Zhang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/zyhjy/lib/anime.min.js"></script>

<script src="/zyhjy/js/utils.js"></script>


<script src="/zyhjy/js/schemes/pisces.js"></script>


<script src="/zyhjy/js/next-boot.js"></script>




  















  

  

</body>
</html>
